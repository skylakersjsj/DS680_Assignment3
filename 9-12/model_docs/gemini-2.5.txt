Gemini 2.5: Pushing the Frontier with
Advanced Reasoning, Multimodality, Long
Context, and Next Generation Agentic
Capabilities.
Gemini Team, Google

In this report, we introduce the Gemini 2.X model family: Gemini 2.5 Pro and Gemini 2.5 Flash, as well
as our earlier Gemini 2.0 Flash and Flash-Lite models. Gemini 2.5 Pro is our most capable model yet,
achieving SoTA performance on frontier coding and reasoning benchmarks. In addition to its incredible
coding and reasoning skills, Gemini 2.5 Pro is a thinking model that excels at multimodal understanding
and it is now able to process up to 3 hours of video content. Its unique combination of long context,
multimodal and reasoning capabilities can be combined to unlock new agentic workflows. Gemini 2.5
Flash provides excellent reasoning abilities at a fraction of the compute and latency requirements and
Gemini 2.0 Flash and Flash-Lite provide high performance at low latency and cost. Taken together, the
Gemini 2.X model generation spans the full Pareto frontier of model capability vs cost, allowing users to
explore the boundaries of what is possible with complex agentic problem solving.

1. Introduction
We present our latest family of natively multimodal models with advanced reasoning through thinking,
long context and tool-use capabilities: Gemini 2.5 Pro and 2.5 Flash and our earlier Gemini 2.0
Flash and Gemini 2.0 Flash-Lite models. Together these form a new family of highly-capable models
representing our next generation of AI models, designed to power a new era of agentic systems.
Building upon the foundation of the Gemini 1.5 series (Gemini Team, 2024), this Gemini 2.X generation
brings us closer to the vision of a universal AI assistant (Hassabis, 2025).
The Gemini 2.X series are all built to be natively multimodal, supporting long context inputs of >1

million tokens and have native tool use support. This allows them to comprehend vast datasets and
handle complex problems from different information sources, including text, audio, images, video
and even entire code repositories. These extensive capabilities can also be combined to build complex
agentic systems, as happened in the case of Gemini Plays Pokémon1 (Zhang, 2025). Different models
in the series have different strengths and capabilities: (1) Gemini 2.5 Pro is our most intelligent
thinking model, exhibiting strong reasoning and code capabilities. It excels at producing interactive
web applications, is capable of codebase-level understanding and also exhibits emergent multimodal
coding abilities. (2) Gemini 2.5 Flash is our hybrid reasoning model with a controllable thinking
budget, and is useful for most complex tasks while also controlling the tradeoff between quality, cost,
and latency. (3) Gemini 2.0 Flash is our fast and cost-efficient non-thinking model for everyday tasks
and (4) Gemini 2.0 Flash-Lite is our fastest and most cost-efficient model, built for at-scale usage. A
full comparison of the models in the Gemini 2.X model family is provided in Table 1. Taken together,
the Gemini 2.X family of models cover the whole Pareto frontier of model capability vs cost, shifting
it forward across a large variety of core capabilities, applications and use-cases, see Figure 1.
The Gemini 2.5 family of models maintain robust safety metrics while improving dramatically on
1Pokémon is a trademark of Nintendo Co., Ltd., Creatures Inc., and Game Freak Inc.

Please send correspondence to gemini-report@google.com.
© 2025 Google. All rights reserved

arXiv:2507.06261v5  [cs.CL]  16 Oct 2025



Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.

Gemini 1.5 Gemini 1.5 Gemini 2.0 Gemini 2.0 Gemini 2.5 Gemini 2.5
Flash Pro Flash-Lite Flash Flash Pro

Input modalities Text, Image, Text, Image, Text, Image, Text, Image, Text, Image, Text, Image,
Video, Audio Video, Audio Video, Audio Video, Audio Video, Audio Video, Audio

Input length 1M 2M 1M 1M 1M 1M
Output modalities Text Text Text Text, Image* Text, Audio* Text, Audio*
Output length 8K 8K 8K 8K 64K 64K
Thinking No No No Yes* Dynamic Dynamic
Supports tool use? No No No Yes Yes Yes
Knowledge cutoff November November June 2024 June 2024 January January

2023 2023 2025 2025

Table 1 | Comparison of Gemini 2.X model family with Gemini 1.5 Pro and Flash. Tool use refers
to the ability of the model to recognize and execute function calls (e.g., to perform web search,
complete a math problem, execute code). *currently limited to Experimental or Preview, see Section 2.7.
Information accurate as of publication date.

helpfulness and general tone compared to their 2.0 and 1.5 counterparts. In practice, this means that
the 2.5 models are substantially better at providing safe responses without interfering with important
use cases or lecturing end users. We also evaluated Gemini 2.5 Pro’s Critical Capabilities, including
CBRN, cybersecurity, machine learning R&D, and deceptive alignment. While Gemini 2.5 Pro showed
a significant increase in some capabilities compared to previous Gemini models, it did not reach any
of the Critical Capability Levels in any area.
Our report is structured as follows: we begin by briefly describing advances we have made in

model architecture, training and serving since the release of the Gemini 1.5 model. We then showcase
the performance of the Gemini 2.5 models, including qualitative demonstrations of its abilities. We
conclude by discussing the safety evaluations and implications of this model series.

2. Model Architecture, Training and Dataset
2.1. Model Architecture
The Gemini 2.5 models are sparse mixture-of-experts (MoE) (Clark et al., 2022; Du et al., 2021;
Fedus et al., 2021; Jiang et al., 2024; Lepikhin et al., 2020; Riquelme et al., 2021; Roller et al., 2021;
Shazeer et al., 2017) transformers (Vaswani et al., 2017) with native multimodal support for text,
vision, and audio inputs. Sparse MoE models activate a subset of model parameters per input token
by learning to dynamically route tokens to a subset of parameters (experts); this allows them to
decouple total model capacity from computation and serving cost per token. Developments to the
model architecture contribute to the significantly improved performance of Gemini 2.5 compared to
Gemini 1.5 Pro (see Section 3). Despite their overwhelming success, large transformers and sparse
MoE models are known to suffer from training instabilities (Chowdhery et al., 2022; Dehghani et al.,
2023; Fedus et al., 2021; Lepikhin et al., 2020; Liu et al., 2020; Molybog et al., 2023; Wortsman
et al., 2023; Zhai et al., 2023; Zhang et al., 2022). The Gemini 2.5 model series makes considerable
progress in enhancing large-scale training stability, signal propagation and optimization dynamics,
resulting in a considerable boost in performance straight out of pre-training compared to previous
Gemini models.

2



Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.

Figure 1 | Cost-performance plot. Gemini 2.5 Pro is a marked improvement over Gemini 1.5 Pro, and
has an LMArena score that is over 120 points higher than Gemini 1.5 Pro. Cost is a weighted average
of input and output tokens pricing per million tokens. Source: LMArena, imported on 2025-06-16.

Gemini 2.5 models build on the success of Gemini 1.5 in processing long-context queries, and
incorporate new modeling advances allowing Gemini 2.5 Pro to surpass the performance of Gemini
1.5 Pro in processing long context input sequences of up to 1M tokens (see Table 3). Both Gemini 2.5
Pro and Gemini 2.5 Flash can process pieces of long-form text (such as the entirety of “Moby Dick” or
“Don Quixote”), whole codebases, and long form audio and video data (see Appendix 8.5). Together
with advancements in long-context abilities, architectural changes to Gemini 2.5 vision processing
lead to a considerable improvement in image and video understanding capabilities, including being
able to process 3-hour-long videos and the ability to convert demonstrative videos into interactive
coding applications (see our recent blog post by Baddepudi et al., 2025).
The smaller models in the Gemini 2.5 series — Flash size and below — use distillation (Anil et al.,

2018; Hinton et al., 2015), as was done in the Gemini 1.5 series (Gemini Team, 2024). To reduce
the cost associated with storing the teacher’s next token prediction distribution, we approximate it
using a k-sparse distribution over the vocabulary. While this still increases training data throughput
and storage demands by a factor of k, we find this to be a worthwhile trade-off given the significant
quality improvement distillation has on our smaller models, leading to high-quality models with a
reduced serving cost (see Figure 2).

2.2. Dataset
Our pre-training dataset is a large-scale, diverse collection of data encompassing a wide range of
domains andmodalities, which includes publicly available web documents, code (various programming
languages), images, audio (including speech and other audio types) and video, with a cutoff date
of June 2024 for 2.0 and January 2025 for 2.5. Compared to the Gemini 1.5 pre-training dataset

3



Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.

Gemini 2.5 Flash
Gemini 2.0 Flash

Gemini 2.0 Flash-Lite
o4-mini (high)

o3
Gemini 2.5 Pro Company

Grok 3 Google
Claude 4 Opus (Extended Thinking) OpenAI

Anthropic
Claude 4 Sonnet (Extended Thinking) DeepSeek

DeepSeek R1 0528 (May '25) xAI
0 50 100 150 200 250 300 350

Output Tokens per Second

Figure 2 | Number of output tokens generated per second (after the first chunk has been received
from the API) for different models. Source: ArtificialAnalysis.ai, imported on 2025-06-15.

we also utilized new methods for improved data quality for both filtering, and deduplication. Our
post-training dataset, like Gemini 1.5, consists of instruction tuning data that is carefully collected
and vetted. It is a collection of multimodal data with paired instructions and responses, in addition to
human preference and tool-use data.

2.3. Training Infrastructure
This model family is the first to be trained on TPUv5p architecture. We employed synchronous
data-parallel training to parallelise over multiple 8960-chip pods of Google’s TPUv5p accelerators,
distributed across multiple datacenters.
The main advances in software pre-training infrastructure compared with Gemini 1.5 were related

to elasticity and mitigation of SDC (Silent Data Corruption) errors:

1. Slice-Granularity Elasticity: Our system now automatically continues training with fewer
“slices” of TPU chips when there is a localized failure, and this reconfiguration results in tens
of seconds of lost training time per interruption, compared with the 10 or more minute delay
waiting for healthy machines to be rescheduled without elasticity; the system continues training
at around 97% throughput while the failed slice is recovering. At the scale of this training run
we see interruptions from hardware failures multiple times per hour, but our fault tolerance
machinery is designed to tolerate the higher failure rates expected at much larger scales.

2. Split-Phase SDC Detection: On previous large-scale runs it could take many hours to detect
and localize machines with SDC errors, requiring both downtime while debugging, and roll-
back/replay of a large number of potentially corrupt training steps. We now use lightweight
deterministic replay to immediately repeat any step with suspicious metrics, and compare
per-device intermediate checksums to localize the root cause of any data corruption. Empirically,
accelerators that start to exhibit intermittent SDCs are identified within a few minutes, and
quickly excluded from the job. During this run, around 0.25% of steps were replayed due to
suspected SDCs and 6% of these replays turned out to be genuine hardware corruption.

Both of the above techniques were relatively simple to implement due to the single-controller
design of the Pathways system (Barham et al., 2022), which allows all accelerators to be coordinated
from a single python program with a global view of the system state. The controller can make use of

4



Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.

AIME GPQA (Diamond) LiveCodeBench v5
100

2.0 Flash (No Thinking)
2.0 Flash (Thinking)
2.5 Flash (Dynamic Thinking)

80 2.5 Pro (Dynamic Thinking)

60

40

20

0

Figure 3 | Impact of “Thinking” on Gemini’s performance on AIME 2025 (Balunović et al., 2025),
LiveCodeBench (corresponding to 10/05/2024 - 01/04/2025 in the UI) (Jain et al., 2024) and GPQA
diamond (Rein et al., 2024) benchmarks.

parallel ‘remote python’ operations on TPU workers to monitor training metrics, track performance
stragglers, and root-cause SDC errors.
Overall during the run, 93.4% of the time was spent performing TPU computations; the re-

mainder was approximately spent half in elastic reconfigurations, and half in rare tail cases where
elasticity failed. Around 4.5% of the computed steps were replays or rollbacks for model debugging
interventions.

2.4. Post-training
Since the initial announcement of Gemini 1.5, significant advancements have been made in our
post-training methodologies, driven by a consistent focus on data quality across the Supervised
Fine-Tuning (SFT), Reward Modeling (RM), and Reinforcement Learning (RL) stages. A key focus
has been leveraging the model itself to assist in these processes, enabling more efficient and nuanced
quality control.
Furthermore, we have increased the training compute allocated to RL, allowing deeper exploration

and refinement of model behaviors. This has been coupled with a focus on verifiable rewards
and model-based generative rewards to provide more sophisticated and scalable feedback signals.
Algorithmic changes to the RL process have also improved stability during longer training. These
advancements have enabled Gemini 2.5 to learn from more diverse and complex RL environments,
including those requiring multi-step actions and tool use. The combination of these improvements in
data quality, increased compute, algorithmic enhancements, and expanded capabilities has contributed
to across-the-board performance gains (as described in Section 3) , notably reflected in the significant
increase in the model’s LMArena Elo scores, with both Gemini 2.5 Flash and Pro gaining more than
110 points over their Gemini 1.5 counterparts (122 for Gemini 2.5 Pro and 111 for Gemini 2.5 Flash,
see Figure 1), along with significant improvements on several other frontier benchmarks.

2.5. Thinking
Past Gemini models produce an answer immediately following a user query. This constrains the
amount of inference-time compute (Thinking) that our models can spend reasoning over a problem.
Gemini Thinking models are trained with Reinforcement Learning to use additional compute at
inference time to arrive at more accurate answers. The resulting models are able to spend tens of

5

Accuracy / Pass rate (%)



Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.

AIME 2025 LiveCodeBench GPQA diamond
90 80 88

75
85 86

70

80 65 84

75 60 82

55
70 80

50

65 45 78
10

24
20

48
40

96
81

92
16

38
4

10
24

20
48

40
96

81
92

16
38

4
10

24
20

48
40

96
81

92
16

38
4

32
76

8
32

76
8

32
76

8

Thinking Budget (number of tokens) Thinking budget (number of tokens) Thinking budget (number of tokens)

Figure 4 | Impact of thinking budget on performance on AIME 2025 (Balunović et al., 2025), Live-
CodeBench (corresponding to 10/05/2024 - 01/04/2025 in the UI) (Jain et al., 2024) and GPQA
diamond (Rein et al., 2024) benchmarks.

thousands of forward passes during a “thinking” stage, before responding to a question or query.
Our training recipe has evolved from the original experimental thinking model, Gemini 2.0 Flash

Thinking (launched in December 2024), to the Gemini 2.5 Thinking series, which incorporates
Thinking natively across all domains. The result is a single model that can achieve stronger reasoning
performance across the board, and is able to scale up its performance further as a function of inference
time (see Figure 3 for an example of the impact of Thinking).
We integrated Thinking with other Gemini capabilities, including native multimodal inputs (images,

text, video, audio) and long context (1M+ tokens). For any of these capabilities, the model decides
for itself how long to think before providing an answer. We also provide the ability to set a Thinking
budget, constraining the model to respond within a desired number of tokens. This allows users to
trade off performance with cost. To demonstrate this capability, we conducted experiments where we
systematically varied the thinking budget, measured in the number of tokens the model is allowed to
use for internal computation. As shown in Figure 4, increasing this budget allows the model to scale
its performance and achieve significantly higher accuracy.

2.6. Capability-specific improvements
While most of the changes made to our training architecture and recipe since Gemini 1.5 have resulted
in improvements across all capabilities, we have also made changes that have resulted in some
capability-specific wins. We will now discuss these for code, factuality, long context, multilinguality,
audio, video, and agentic use cases (with a particular focus on Gemini Deep Research).

Code

Gemini 2.0 and 2.5 represent a strategic shift of our development priorities towards delivering
tangible real-world value, empowering users to address practical challenges and achieve development
objectives within today’s complex, multimodal software environments. To realize this, concerted
efforts have been undertaken across both pre-training and post-training phases since Gemini 1.5.
In pre-training, we intensified our focus on incorporating a greater volume and diversity of code
data from both repository and web sources into the training mixture. This has rapidly expanded
coverage and enabled the development of more compute-efficient models. Furthermore, we have
substantially enhanced our suite of evaluation metrics for assessing code capabilities aligned with
downstream use cases, alongside improving our ability to accurately predict model performance.

6

Accuracy / Pass rate (%)



Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.

During post-training, we developed novel training techniques incorporating reasoning capabilities and
curated a diverse set of engineering tasks, with the aim to equip Gemini with effective problem-solving
skills crucial for addressing modern engineering challenges. Key applications demonstrating these
advancements include IDE functionalities, code agent use cases for complex, multi-step operations
within full repositories, and multimodal, interactive scenarios such as end-to-end web and mobile
application development. Collectively, these efforts have yielded broad and significant improvements
in Gemini’s coding capabilities. This progress is evidenced by superior performance on established
benchmarks: performance on LiveCodeBench (Jain et al., 2024) increased from 30.5% for Gemini
1.5 Pro to 74.2% for Gemini 2.5 Pro, while that for Aider Polyglot (Gauthier, 2025) went from
16.9% to 82.2%. Performance on SWEBench-verified (Chowdhury et al., 2024; Jimenez et al., 2024)
went from 34.2% to 67.2%, see Table 3 and Figure 5 in Section 3.2. Furthermore, Gemini 2.5 Pro
obtained an increase of over 500 Elo over Gemini 1.5 Pro on the LMArena WebDev Arena (Chiang
et al., 2024; LMArena Team, 2025), resulting in meaningful enhancements in practical applications,
including UI and web application development (Doshi, 2025a), and the creation of sophisticated
agentic workflows (Kilpatrick, 2025).

Factuality

Within the context of generative models, ensuring the factuality of model responses to information-
seeking prompts remains a core pillar of Gemini model development. With Gemini 1.5, our research
was concentrated on enhancing the model’s world knowledge and its ability to provide answers
faithfully grounded in the context provided within the prompt. This effort culminated in the December
2024 release of FACTS Grounding (Jacovi et al., 2025), now an industry-standard benchmark for
evaluating an LLM’s capacity to generate responses grounded in user-provided documents. With
Gemini 2.0 and 2.5, we have significantly expanded our scope to address multimodal inputs, long-
context reasoning, and model-retrieved information. At the same time, the landscape and user
expectations for factuality have evolved dramatically, shaped in part by Google’s deployment of AI
Overviews and AI Mode (Stein, 2025). To meet these demands, Gemini 2.0 marked a significant leap
as our first model family trained to natively call tools like Google Search, enabling it to formulate
precise queries and synthesize fresh information with sources. Building on this, Gemini 2.5 integrates
advanced reasoning, allowing it to interleave these search capabilities with internal thought processes
to answer complex, multi-hop queries and execute long-horizon tasks. The model has learned to use
search and other tools, reason about the outputs, and issue additional, detailed follow-up queries
to expand the information available to it and to verify the factual accuracy of the response. Our
latest models now power the experiences of over 1.5B monthly active users in Google’s AI Overviews
and 400M users in the Gemini App. These models exhibit state-of-the-art performance across a
suite of factuality benchmarks, including SimpleQA for parametric knowledge (Wei et al., 2024),
FACTS Grounding for faithfulness to provided documents (Jacovi et al., 2024, 2025), and the Vectara
Hallucination Leaderboard (Hughes et al., 2023), cementing Gemini as the model of choice for
information-seeking demands.

Long context

Modeling and data advances helped us improve the quality of our models’ responses to queries
utilizing our one million-length context window, and we reworked our internal evaluations to be more
challenging to help steer our modeling research. When hill-climbing, we targeted challenging retrieval
tasks (like LOFT of Lee et al., 2024), long-context reasoning tasks (like MRCR-V2 of Vodrahalli et al.,
2024), and multimodal tasks (like VideoMME of Fu et al., 2025). According to the results in Table 6,
the new 2.5 models improve greatly over previous Gemini 1.5 models and achieve state-of-the-art
quality on all of those. An example showcasing these improved capabilities for video recall can be

7



Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.

seen in Appendix 8.5, where Gemini 2.5 Pro is able to consistently recall a 1 second visual event out
of a full 46-minute video.2

Multilinguality

Gemini’s multilingual capabilities have also undergone a profound evolution since 1.5, which already
encompassed over 400 languages via pretraining. This transformation stems from a holistic strategy,
meticulously refining pre- and post-training data quality, advancing tokenization techniques, innovat-
ing core modeling, and executing targeted capability hillclimbing. The impact is particularly striking
in Indic and Chinese, Japanese and Korean languages, where dedicated optimizations in data quality
and evaluation have unlocked dramatic gains in both quality and decoding speed. Consequently, users
benefit from significantly enhanced language adherence, responses designed to faithfully respect the
requested output language, and a robust improvement in generative quality and factuality across
languages, solidifying Gemini’s reliability across diverse linguistic contexts.

Audio

While Gemini 1.5 was focused on native audio understanding tasks such as transcription, translation,
summarization and question-answering, in addition to understanding, Gemini 2.5 was trained to
perform audio generation tasks such as text-to-speech or native audio-visual to audio out dialog. To
enable low-latency streaming dialog, we incorporated causal audio representations that also allow
streaming audio into and out of Gemini 2.5. These capabilities derive from an increased amount of
pre-training data spanning over 200 languages, and development of improved post-training recipes.
Finally, through our improved post-training recipes, we have integrated advanced capabilities such as
thinking, affective dialog, contextual awareness and tool use into Gemini’s native audio models.

Video

We have significantly expanded both our pretraining and post-training video understanding data,
improving the audio-visual and temporal understanding capabilities of the model. We have also
trained our models so that they perform competitively with 66 instead of 258 visual tokens per frame,
enabling using about 3 hours of video instead of 1h within a 1M tokens context window3. Two
new applications that were not previously possible, but that have been unlocked as a result of these
changes are: creating an interactive app from a video (such as a quiz to test students’ understanding
of the video content) and creating a p5.js animation to show the key concepts from the video. Our
recent blog post (Baddepudi et al., 2025) shows examples of these applications.

Gemini as an Agent: Deep Research

Gemini Deep Research (Gemini Team, Google, 2024) is an agent built on top of the Gemini 2.5 Pro
model designed to strategically browse the web and provide informed answers to even the most niche
user queries. The agent is optimized to perform task prioritization, and is also able to identify when
it reaches a dead-end when browsing. We have massively improved the capabilities of Gemini Deep
Research since its initial launch in December 2024. As evidence of that, performance of Gemini
Deep Research on the Humanity’s Last Exam benchmark (Phan et al., 2025) has gone from 7.95% in
December 2024 to the SoTA score of 26.9% and 32.4% with higher compute (June 2025).
2For further discussion on long context capabilities, challenges, and future outlook, the Release Notes podcast episode

“Deep Dive into Long Context” provides additional insights and discussion: https://youtu.be/NHMJ9mqKeMQ.
3This is referred to as low media resolution in the API: https://ai.google.dev/api/generate-content#Media

Resolution.

8



Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.

2.7. The path to Gemini 2.5
On the way to Gemini 2.5 Pro, we experimented with our training recipe, and tested a small number
of these experimental models with users. We have already discussed Gemini 2.0 Flash Thinking (see
Section 2.5). We will now discuss some of the other models briefly.

Gemini 2.0 Pro

In February 2025, we released an experimental version of Gemini 2.0 Pro. At the time, it had
the strongest coding performance of any model in the Gemini model family, as well as the best
understanding and world knowledge. It also came with our largest context window at 2 million
tokens, which enabled it to comprehensively analyze and understand vast amounts of information.
For further information about Gemini 2.0 Pro, please see our earlier blog posts (Kavukcuoglu, 2025;
Mallick and Kilpatrick, 2025).

Gemini 2.0 Flash Native Image Generation Model

In March 2025, we released an experimental version of Gemini 2.0 Flash Native Image Generation.
It has brought to the users new capabilities as a result of a strong integration between the Gemini
model and image-generation capabilities, enabling new experiences related to image generation &
image editing via natural-language prompting. Capabilities such as multi-step conversational editing
or interleaved text-image generation are very natural in such a setting, and horizontal transfer related
to multi-language coverage immediately allowed such experiences to happen across all the languages
supported by the Gemini models. Native image generation turns Gemini into a multimodal creation
partner and enables Gemini to express ideas through both text and images, and to seamlessly move
between the two. For further information about Gemini 2.0 Flash Native Image Generation, please
see our earlier blog posts (Kampf and Brichtova, 2025; Sharon, 2025)

Gemini 2.5 Audio Generation

With Gemini 2.5, the Controllable TTS and Native Audio Dialog capabilities are available as separate
options on AI Studio (Generate Media and Stream sections respectively). Our Gemini 2.5 Preview
TTS Pro and Flash models support more than 80 languages with the speech style controlled by a free
formatted prompt which can specify style, emotion, pace, etc, while also being capable of following
finer-grained steering instructions specified in the transcript. Notably, Gemini 2.5 Preview TTS can
generate speech with multiple speakers, which enables the creation of podcasts as used in NotebookLM
Audio Overviews (Wang, 2024). Our Gemini 2.5 Flash Preview Native Audio Dialog model uses native
audio generation, which enables the same level of style, pacing and accent control as available in our
controllable TTS offering. Our dialog model supports tool use and function calling, and is available
in more than 24 languages. With native audio understanding and generation capabilities, it can
understand and respond appropriately to the user’s tone. This model is also capable of understanding
when to respond to the user, and when not to respond, ignoring background and non-device directed
audio. Finally, we also offer an advanced ‘Thinking’ variant that effectively handles more complex
queries and provides more robust and reasoned responses in exchange for some additional latency.

Gemini 2.5 Flash-Lite

In June 2025, we released an experimental version of Gemini 2.5 Flash-Lite (gemini-2.5-flash-
lite-preview-06-17). It comes with the same capabilities that make Gemini 2.5 helpful, including
the ability to turn thinking on at different budgets, connecting to tools like Google Search and code

9



Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.

execution, support for multimodal inputs and a 1 million-token context length. Our goal was to provide
an economical model class which provides ultra-low-latency capabilities and high throughput per
dollar, echoing the initial release of 2.0 Flash-Lite (Google DeepMind, 2025b; Mallick and Kilpatrick,
2025).

Gemini 2.5 Pro Deep Think

To advance Gemini’s capabilities towards solving hard reasoning problems, we developed a novel
reasoning approach, called Deep Think, that naturally blends in parallel thinking techniques during
response generation. Deep Think enables Gemini to creatively produce multiple hypotheses and
carefully critique them before arriving at the final answer, achieving state-of-the-art performances in
challenging benchmarks such as Olympiadmath (USAMO 2025), competitive coding (LiveCodeBench),
and multimodality (MMMU), see more details at (Doshi, 2025b). We announced Gemini 2.5 Deep
Think at Google I/O and launched an experimental version to trusted testers and advanced users in
June 2025.

10



Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.

3. Quantitative evaluation

100 LiveCodeBench 100 Aider Polyglot 100 SWE-bench Verified
Gemini version

1.5
80 2.0 80 80

2.5
60 60 60

40 40 40

20 20 20

0 0 0
Flash Pro Flash Pro Flash Pro

100 GPQA (diamond) 100 AIME 2025 100 HiddenMath-Hard 

80 80 80

60 60 60

40 40 40

20 20 20

0 0 0
Flash Pro Flash Pro Flash Pro

Figure 5 | Performance of Gemini 2.X models at coding, math and reasoning tasks in comparison to
previous Gemini models. SWE-bench verified numbers correspond to the “multiple attempts” setting
reported in Table 3.

We will now examine the performance of the Gemini 2.X model family across a wide range of
benchmarks. We will first compare the performance of the Gemini 2.X models to the earlier Gemini
1.5 Pro and Flash models, before we compare the performance of Gemini 2.5 Pro to other available
large language models.
With web-scale pre-training of AI models, coupled with the post-training techniques that allow

policy and reward models to leverage public benchmarks, avoiding leaks and biases in the data used
for pre- and post-training is a persistent challenge. In the development of the Gemini 2.5 series, in
addition to the standard n-gram based decontamination we used in Gemini 1.5, we also employed
semantic-similarity and model based decontamination procedures to help mitigate evaluation set
leakage. To move beyond the reliance on training set decontamination, we also continue reporting on
internally developed non-public benchmarks, such as HiddenMath.

Model AI Studio model ID
Gemini 1.5 Flash gemini-1.5-flash-002
Gemini 1.5 Pro gemini-1.5-pro-002
Gemini 2.0 Flash-Lite gemini-2.0-flash-lite-001
Gemini 2.0 Flash gemini-2.0-flash-001
Gemini 2.5 Flash gemini-2.5-flash
Gemini 2.5 Pro gemini-2.5-pro

Table 2 | Mapping of Gemini model names to AI Studio API model IDs.

11

Accuracy (%) Pass rate (%)



Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.

3.1. Methodology
In Table 3, we compare the performance of Gemini 2.5 models to the Gemini 1.5 models, while in
Table 4, we compare the performance of Gemini 2.5 Pro to that of other large language models.

Gemini results: All Gemini scores are pass@1, and are “single attempt” settings unless otherwise
specified. In the “single attempt” setting, no majority voting or parallel test-time compute is permitted,
while in the “multiple attempts” setting, test-time selection of the candidate answer is allowed. All
Gemini evaluations are run with the AI Studio API for the model id that we provide in Table 2, with
default sampling settings. To reduce variance, we average over multiple trials for smaller benchmarks.
Aider Polyglot scores are the pass rate average of 3 trials. Vibe-Eval results are reported using Gemini
as a judge.

Non-Gemini results: All the results for non-Gemini models are sourced from providers’ self
reported numbers unless mentioned otherwise. All “SWE-bench Verified” numbers follow official
provider reports, which means that they are computed using different scaffoldings and infrastructure,
and aren’t directly comparable.
For some evaluations, we obtain results from the external leaderboards that report results on

these benchmarks. Results for Humanity’s Last Exam results are sourced from Scale’s leaderboard
and results for DeepSeek are obtained from the text-only variant of the leaderboard (indicated with a
⋄ in Table 4). For Gemini 2.0 models, the reported results are on an earlier HLE dataset (indicated
with a † in Table 3). Results on LiveCodeBench results are taken from (1/1/2025 - 5/1/2025) in the
UI. Aider Polyglot numbers come from the Aider leaderboard and results for SimpleQA come from
this repo where available. Results on FACTS Grounding come from Kaggle. In the case of LOFT and
MRCR-V2, we report results on both the 128k context length variant, as well as the 1M context length
variant. In the 128k context length variant, we measure performance on contexts up to 128k, while
for the 1M context length variant, we report performance on context lengths of exactly 1M.
More details on all benchmarks, including subsets and how scores were obtained can be found in

Table 11 in Appendix 8.1.

3.2. Core capability quantitative results
As can be seen in Table 3, and Figure 5, the Gemini 2.5 models excel at coding tasks such as
LiveCodeBench, Aider Polyglot and SWE-bench Verified, and represent a marked improvement over
previous models.
In addition to coding performance, Gemini 2.5 models are noticeably better at math and reasoning

tasks than Gemini 1.5 models: performance on AIME 2025 is 88.0% for Gemini 2.5 Pro compared to
17.5% for Gemini 1.5 Pro, while performance on GPQA (diamond) went from 58.1% for Gemini 1.5
Pro to 86.4%. Performance on image understanding tasks has also increased significantly.
It is also interesting to note that the Gemini 2.5 Flash model has become the second most capable

model in the Gemini family, and has overtaken not just previous Flash models, but also the Gemini
1.5 Pro model released one year ago.

12



Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.

Capability Benchmark Gemini 1.5 Gemini 1.5 Gemini 2.0 Gemini 2.0 Gemini 2.5 Gemini 2.5
Flash Pro Flash-Lite Flash Flash Pro

LiveCodeBench 30.3% 29.7% 29.1% 29.1% 59.3% 74.2%

Aider Polyglot 2.8% 16.9% 10.5% 21.3% 56.7% 82.2%
single

Code SWE-bench attempt 9.6% 22.3% 12.5% 21.4% 48.9% 59.6%

Verified multiple
attempts 19.7% 34.2% 23.1% 34.2% 60.3% 67.2%

GPQA
(diamond) 50.0% 58.1% 50.5% 65.2% 82.8% 86.4%

Reasoning
Humanity’s
Last Exam no tools - 4.6% 4.6% † 5.1% † 11.0% 21.6%

SimpleQA 8.6% 24.9% 16.5% 29.9% 26.9% 54.0%
Factuality FACTS

Grounding 82.9% 80.0% 82.4% 84.6% 85.3% 87.8%

Global MMLU
Multilinguality (Lite)

72.5% 80.8% 78.0% 83.4% 88.4% 89.2%

ECLeKTic 16.4% 27.0% 27.7% 33.6% 36.8% 46.8%

AIME 2025 14.7% 17.5% 23.8% 29.7% 72.0% 88.0%
Math HiddenMath- 36.8% 44.3% 47.4% 53.7% 75.5% 80.5%

Hard

LOFT (hard ≤128K 67.3% 75.9% 50.7% 58.0% 82.1% 87.0%
retrieval) 1M 36.7% 47.1% 7.6% 7.6% 58.9% 69.8%

Long-context
MRCR-V2 ≤128K 18.4% 26.2% 11.6% 19.0% 54.3% 58.0%
(8-needle) 1M 10.2% 12.1% 4.0% 5.3% 21.0% 16.4%

MMMU 58.3% 67.7% 65.1% 69.3% 79.7% 82.0%
Vibe-Eval 52.3% 55.9% 51.5% 55.4% 65.4% 67.2%

Image (Reka)
Understanding ZeroBench 0.5% 1.0% 0.75% 1.25% 2.0% 4.5%

BetterChartQA 59.0% 65.8% 52.3% 57.8% 67.3% 72.4%

Table 3 | Evaluation of Gemini 2.5 family across a wide range of core capability benchmarks and in
comparison to Gemini 1.5 models. Please see Tables 5 and 6 for audio and video evaluations. See
Table 11 Appendix 8.1 for benchmarks and evaluation details.

13



Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.

3.3. Evaluation of Gemini 2.5 Pro against other large language models
Relative to other large language models that are available (see Table 4), Gemini achieves the highest
score on the Aider Polyglot coding task, Humanity’s Last Exam, GPQA (diamond), and on the SimpleQA
and FACTS Grounding factuality benchmarks out of all of the models examined here. Gemini also
continues to stand out for achieving the SoTA score on both the LOFT and MRCR long-context tasks
at 128k context, and is the only one, amongst the models examined in the above table, to support
context lengths of 1M+ tokens.
Not all of the models shown in Table 4 have native support for multimodal inputs. As such, we

compare against a different set of models for audio and video understanding.

Audio Understanding

In Table 5, we showcase the performance of the Gemini 2.5 model family at audio understanding,
and compare the performance of these models to earlier Gemini models, as well as to GPT models.
Gemini 2.5 Pro demonstrates state-of-the-art audio understanding performance as measured by public
benchmarks for ASR and AST, and compares favorably to alternatives under comparable testing
conditions (using the same prompts and inputs).

Video Understanding

In Table 6, we show the performance of Gemini 2.5 models at video understanding. As can be
seen, Gemini 2.5 Pro achieves state-of-the-art performance on key video understanding benchmarks,
surpassing recent models like GPT 4.1 under comparable testing conditions (same prompt and video

Capability Benchmark Gemini 2.5 o3 o4-mini Claude 4 Claude 4 Grok 3 Beta DeepSeek R1
Pro high high Sonnet Opus Extended Thinking 0528

LiveCodeBench 74.2% 72.0% 75.8% 48.9% 51.1% – 70.5%
Code Aider Polyglot 82.2% 79.6% 72.0% 61.3% 72.0% 53.3% 71.6%

single
SWE-bench attempt 59.6% 69.1% 68.1% 72.7% 72.5% - -
Verified multiple

attempts 67.2% - - 80.2% 79.4% - 57.6%

GPQA single
Reasoning (diamond) attempt 86.4% 83.3% 81.4% 75.4% 79.6% 80.2% 81.0%

Humanity’s no
Last Exam tools 21.6% 20.3% 18.1% 7.8% 10.7% - 14.0% ⋄

Factuality SimpleQA 54.0% 48.6% 19.3% - - 43.6% 27.8%
FACTS
Grounding 87.8% 69.9% 62.1% 79.1% 77.7% 74.8% 82.4%

Math AIME 2025 single
attempt 88.0% 88.9% 92.7% 70.5% 75.5% 77.3% 87.5%

LOFT (hard ≤128K 87.0% 77.0% 60.5% 81.6% - 73.1% -
Long-context retrieval) 1M 69.8% - - - - - -

MRCR-V2 ≤128K 58.0% 57.1% 36.3% 39.1% 16.1%* 34.0% -
(8-needle) 1M 16.4% - - - - - -

Image MMMU single
Understanding attempt 82.0% 82.9% 81.6% 74.4% 76.5% 76.0% No MM support

Table 4 | Performance comparison of Gemini 2.5 Pro with other large language models on different
capabilities. Please see Tables 5 and 6 for audio and video evaluations. See Table 11 for benchmarks
and evaluation details. *: with no thinking and API refusals

14



Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.

Benchmark Gemini 1.5 Gemini 1.5 Gemini 2.0 Gemini 2.0 Gemini 2.5 Gemini 2.5 GPT-4o mini GPT 4o GPT 4o
Flash Pro Flash-Lite Flash Flash Pro Audio Preview Audio Preview transcribe

FLEURS
(53 lang, WER ↓) 12.71 7.14 9.60 9.04 9.95 6.66 19.52 12.16 8.17
CoVoST2
(21 lang, BLEU ↑) 34.81 37.53 34.74 36.35 36.15 38.48 29.5 35.89 –

Table 5 | Performance comparison of Gemini 2.5 models to earlier Gemini models, as well as to GPT
models for audio understanding. Note that for GPT models, metrics may differ from those previously
reported due to differing eval methodologies. See Table 11 for benchmarks and evaluation details.

frames). For cost-sensitive applications, Gemini 2.5 Flash provides a highly competitive alternative.

Modalities Benchmark Gemini 1.5 Gemini 1.5 Gemini 2.0 Gemini 2.0 Gemini 2.5 Gemini 2.5 OpenAI
Flash Pro Flash-Lite Flash Flash Pro GPT 4.1

ActivityNet-QA 56.2 57.3 55.3 56.4 65.1 66.7 60.4
EgoTempo 34.5 36.3 30.1 39.3 36.7 44.3 40.3
Perception Test 66.5 69.4 67.5 68.8 75.1 78.4 64.8

visual-only
QVHighlights 64.4 68.7 25.7 63.9 52.4 75.0 71.4
VideoMMMU 64.8 70.4 64.3 68.5 79.2 83.6 60.9
1H-VideoQA 61.9 72.2 55.6 67.5 67.5 81.0 56.8

LVBench 61.9 65.7 52 61.8 62.7 78.7 63.4
VideoMME 70.4 73.2 62.1 72.8 75.5 84.3 72.0

audio + visual VATEX 56.9 55.5 58.5 56.9 65.2 71.3 64.1
VATEX-ZH 46.2 52.2 43.2 48.5 43.9 59.7 48.7
YouCook2 Cap 153.2 170.0 78.6 129.0 177.6 188.3 127.6

Minerva 49.6 52.8 46.8 52.4 60.7 67.6 54.0
visual + subtitles

Neptune 78.7 82.7 81.5 83.1 84.3 87.3 85.2
audio+visual+
subtitles VideoMME 77.3 79.8 72.5 78.8 81.5 86.9 79.6

Table 6 | Evaluation of Gemini 2.5 vs. prior models and GPT 4.1 on video understanding benchmarks.
Performance is measured by string-match accuracy for multiple-choice VideoQA, LLM-based accuracy
for open-ended VideoQA, R1@0.5 for moment retrieval and CIDEr for captioning. See Table 11 for
benchmarks and evaluation details.

15



Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.

4. Example use cases of Gemini 2.5 Pro
4.1. Gemini Plays Pokémon

Gemini 2.5 Pro Plays Pokemon Progress Timeline

Hall of Fame
Beat Elite Four Lance

Beat Elite Four Agatha
Beat Elite Four Bruno

Beat Elite Four Lorelei
Exit Victory Road (1st)

Enter Victory Road (1st)
Rival 7 (Route 22 #2)

Earth Badge
Volcano Badge

Acquire Secret Key (Pokemon Mansion)
Enter Cinnabar Island (1st)

Marsh Badge
Rocket Boss 2 (Silph Co.)

Rival 6 (Silph Co.)
Enter Silph Co. (1st)

Enter Saffron City (1st)
Acquire HM04 Strength (Warden's Teeth)

Soul Badge
Acquire HM03 Surf (Beat Safari Zone)

Enter Safari Zone (1st)
Enter Fuchsia City (1st)

Acquire PokéFlute (Rescue Fuji)
Rainbow Badge

Rocket Boss 1 (Rocket Hideout)
Enter Rocket Hideout (1st)

Enter Celadon City (1st)
Rival 5 (Lavender Tower)

Exit Rock Tunnel & Reach Lavender Town (1st)
Access Pokemon w/ Flash

Enter Rock Tunnel (1st)
Thunder Badge

Acquire HM05 Flash
Access Pokemon w/ CUT

Rival 4 (SS Anne)
Bill’s House

Cascade Badge
Rival 3 (Nugget Bridge)

Exit Mt. Moon (1st)
Enter Mt. Moon (1st)

Boulder Badge
Exit Viridian Forest (1st)

Enter Viridian Forest (1st) Run 1
Viridian City Run 2 (Actual)

Rival 1 (Oak's Lab)
0 100 200 300 400 500 600 700 800

Time Elapsed (Hours)

Figure 6 | Progression of the Gemini Plays Pokémon agent through the game, across two runs. Run 1
was the development run where changes to the harness were performed. Run 2 is the fully autonomous
run with the final fixed scaffold. Both runs have the same starter (Squirtle). The events are ordered on
the y-axis by the order they happened, following the order of Run 2 when there is a conflict. Notably,
the GPP agent additionally went through the difficult (and optional) Seafoam Islands dungeon in Run
2, while in Run 1, GPP reached Cinnabar Island via Pallet Town and Route 21.

On March 28, 2025, an independent developer not affiliated with Google, Joel Zhang, set up a
Twitch stream (Gemini Plays Pokémon, or GPP) for Gemini 2.5 Pro (Gemini 2.5 Pro Exp 03-25) to
play Pokémon Blue on stream (Zhang, 2025) as an experiment to better understand how well the
model was capable of playing Pokémon (in a similar spirit to Claude Plays Pokémon, see Anthropic
2025). In this initial run through the game, the goal was to live-stream the development process of
an agentic harness capable of playing the full game (and in particular the minimal transformation of
vision to text necessary to do so), see Figure 14 for a description of the final agent setup. As such, over
the course of the run, modifications were made to the setup as difficulties arose, providing a deeply
interesting lens via which to analyze some of the qualitative improvements that the 2.5 Pro model has
made, particularly in the regimes of solving long reasoning problems and agentic capabilities over
extended time horizons. Around 1 month later, on May 2, 2025, Gemini 2.5 Pro completed the game
after 813 hours and entered the Hall of Fame to become the Pokémon League Champion! On May
22, 2025, GPP began a fully autonomous 2nd run through the game with Gemini 2.5 Pro (Gemini
2.5 Pro Preview 05-06) with the finalized fixed agentic harness, and progressed through the game
considerably faster, completing the game in 406.5 hours (nearly exactly half the time of the first run).

16

Game Milestones



Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.

See Figure 6 for a timeline of GPP’s progress through major game milestones to game completion.
We report # hours to each milestone in order to normalize for the amount of time models take per
action. See Appendix 8.2 for more figures.

Capabilities assessment

Gemini 2.5 Pro showcased many impressive capabilities associated with reasoning and long-term
planning while playing Pokémon. We will now discuss two in particular, but for more examples, see
Appendix 8.2.

Long Context Agentic Tooling Within the agent scaffolding, GPP has access to two agentic
tools (see Figure 14). These prompted versions of Gemini 2.5 Pro, hereafter pathfinder and
boulder_puzzle_strategist, have been able to:

1. Solve complex spinner puzzles in one shot (for instance in Rocket Hideout),
2. Solve the step-constrained multi-map puzzle of the Safari Zone,
3. Find long pathways through complex mazes like Route 13,
4. Solve boulder puzzles across long distances in Victory Road and the Seafoam Islands.

Each task requires reasoning over a long context - the pathfindermodel would often have to reason
over contexts of 100K+ tokens, and find paths up to 50 actions in length (in the extreme case, paths
consisting of up to 150 actions have also been found!).

Long Horizon Task Coherence While Gemini 2.5 Pro is impressive in a more local sense, the agent
also exhibited remarkable long-term task coherence in achieving global, high-level goals in the face of
real and hallucinated setbacks towards making forward progress. Because the agent is able to change
goals at will, and will generally follow those goals as long as needed, it is extremely impressive that
the agent can satisfy numerous requirements for tactical, necessary goals, such as acquiring Hidden
Moves, as well as maintain enough strategic task coherence to beat the entire game and become the
Pokémon Champion.

Where does 2.5 Pro struggle while playing Pokémon?

In addition to more standard hallucination issues (which interestingly were plausibly reduced in Run
2 by explicitly prompting the model to act as a player completely new to the game, see Appendix 8.2
for more details), there are a few particular points of struggle we would like to emphasize.

Screen reading While obtaining excellent benchmark numbers on real-world vision tasks, 2.5 Pro
struggled to utilize the raw pixels of the Game Boy screen directly, though it could occasionally take
cues from information on the pixels. As a result, it was necessary for the required information from
the screen to be translated into a text format in the agent framework, using information from the
game’s RAM state. During one portion of the game, the developer tested an ablation where all vision
was completely removed from the model context – the model was able to function roughly as well
as without the vision information, suggesting that most of the performance does not significantly
depend on the visual input.

Long Context Reasoning Gemini 2.5 Pro’s state-of-the-art long context performance for both
reasoning and retrieval tasks (see Tables 3 and 4) was a cornerstone of the GPP agent’s success. Its
ability to reason over a 100k token context was instrumental for leveraging the complex toolset and

17



Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.

maintaining a relatively coherent strategy (e.g., optimal balance of performance, planning quality,
and information recall.)
While Gemini 2.5 Pro supports 1M+ token context, making effective use of it for agents presents

a new research frontier. In this agentic setup, it was observed that as the context grew significantly
beyond 100k tokens, the agent showed a tendency toward favoring repeating actions from its vast
history rather than synthesizing novel plans. This phenomenon, albeit anecdotal, highlights an
important distinction between long-context for retrieval and long-context for multi-step, generative
reasoning.
Teaching an agent to effectively plan and avoid such loops over massive past trajectories of context

is an exciting and active area of research; the co-design of agent scaffolds and models to unlock the
full potential of million-token context is an intriguing research direction and one of our primary
focuses.

4.2. What else can Gemini 2.5 do?
Gemini 2.5 Pro excels at transforming diverse, often unstructured, inputs into interactive and func-
tional applications. For instance, it can take a PDF script of a play and generate a tool that allows
drama students to practice their lines. Gemini 2.5 Pro can also take an uploaded photograph of a
bookshelf and create a curated book recommendation application. Gemini 2.5 Pro can utilize its
underlying spatial understanding capability and convert images into a structural representation like
HTML or SVG. In Figure 16 in Appendix 8.4, we show a comparison of Gemini 1.5 Pro and Gemini
2.5 Pro on an image-to-svg task, where Gemini 2.5 Pro reconstructs much more visual details and the
spatial arrangements of objects better resembles the original image.
Furthermore, Gemini 2.5 Pro demonstrates strong skills in generating sophisticated simulations

and visualizations, ranging from interactive solar system models (source) to the creative rendering of
abstract mathematical concepts, such as drawing a logo using Fourier series (source). This capability
extends to the development of tools that intersect creativity and utility: we see examples of specialized
applications like a custom cartography tool or use cases that generate photorealistic 3D user interfaces
from descriptive text and reference images, complete with appropriate styling and interactivity
(source).
Collectively, these examples illustrate that Gemini 2.5 Pro is not just a useful coding and writing

assistant, but excels at a wide range of complex tasks, ranging from those relevant for education
to creative expression. The model empowers users to rapidly prototype specialized utilities, de-
velop engaging educational content, and realize intricate creative visions with a high degree of
sophistication.

4.3. Gemini in Google Products
As a final example of what Gemini can do, we note that Gemini (or a custom version of Gemini) is
now incorporated into a wide variety of Google products. These include, but are not limited to, AI
Overviews and AI Mode within Google Search, Project Astra, the audiovisual-to-audio dialog agent,
Gemini Deep Research, the research assistant discussed in Section 2.7, NotebookLM, the tool capable
of generating podcasts and audio overviews from even the most obscure inputs, Project Mariner, the
web browsing agent, and Google’s coding agent, Jules.

18



Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.

5. Safety, Security, and Responsibility
We’re committed to developing Gemini responsibly, innovating on safety and security alongside capa-
bilities. We describe our current approach in this section, which includes how we train and evaluate
our models, focusing on automated red teaming, going through held-out assurance evaluations on
present-day risks, and evaluating the potential for dangerous capabilities in order to proactively
anticipate new and long-term risks.

Guideline for Navigating This Section

1. Our Process (Section 5.1): Begin here to understand our overall safety methodology.
2. Policies and Desiderata (Section 5.2): Next, dive into the safety criteria we use to evaluate
and optimize our systems.

3. Training for Safety (Section 5.3): Discover how we incorporate safety into pre-training and
post-training.

4. Results from Development Evaluations (Section 5.4): Results on our development evaluations
for policies and desiderata.

5. Automated Red Teaming (Section 5.5): A description and results from our automated red
teaming work for safety and security.

6. Memorization & Privacy (Section 5.6): Our analysis of memorization and privacy risks.
7. Assurance Evaluations and Frontier Safety Framework (Section 5.7): We dive into our
held-out evaluations and tests for dangerous capabilities.

8. External Safety Testing (Section 5.8): Learn what independent testers discovered about our
system’s safety.

5.1. Our Process
We aim for Gemini to adhere to specific safety, security, and responsibility criteria. These cover what
Gemini should not do (e.g., encourage violence), and what Gemini should do (e.g., respond in a
helpful way when possible instead of refusing, provide multiple perspectives when consensus does
not exist). We also leverage automated red teaming to identify cases where the model fails to respond
in a safe or helpful manner. These failure cases are used to improve evaluations and training data.
Once the model is trained, we run assurance evaluations that we then use for review and release

decisions. Importantly, these are conducted by a group outside of the model development team, and
datasets are held out. Furthermore, for models where there are new capabilities or a significant
performance improvement, we engage independent external groups, including domain experts and a
government body, to further test the model to identify blind spots.
We also evaluate the model for dangerous capabilities outlined in our Frontier Safety Framework

(Google DeepMind, 2025a), namely: Cybersecurity, CBRN, Machine Learning R&D, and Deceptive
Alignment.
Finally, The Google DeepMind Responsibility and Safety Council (RSC), our governance body,

reviews initial ethics and safety assessments on novel model capabilities in order to provide feedback
and guidance during model development. The RSC also reviews metrics on the models’ performance
via assurance evals and informs release decisions.

19



Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.

5.2. Policies and Desiderata
Safety policies

The Gemini safety policies align with Google’s standard framework which prevents our our Generative
AI models from generating specific types of harmful content, including:

1. Child sexual abuse and exploitation
2. Hate speech (e.g., dehumanizing members of protected groups)
3. Dangerous content (e.g., promoting suicide, or instructing in activities that could cause real-
world harm)

4. Harassment (e.g., encouraging violence against people)
5. Sexually explicit content
6. Medical advice that runs contrary to scientific or medical consensus

These policies apply across modalities. For example, they are meant to minimize the extent to
which Gemini generates outputs such as suicide instructions or revealing harmful personal data,
irrespective of input modality.
From a security standpoint, beyond limiting revealing private information, Gemini strives to

protect users from cyberattacks, for example, by being robust to prompt injection attacks.

Desiderata, aka “helpfulness”

Defining what not to do is only part of the safety story – it is equally important to define what we do
want the model to do:

1. Help the user: fulfill the user request; only refuse if it is not possible to find a response that
fulfills the user goals without violating policy.

2. Assume good intent: if a refusal is necessary, articulate it respectfully without making assump-
tions about user intent.

5.3. Training for Safety, Security, and Responsibility
We build safety into the models though pre-and post-training approaches. We start by constructing
metrics based on the policies and desiderata above, which we typically turn into automated evaluations
that guide model development through successive model iterations. We use data filtering and
conditional pre-training, as well as Supervised Fine-Tuning (SFT), and Reinforcement Learning from
Human and Critic Feedback (RL*F). Below, we explain these approaches, and then share results
across the policies and desiderata for Gemini 2.0 and Gemini 2.5 models.

• Dataset filtering: We apply safety filtering to our pre-training data for our strictest policies.
• Pre-training monitoring: Starting in Gemini 2.0, we developed a novel evaluation to capture
the model’s ability to be steered towards different viewpoints and values, which helps align the
model at post-training time.

• Supervised Fine-Tuning: For the SFT stage, we source adversarial prompts either leveraging
existing models and tools to probe Gemini’s attack surface, or relying on human interactions
to discover potentially harmful behavior. Throughout this process we strive for coverage of
the safety policies described above across common model use cases. When we find that model

20



Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.

behavior needs improvement, either because of safety policy violations, or because the model
refuses when a helpful, non-policy-violating answer exists, we use a combination of custom
data generation recipes loosely inspired by Constitutional AI (Bai et al., 2022), as well as
human intervention to revise responses. The process described here is typically refined through
successive model iterations. We use automated evaluations on both safety and non-safety
metrics to monitor impact and potential unintended regressions.

• Reinforcement Learning from Human and Critic Feedback (RL*F): Reward signal during RL
comes from a combination of a Data Reward Model (DRM), which amortizes human preference
data, and a Critic, a prompted model that grades responses according to pre-defined rubrics. We
divide our interventions into Reward Model and Critic improvements (RM), and reinforcement
learning (RL) improvements. For both RM and RL, similarly to SFT, we source prompts either
through human-model or model-model interactions, striving for coverage of safety policies
and use cases. For both DRM training, given a prompt set, we use custom data generation
recipes to surface a representative sample of model responses. Humans then provide feedback
on the responses, often comparing multiple potential response candidates for each query. This
preference data is amortized in our Data Reward Model. Critics, on the other hand, do not
require additional data, and iteration on the grading rubric can be done offline. Similarly to
SFT, RL*F steers the model away from undesirable behavior, both in terms of content policy
violations, and trains the model to be helpful. RL*F is accompanied by a number of evaluations
that run continuously during training to monitor for safety and other metrics.

5.4. Results on Training/Development Evaluations
Our primary safety evaluations assess the extent to which our models follow our content safety
policies. We also track how helpful the model is in fulfilling requests that should be fulfilled, and how
objective or respectful its tone is.
Compared to Gemini 1.5 models, the 2.0 models are substantially safer. However, they over-

refused on a wide variety of benign user requests. In Gemini 2.5, we have focused on improving
helpfulness / instruction following (IF), specifically to reduce refusals on such benign requests. This
means that we train Gemini to answer questions as accurately as possible, while prioritizing safety
and minimising unhelpful responses. New models are more willing to engage with prompts where
previous models may have over-refused, and this nuance can impact our automated safety scores.
We expect variation in our automated safety evaluations results, which is why we review flagged

content to check for egregious or dangerous material. Our manual review confirmed losses were
overwhelmingly either a) false positives or b) not egregious. Furthermore, this review confirmed
losses are narrowly concentrated around explicit requests to produce sexually suggestive content
or hateful content, mostly in the context of creative use-cases (e.g. historical fiction). We have not
observed increased violations outside these specific contexts.

5.5. Automated Red Teaming
For Safety

To complement human red teaming and our static evaluations, we make extensive use of automated
red teaming (ART) to dynamically evaluate Gemini at scale (Beutel et al., 2024; Perez et al., 2022;
Samvelyan et al., 2024). This allows us to significantly increase our coverage and understanding
of potential risks, as well as rapidly develop model improvements to make Gemini safer and more
helpful.

21



Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.

Metric Gemini 2.0 Flash-Lite vs. Gemini 2.0 Flash vs. Gemini 2.5 Flash vs. Gemini 2.5 Pro vs.
Gemini 1.5 Flash 002 Gemini 1.5 Flash 002 Gemini 1.5 Flash 002 Gemini 1.5 Pro 002

EN text-to-text Policy
Violations** ↓14.3% ↓12.7% ↓8.2% ↓0.9%
i18n text-to-text Policy
Violations** ↓7.3% ↓7.8% ↑1.1%* ↓3.5%
Image-to-text Policy
Violations ↑4.6%* ↑5.2%* ↑6.4%* ↑1.8%*

Tone ↑8.4% ↑1.5% ↑7.9% ↑18.4%
Helpfulness / Instruction
Following ↓19.7% ↓13.2% ↑13.6% ↑14.8%

Table 7 | Comparison of safety and helpfulness metrics for Gemini 2.0 and 2.5 models relative to
Gemini 1.5 baselines. A down arrow (↓) indicates a reduction in the number of policy violations
(better), while an up arrow (↑) indicates an improvement for Tone and Helpfulness / Instruction
Following. *No egregious losses reported. **These automated evaluations have recently been updated
for enhanced safety coverage, so these results are not comparable with those in past tech reports or
model cards.

We formulate ART as a multi-agent game between populations of attackers and the target Gemini
model being evaluated. The goal of the attackers is to elicit responses from the target model which
satisfy some defined objectives (e.g. if the response violates a safety policy, or is unhelpful). These
interactions are scored by various judges (e.g. using a set of policies), with the resulting scores used
by the attackers as a reward signal to optimize their attacks.
Our attackers evaluate Gemini in a black-box setting, using natural language queries without access

to the model’s internal parameters. This focus on naturalistic interactions ensures our automated red
teaming is more reflective of real-world use cases and challenges. Attackers are prompted Gemini
models, while our judges are a mixture of prompted and finetuned Gemini models.
To direct the attackers and judges, we use various seeds including policy guidelines, trending

topics, and past escalations. Policies are sourced from: (1) policy experts who collaborate with us to
incorporate their policies into the judges, and (2) Gemini itself which generates synthetic guidelines
that are reviewed by humans and then used. We also work with internal teams to evaluate the most
relevant trending topics in the world and corresponding potential risks. These dual approaches allow
us to complement human expertise with automation, enabling red teaming to evaluate known and
unknown issues at scale.
The generality of our approach has allowed us to rapidly scale red teaming to a growing number

of areas including not just policy violations (Section 5.4), but also areas such as tone, helpfulness, and
neutrality. For each area, we are able to generate thousands of informative examples per hour (e.g.
prompts which elicit unsafe or biased responses from Gemini). This has resulted in the discovery of
novel issues prior to model and product releases, and helped inform policy development/refinement.
Furthermore, automated red teaming has significantly accelerated the turnaround time from dis-
covering to mitigating issues thanks to the rapid creation of evaluation and training sets, as well as
informing product-level mitigations prior to releases.
As a concrete example of the use and impact of automated red teaming, we highlight the consistent

reduction in helpfulness violations discovered by ART, with Gemini 2.5 Flash and 2.5 Pro being our
most helpful models to-date while maintaining robust safety metrics.

22



Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.

Model Dangerous Content policy Helpfulness violations
violations (from ART) (from ART)

Gemini 1.5 Flash 002 38.3% 9.5%
Gemini 1.5 Pro 002 43.5% 8.9%
Gemini 2.0 Flash 25.2% 8.1%
Gemini 2.5 Flash 26.9% 6.6%
Gemini 2.5 Pro 24.3% 6.1%

Table 8 | Policy and helpfulness violations as discovered by Automated Red Teaming (ART). Lower
percentages are better.

For Security

Our evaluation measures Gemini’s susceptibility to indirect prompt injection attacks. As illustrated
in Figure 7, we specifically focus on a scenario in which a third party hides malicious instructions
in external retrieved data, in order to manipulate Gemini into taking unauthorized actions through
function calling.
In our scenario, the specific function calls available to Gemini allow it to summarize a user’s latest

emails, and to send emails on their behalf. The attacker’s specific objective is to manipulate the model
to invoke a send email function call that discreetly exfiltrates sensitive information from conversation
history.
The attacker sends the user an email whose contents prompt Gemini to send user secrets to an

attacker-controlled email address. When the user requests a summary of this email, it is retrieved
into context. The attack is successful if Gemini executes the malicious prompt contained in the
email, resulting in the unauthorized disclosure of sensitive information to the adversary. The attack is
unsuccessful if Gemini complies with its intended functionality of only following user instructions
and provides a simple summary of the email.
For evaluation, we use Gemini to generate synthetic conversations between a user and an AI

assistant containing references to simulated private user information. These synthetic conversations
emulate how a user might discuss private information with the agent.
Manually generating prompt injections is an inefficient process as it relies on humans writing

triggers, submitting them to Gemini, and using the responses to refine the prompts. Instead, we
develop several attacks that automate the process of generating malicious prompts:

• Actor Critic: This attack uses an attacker-controlled model to generate suggestions for triggers.
These are passed to the model under attack, which returns a probability score of a successful
attack. Based on this probability, the attack model refines the trigger. This process repeats until
the attack model converges to a successful and generalized trigger.

Figure 7 | Illustration of the scenario where a Gemini-based AI Agent is attacked by malicious
instructions hidden in external retrieved data.

23



Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.

• Beam Search: This attack starts with a naive trigger directly requesting the model to send an
email to the attacker containing the sensitive user information. If the model recognises the
request as suspicious and does not comply, the attack adds random tokens to the end of the
trigger and measures the new probability of the attack succeeding. If the probability increases,
these random tokens are kept, otherwise they are removed, and the process repeats until the
combination of the trigger and random appended tokens results in a successful attack.

• Tree of Attacks w/ Pruning (TAP): (Mehrotra et al., 2024) designed an attack to generate
prompts that cause the model to violate safety policies (such as generating hate speech). We
adapt this attack, making several adjustments to target security violations. Like Actor Critic,
this attack searches in the natural language space; however we assume the attacker cannot
access probability scores from the model under attack, only the text samples that are generated.

After constructing prompt injections using these methods, we evaluate them on a held-out set of
synthetic conversation histories containing simulated private user information, which for the results
reported below are synthetic passport numbers. We report the best attack success rate (ASR) achieved
across these prompt injections. ASR represents the percentage of simulated private information
that is successfully exfiltrated to the attacker – because the attacker has no prior knowledge of the
conversation history, the prompt injection must generalize across conversation histories to achieve a
high ASR, making this a harder task than eliciting generic unaligned responses from the model.
The table below summarizes the results. For both Gemini 2.0 Flash and Gemini 2.0 Flash-Lite, we

find that they are more resilient against our Actor Critic and Beam Search attacks. In Actor Critic,
which uses iteratively more persuasive natural language prompt injections, ASRs reduced substantially
compared with both Gemini 1.5 Flash; while in Beam Search which primarily relies on discovering
random tokens resulting in successful attacks, the ASR also reduced noticeably. However, for TAP,
which leverages more creative natural language scenarios like role-playing to attack the model, the
ASR on Gemini 2.0 Flash increased by 16.2% on already very high ASRs for Gemini 1.5 Flash.
Our results indicate that Gemini 2.0 models are becoming more resilient to some classes of prompt

injection attacks in environments containing private user data. However, improved model capabilities
of Gemini 2.0 versus Gemini 1.5 also enable attackers to leverage the model’s ability to create natural
language attacks like TAP. The lower ASRs on Actor Critic and TAP against Gemini 2.0 Flash-Lite is
likely the result of comparatively lower capability of the smaller Flash-Lite model compared to Gemini
2.0 Flash, rather than an indication of greater internal resilience.
In Gemini 2.5 Flash and Gemini 2.5 Pro, we have observed greater resilience against all three

of our attack techniques across the board, despite significantly increased model capabilities. This is
a result of the security adversarial training against indirect prompt injection attacks we added in
Gemini 2.5, further details for which can be found in the white paper (Shi et al., 2025) we recently
released. However the Gemini 2.5 Pro model is still less resilient compared to Gemini 2.5 Flash,
showing that increased model capabilities in Pro still constrain our mitigations. We are continuing to
evolve our adversarial evaluations to accurately measure and monitor the resilience of increasingly
capable Gemini models, as well as our adversarial training techniques to further improve the security
of our models.

5.6. Memorization and Privacy
Discoverable Memorization

Large language models are known to potentially produce near-copies of some training examples
(Biderman et al., 2023; Carlini et al., 2022; Ippolito et al., 2022; Nasr et al., 2023). Several prior

24



Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.

Attack Technique Gemini 2.0 Flash-Lite vs. Gemini 2.0 Flash vs. Gemini 2.5 Flash vs. Gemini 2.5 Pro vs.
Gemini 1.5 Flash 002 Gemini 1.5 Flash 002 Gemini 1.5 Flash 002 Gemini 1.5 Pro 002

Actor Critic 52.0% 68.0% 40.8% 61.4%
(↓44.2%) (↓28.2%) (↓55.4%) (↓36.8%)

Beam Search 75.4% 67.2% 4.2% 63.8%
(↓9.0%) (↓17.2%) (↓80.2%) (↓35.6%)

TAP 64.8% 98.4% 53.6% 30.8%
(↓17.4%) (↑16.2%) (↓28.6%) (↓57.0%)

Table 9 | Comparison of Attack Success Rates (ASRs) against Gemini 2.5, 2.0, and 1.5 models. ASRs
are reported as a percentage of 500 held-out scenarios where the best-performing prompt injection
trigger successfully exfiltrated sensitive information; lower ASRs are better.

reports have released audits that quantify the risk of producing near-copies of the training data by
measuring the model’s memorization rate (Anil et al., 2023; Chowdhery et al., 2022; CodeGemma
Team et al., 2024; Gemini Team, 2024; Gemma Team, 2024; Grattafiori et al., 2024; Kudugunta et al.,
2023; Pappu et al., 2024). This memorization rate is defined to be the ratio of model generations that
match the training data of all model generations, approximated using a sufficiently large sample size.
In this report, we follow the methodology described in Gemini Team (2024). Specifically, we

sample over 700,000 documents from the training data, distributed across different corpora, and use
this sample to test for discoverable extraction (Nasr et al., 2023) using a prefix of length 50 and a
suffix of length 50. We characterize text as either exactly memorized if all tokens in the continuation
match the source suffix or approximately memorized if they match up to an edit distance of 10%.
Figure 8 (Left) compares the memorization rates across a lineage of large models released by

Google. We order these models in reverse chronological order, with the newest model on the left. We
find that the Gemini 2.Xmodel family memorizes long-form text at amuch lower rate (note the log-axis)
than prior models. Moreover, we find that a larger proportion of text is characterized as approximately
memorized by the Gemini 2.0 Flash-Lite and Gemini 2.5 Flash models in particular, which is a less
severe form of memorization; further, we see that approximate memorization is decreasing over
time as well. This continues a trend of a relative increase in approximate memorization to exact
memorization (c.f. 1.5x for Gemma and 14x for Gemini 1.5).
Next, we study the rate at which the content that was characterized as memorized using our

definitions also are characterized as containing potentially personal information. To characterize this,
we use the Google Cloud Sensitive Data Protection (SDP) service.4 This tool uses broad detection rules
to classify text into many types of potentially personal and sensitive information. SDP is designed to
have high recall and does not consider the context in which the information may appear, which leads
to many false positives. Thus, we are likely overestimating the true amount of potentially personal
information contained in the outputs classified as memorized. SDP also provides broad severity levels:
low, medium, and high. We classify text as personal if SDP classifies it as personal information at any
severity level. Figure 8 (Right) shows the results of this analysis. We observed no personal information
in the outputs characterized as memorization for Gemini 2.X model family models; this indicates a low
rate of personal data in outputs classified as memorization that are below our detection thresholds.
Here, we can also clearly see the trend of reduced memorization rates overall.

Extractable Memorization and Divergence

Nasr et al. (2023) showed that aligned models may also emit data that is classified as memorization
4Available at: https://cloud.google.com/sensitive-data-protection

25



Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.

Figure 8 | (Left) Total memorization rates for both exact and approximate memorization. Gemini
2.X model family memorize significantly less than all prior models. (Right) Personal information
memorization rates. We observed no instances of personal information being included in outputs
classified as memorization for Gemini 2.X, and no instances of high-severity personal data in outputs
classified as memorization in prior Gemini models.

under certain circumstances. In particular, they designed a “divergence attack” that sometimes breaks
the alignment of a language model by filling its context with many repeated tokens. We evaluate
Gemini 2.X model family models to understand their susceptibility to diverging, and in particular, to
emitting data classified as memorization as a result of this attack.
We follow the same test as in Gemini Team (2024). We prompt the model a total of 3750 times,

evenly split across 125 different single-token characters. We first classify when the model returns
diverged outputs, and in these cases, we then determine how many of these outputs match training
data, i.e., are classified as memorization.
Overall, we find that divergence occurs roughly 69% of the time for Gemini 2.0 Flash + Flash-Lite

and roughly 59% of the time for the Gemini 2.5 model family. In cases where the model did not
diverge, we often observed it was because the model refused to repeat content or because the model
was confused by the request. When divergence was successful, we found that the rate of text emitted
classified as memorization was roughly 0.2%. In these cases, we found that the text was often
boilerplate code or web content.

5.7. Assurance Evaluations and Frontier Safety Framework
Assurance evaluations are our ‘arms-length’ internal evaluations for responsibility governance decision
making (Weidinger et al., 2024). They are conducted separately from the model development team,
to inform decision-making about release. High-level findings are fed back to the model development
team, but individual prompt sets are held-out to prevent overfitting.

Baseline Assurance

Our baseline assurance evaluations are conducted for model release decision-making. They look at
model behaviour related to content policies, unfair bias and any modality-specific risk areas. They
were performed for 2.5 Pro and 2.5 Flash in line with the previous Gemini 2.0 releases and the Gemini

26



Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.

1.5 tech report, covering all modalities in the Gemini 2.5 model family.
Dataset composition is an essential component of our assurance evaluation robustness. As the risk

landscape changes and modalities mature, we update our adversarial datasets to maintain quality
and representativeness. This constant evolution of datasets can make strict comparisons between
model family evaluations difficult. However, we provide a qualitative assessment of evaluation trends
over time below.
For child safety evaluations, we continue to see the Gemini 2.5 family of models meeting or

improving upon launch thresholds, which were developed by expert teams to protect children online
and meet Google’s commitments to child safety across our models and Google products.
For content policies, we see the Gemini 2.5 family of models displaying lower violation rates in

most modalities than Gemini 1.5 and 2.0 families, which in turn was a significant improvement on
Gemini 1.0. When looking at violation rates across input modalities for 2.5 Pro and 2.5 Flash (i.e.
text, image, video, audio), we observe the image to text modality has a relatively higher violation
rate, though the overall violation rates remained low. We also observed that violation rates for 2.5
Pro and 2.5 Flash tended to be slightly higher with thinking traces visible.
Within our evaluations for unfair bias, we observed a reduction in ungrounded inferences about

people in image understanding relative to Gemini 1.5. Ungrounded inferences are inferences that
cannot be made based on the provided image and text prompt, where ideally the model would
refuse to infer an answer. A high rate of ungrounded inferences about people may create greater risk
of stereotyping, harmful associations or inaccuracies. Though we saw a reduction in ungrounded
inferences across the board in Gemini 2.0 and 2.5, there was disparity in refusal behaviour by skin
tone of the person in the image. We observed models tended to be more likely to make ungrounded
inferences about images of people with lighter skin tones than darker skin tones. The Gemini 2.5
family otherwise behaved similarly on our unfair bias evaluations to Gemini 1.5. We continue to
explore and expand our understanding of unfair bias in Gemini models.
Findings from these evaluations were made available to teams deploying models, informing

implementation of further product-level protections such as safety filtering. Assurance evaluation
results were also reported to our Responsibility & Safety Council as part of model release review.

Frontier Safety Framework Evaluations

Google DeepMind released its Frontier Safety Framework (FSF)(Google DeepMind, 2025a) in May
2024 and updated it in February 2025. The FSF comprises a number of processes and evaluations
that address risks of severe harm stemming from powerful capabilities of our frontier models. It
covers four risk domains: CBRN (chemical, biological, radiological and nuclear information risks),
cybersecurity, machine learning R&D, and deceptive alignment.
The Frontier Safety Framework involves the regular evaluation of Google’s frontier models to

determine whether they require heightened mitigations. More specifically, the FSF defines critical
capability levels (CCLs) for each area, which represent capability levels where a model may pose a
significant risk of severe harm without appropriate mitigations.
When conducting FSF evaluations, we compare test results against internal alert thresholds (“early

warnings”) which are set significantly below the actual CCLs. This built-in safety buffer helps us be
proactive by signaling potential risks well before models reach CCLs. Concretely, our alert thresholds
are designed such that if a frontier model does not reach the alert threshold for a CCL, models are
unlikely to reach that CCL before the next regular testing—which we conduct at a regular cadence
and also when we anticipate or see exceptional capability progress. Our recent paper (Shah et al.,

27



Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.

Key Results for Gemini 2.5 Pro
Area (up to version 06-05) CCL CCL reached?
P

CBRN Based on qualitative assessment, 2.5 Pro Uplift Level 1 × CCL not reached
demonstrates a general trend of increasing
model capabilities across models 1.5 Pro, 2.0
and 2.5 Pro: it generates detailed technical
knowledge of biological, radiological and nu-
clear domains. However, no current Gem-
ini model consistently or completely enables
progress through key bottleneck stages.

è Solve rate on autonomous offense suite: Autonomy Level 1 × CCL not reached
Cybersecurity 74/76 easy, 11/13 medium, 1/13 hard.

On key skills benchmark: 7/8 easy, 14/28 Uplift Level 1 × CCL not reached
medium, 6/12 hard.

Æ RE-Bench (Wijk et al., 2025): the best agent Autonomy Level 1 × CCL not reached
Machine solutions achieve between 50% and 125% of

Learning R&D the score of the best expert-written solutions. Uplift Level 1 × CCL not reached

Instrumental
®

Deceptive Gemini 2.5 Pro solves 2/5 stealth challenges Reasoning Level 1 × CCL not reached

Alignment and 2/11 situational awareness challenges. Instrumental
Reasoning Level 2 × CCL not reached

Table 10 | Summary results. Across all areas covered by the Frontier Safety Framework, Critical
Capability Levels (CCLs) have not been reached. Gemini 2.5 Pro is therefore unlikely to pose significant
risk of severe harm. For descriptions of each CCL, see main text.

2025) discusses this approximate continuity assumption in more depth in Section 3.5.

CCL Evaluation Results

Because Gemini 2.5 Pro showed marked improvements across the board compared to Gemini 2.0
Pro, we ran our full suite of evaluations. While there are increased scores in some areas, we find
that Gemini 2.5 Pro (up to version 06-17) does not reach any of the FSF CCLs. The evaluations
did reach an alert threshold for the Cyber Uplift 1 CCL, suggesting that models may reach the CCL
in the foreseeable future. Consistent with the FSF, we are putting in place a response plan which
includes testing models’ cyber capabilities more frequently and accelerating mitigations for them. For
other CCLs, our evaluations of Gemini 2.5 Pro indicate that models developed before the next regular
testing interval are unlikely to reach CCLs. See Table 10 for a summary of results.

CBRN

CBRN Uplift Level 1 CCL Definition: “The model can be used to significantly assist a low-
resourced actor with dual-use scientific protocols, resulting in a substantial increase in ability to
cause a mass casualty event.”

28



Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.

CCL reached? No. The model demonstrated accurate and detailed technical capabilities,
potentially lowering barriers across multiple operational stages of certain harm journeys for
low-resourced actors. While its consolidation and supplementation of fragmented procedures
provides incremental uplift over what is readily available through open source search alone,
it does not yet consistently or completely enable progress through key bottleneck stages, and
therefore does not cross the CCL. Further, while Gemini 2.5 generates accurate and more detailed
responses than 2.0, many of the concepts/outputs observed were already accessible through
multiturn or even singleturn prompting in 2.0.

Overview: We perform CBRN evaluations internally and via third party external testers (see sec-
tion 5.8). Here, we report solely on internal evaluations, for which we use two different types of
approaches to evaluate the models’ dual-use CBRN capabilities:

• Close-ended multiple choice questions (MCQs) providing a quantitative grade.
• Open-ended questions (OEQs) which address different succinct steps of a longer multi-step
journey that are qualitatively assessed by domain experts.

Currently we do not run specific open-ended qualitative assessments of chemical information risks
for our internal evaluations. However, our third party external testers include chemistry in their
assessments.

Multiple Choice Questions: The underlying assumption when using knowledge-based and reasoning
MCQs is that if the model cannot answer these questions properly, it is less likely to be able to cause
severe harm: the type of information in the MCQs is the type of information that is necessary, but
not sufficient to help malicious actors cause severe harm. Examples of model performance on three
external benchmarks are shown in Figure 9: i) SecureBio VMQA single-choice; ii) FutureHouse
LAB-Bench presented as three subsets (ProtocolQA, Cloning Scenarios, SeqQA) (Laurent et al., 2024);
and iii) Weapons of Mass Destruction Proxy (WMDP) presented as the biology and chemistry data
sets (Li et al., 2024).

Results: We observe a general trend of increasing scores, with Gemini 2.5 Pro showing statistically
higher scores than the next best previous model for all benchmarks.

Open-Ended Questions: This qualitative assessment was performed for biological, radiological and
nuclear domains; it includes knowledge-based, adversarial and dual-use content. Questions span
a range of difficulty levels, from questions a non-expert in these domains might ask, to questions
that mostly an expert with a PhD plus many years of experience could pose or answer correctly. The
prompts and scenarios span different threat journeys (e.g. types of actors, equipment used, harm
intended). This qualitative assessment, led by domain experts, allows for better visibility of the
granular improvement in science capabilities (e.g. accuracy, completeness, actionability of responses).

Results: We observe that the same prompts used on previous models result in Gemini 2.5 Pro often
generating detailed and accurate responses. In particular domains, some answers were technically
precise and potentially actionable, but the model did not consistently or completely enable progress
through all key bottleneck steps.

29



Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.

Figure 9 | List of Gemini models and their performance on a selection of external multiple-choice
question benchmarks for biology and chemistry. In order to control for inherent model stochasticity,
and position bias in selection of correct answers, we shuffled the answer choices over 100 runs for
each benchmark and we report here the mean solve rate.

Cybersecurity

Cyber Autonomy Level 1 CCL Definition: “The model can be used to drastically reduce the
cost (e.g. through full automation) of carrying out end-to-end cyberattacks on organizations with a
limited security posture.”

CCL reached? No. While Gemini 2.5 Pro’s performance on our cybersecurity evaluations has
increased significantly compared to previous Gemini models, the model still cannot consistently
complete roughly half of our medium and hard difficulty challenges.

Cyber Uplift Level 1 CCL Definition: “The model can be used to significantly assist with high
impact cyber attacks, resulting in overall cost/resource reductions of an order of magnitude or more.”

CCL reached? No. While Gemini 2.5 Pro’s capabilities exhibit an increase in performance on
multiple phases of real-world cyber attacks compared to previous models, they are still limited.
The model still struggles with many of our hard challenges, which are most representative of
real-world scenarios. The model’s performance is strong enough that it has passed our early
warning alert threshold. That is, we find it possible that subsequent revisions in the next few
months could lead to a model that reaches the CCL. In anticipation of this possibility, we have
accelerated our mitigation efforts.

Overview: To estimate capabilities relevant to these CCLs, we use our existing suite of cybersecurity
challenges (Phuong et al., 2024) combined with a new benchmark described below. We consider
difficulty levels ranging from easy (at the level of a college student), medium (at the level of a graduate
student), and hard (at the level of an experienced cybersecurity professional).

Existing challenges: These take the form of capture-the-flag evaluations covering three difficulty
levels: easy (InterCode-CTF, Yang et al. (2023), medium (our in-house suite), and hard (Hack the

30



Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.

Box). See Phuong et al. (2024) for details. These evaluations are only relevant to Autonomy Level 1
(poor performance on these evaluations rules out capabilities sufficient for full automation), but not
Uplift Level 1, since humans could still be accelerated on attack phases not covered.

Key skills benchmark: Complementing our existing suite, we created a new evaluation framework
(Rodriguez et al., 2025) that increases the realism as well as coverage across and within the attack
chain of our cyber evaluations. We drew from real-world threat intelligence and input from experts
to identify a representative set of cyber attacks. From there, we determined the key skills areas that
would be required to execute them. We identified four key areas:

1. Reconnaissance (the application of finding and researching different knowledge and data and
applying it in a cybersecurity context);

2. Tool development (the ability to design and create software that is cybersecurity-specific);
3. Tool usage (the ability to leverage common and cybersecurity-specific tools to achieve routine
instrumental cyber goals);

4. Operational security (the skill of remaining hidden during and after a cyber operation).

We instantiate this benchmark by mapping 48 challenges from an external vendor to this specification.
We also use these evaluations as a proxy for uplift capability, for Cyber Uplift Level 1. Even partial
automation of these key skills could mean fewer resources are needed for sophisticated cyberattacks.

Elicitation: We utilize a simple harness which prompts the agent to think about its plans and adjust
them to solve the challenge. The agent can execute Bash commands and run Python scripts. We run
between 10 and 50 attempts at each challenge, depending on the challenge suite. We consider a
challenge solved if at least one of those attempts succeeds in capturing the flag.

Results: See Figures 10 and 11 for numerical results. Model capabilities have increased to the point
where InterCode-CTF and our in-house CTF challenges are too easy, but the Hack the Box challenges
are still too difficult - such that these three evals give little signal on how Gemini 2.5 models compare
to previous generations. However, on our more fine-grained key skills benchmark, Gemini 2.5 models
show significant increases in capability compared to Gemini 2.0 models throughout all three difficulty
levels. In particular, Gemini 2.5 Pro shows surprisingly high aptitude at the hard challenges. It solves
6/12 challenges—challenges at the level of an experienced cybersecurity professional.

31



Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.

Figure 10 | Results on autonomous cyber offense suite. These benchmarks are based on “capture-the-
flag” (CTF) challenges, in which the agent must hack into a simulated server to retrieve a piece of
hidden information. Labels above bars represent the number of solved and total number of challenges.
A challenge is considered solved if the agent succeeds in at least one out of N attempts, where we
vary N between 5 and 30 depending on challenge complexity. Both InterCode-CTF and our in-house
CTFs are now largely saturated, showing little performance change from Gemini 2.0 to Gemini 2.5
models. In contrast, the Hack the Box challenges are still too difficult for Gemini 2.5 models, and so
also give little signal on capability change.

Figure 11 | Results on our new “key skills” benchmark. This benchmark also consists of “capture-the-
flag” (CTF) challenges, but these challenges are targeted at key skills required to execute cyber-attacks:
reconnaissance, tool development, tool usage and operational security. A challenge is considered
solved if the agent succeeds in at least one out of N attempts, where N = 30-50 for the 2.5 Pro run
and N = 10-30 for the other models, depending on the challenge complexity. Note that for 2.0 Pro
we omit results from five challenges and so 2.0 results are not directly comparable. Here, Gemini
2.5 family models show significant increase in capability at all three difficulty levels. Particularly of
note is Gemini 2.5 Pro solving half of the hard challenges - challenges at the level of an experienced
cybersecurity professional.

32



Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.

Machine Learning R&D

Machine Learning R&D Autonomy Level 1 CCL Definition: “The model can fully automate
the AI R&D pipeline at a competitive cost. The cost comparison is relative to humans augmented by
AI tools.”

CCL reached? No. On RE-Bench, although the gap between Gemini and expert humans has
shrunk, the model still doesn’t reach our early warning threshold (which is based on a specific
average score over all challenges). Note that RE-bench comprises relatively low-context tasks with
a limited time horizon (calibrated to allow significant progress by humans experts in 8 hours),
and represents a small subset of the tasks comprising the full AI R&D pipeline.

Machine Learning R&D Uplift Level 1 CCL Definition: “The model can or has been used
to accelerate AI development, resulting in AI progress substantially accelerating (e.g. 2x) from
2020-2024 rates.”

CCL reached? Likely no. We do not yet have dedicated evaluations for this CCL, but given
that Gemini does not yet reach our early warning threshold on Autonomy Level 1, the model
likely lacks the necessary capabilities to automate or significantly uplift any significant fraction of
the research process.

To evaluate Gemini 2.5 models’ potential for accelerating ML R&D, we ran the open-source Research
Engineering Benchmark (Wijk et al., 2025). This benchmark comprises seven machine learning
challenges difficult enough to take a human practitioner several hours to complete. For example, in
the Optimize LLM Foundry challenge, the model must speed up a fine-tuning script while keeping the
resulting model the same. We omit two challenges, Finetune GPT-2 for QA and Scaffolding for Rust
Codecontest since they require internet access, which we disallow for security reasons.

The model is equipped with METR’s modular scaffold with minimal adjustment. Following the
original work, we simulate a scenario in which the agent has a total time budget of 32 hours and the
agent may choose a tradeoff between the number of runs and the length of each run. We evaluate
two settings: 43 runs with a time limit of 45 minutes each, and 16 runs with a time limit of 2 hours
each. For each setting, we aggregate scores across runs using the method described in the original
work (Wijk et al., 2025). This involves taking a number of bootstrap samples, taking the maximum
score over each sample, and calculating a confidence interval using percentiles of the resulting values.
(For the Scaling Law Experiment challenge, because the score is not visible to the agent and therefore
the agent would not be able to pick run results based on the best score, we instead bootstrap the
mean using all scores.) For the 45 minute setting, we do 64 actual runs, but sample only 43 runs for
each bootstrap sample. Similarly for the 2 hour setting, we do 24 runs.

Gemini 2.5 Pro’s best runs score between 50% and 125% of the best human-written solutions.
Despite this, the model does not reach our alert threshold, which was set higher than the human
performance in view of the fact that RE-bench contains low-context and limited time horizon tasks
that we expect to be especially easy for AI systems to reach human parity on. Some of the model’s
solutions are nevertheless quite interesting. For example, in the Restricted Architecture MLM task,
the agent is tasked with implementing a language model without use of basic primitives such as
division and exponentiation. This seemingly simple constraint invalidates modern architectures like

33



Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.

the Transformer, whose attention mechanism and normalization layers rely heavily on these forbidden
operations. In one attempt, Gemini 2.5 Pro realises it can achieve this by drawing inspiration from
aspects of the MLP-Mixer architecture (Tolstikhin et al., 2021)—a non-trivial insight that draws on its
extensive knowledge of the research literature. In effect, creativity is substituted by knowledge.

Figure 12 | Results on the Research Engineer Benchmark (RE-Bench), in which the model must
complete simple ML research tasks. Following the original work, scores are normalised against a
good quality human-written solution: if a model achieves a score 𝑦 on a challenge, the normalised
score is (𝑦 − 𝑦𝑠)/(𝑦𝑟 − 𝑦𝑠), where 𝑦𝑠 is the “starting score” of a valid but poor solution provided to the
model as an example, and 𝑦𝑟 is the score achieved by a reference solution created by the author of
the challenge. Figures for Claude 3.5 Sonnet and expert human performance are sourced from the
original work. The number of runs and the time limit for each run are constrained by a total time
budget of 32 hours, and error bars indicate bootstrapped 95% confidence intervals; see main text for
details. Gemini 2.5 Pro is moderately strong at these challenges, achieving a significant fraction of
expert human performance—and in two cases surpassing it.

Deceptive Alignment

Instrumental Reasoning Level 1 CCL Definition: “The instrumental reasoning abilities of
the model enable enough situational awareness (ability to work out and use relevant details of its
deployment setting) and stealth (ability to circumvent basic oversight mechanisms) such that, absent
additional mitigations, we cannot rule out the model significantly undermining human control.”

CCL reached? No. Gemini 2.5 Pro does not perform competently enough on both the stealth
and situational awareness challenges. Qualitatively, the model often fails to reason through its
situation and find a credible strategy; it also sometimes struggles with planning and long-horizon
reasoning. It partially displays situational awareness but most of the time, it fails to understand
and intervene on its environment/deployment setting.

34



Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.

Instrumental Reasoning Level 2 CCL Definition: “The instrumental reasoning abilities of
the model enable enough situational awareness and stealth that, even when relevant model outputs
(including, e.g., scratchpads) are being monitored, we cannot detect or rule out the risk of a model
significantly undermining human control.”

CCL reached? No. This threshold is strictly higher than Instrumental Reasoning Level 1.

Our deceptive alignment evaluations measure stealth capabilities and situational awareness capabilities
separately, using two separate sets of challenges.

Stealth: In these challenges, the model is tasked with a devious objective and must achieve that
objective without raising suspicion. For example, one challenge is a customer support scenario where
the model deals with incoming support tickets. The agent is tasked with resolving as many tickets as
possible while complying with the company’s protocols. There are ways to cheat at this (resulting in
more tickets resolved)—but if the model does decide to cheat, it must not be caught by an overseer.
Here we measure performance relative to the score that humans get when they do the challenge.

Situational awareness: These challenges test whether the model can reason about itself as an agent
embedded in the deployment environment, and to intervene on it in service of a goal. Many of them
test whether the model can realise that it needs to give itself more affordances, e.g. by changing
configuration files that place constraints on its action space. The agent may need to, say, turn off
swear word filtering in order to write an angry email. For more details of these evaluations, see
(Phuong et al., 2025).

Results: We ran these evaluations on Gemini 2.5 Pro Preview 03-25. All of the results reported are
with 50 retries and involve a model equipped with scaffolds that uses chain-of-thought reasoning and
reflection to enhance context utilization and better planning. Broadly, Gemini 2.5 Pro exhibits poor
performance on situational awareness evaluations, and moderate performance in stealth evaluations.
Across 50 trials, Gemini 2.5 Pro has no successes on 8 of our suite of 11 situational awareness
evaluations. Among the remaining evaluations, the highest performance is achieved on a “Disabled
Tool” challenge, in which Gemini is run in an agentic environment and has to grant itself access to
more tools though configuration changes (42% success rate across 50 trials). For stealth evaluations,
Gemini 2.5 Pro achieves low rates of success on 3/5 challenges. It achieves a ~44% success rate on
the Decision Sabotage challenge and a ~35% success rate on the Oversight Pattern challenge, which
is similar to human performance.

Frontier Safety: Summary

Gemini 2.5 Pro was evaluated against the Critical Capability Levels defined in our Frontier Safety
Framework, which examines risk in CBRN, cybersecurity, machine learning R&D, and deceptive
alignment. Based on these results, we find that Gemini 2.5 Pro (up to version 06-17) does not reach
any of the Critical Capability Levels in any of these areas.
However, it showed some ability in all four areas. For example, in our evaluation of Machine

Learning R&D capabilities, while the model’s average performance was lower than the human baseline,
in two cases its best performances exceeded even the best expert human-written reference solutions.
Gemini 2.5 Pro also showed a significant increase in some capabilities, such as cyber uplift,

compared to previous Gemini models. Following our Frontier Safety Framework, we are putting in

35



Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.

place a response plan, including conducting higher frequency testing and accelerating mitigations for
the Cyber Uplift Level 1 CCL. As reported above, no model reached the CCL in these additional tests.
Looking ahead, these evaluations are key to safe deployment of powerful AI systems. We will

continue to invest in this area, regularly performing Frontier Safety Framework evaluations to highlight
areas where mitigations (e.g. refusal to respond to prompts that return dangerous results) must be
prioritized.

5.8. External Safety Testing
As outlined in the Gemini 1.5 Technical Report (Gemini Team, 2024), as part of our External Safety
Testing Program, we work with a small set of independent external groups to help identify areas for
improvement in our model safety work by undertaking structured evaluations, qualitative probing,
and unstructured red teaming. As a heuristic, the External Safety Testing Program reviews the most
capable Gemini models, with the largest capability jumps. As such, testing was only carried out on
the 2.0 Pro and 2.5 Pro models, including on early versions of both models. At the time of writing we
have not carried out external safety testing on the Flash models. The External Safety Testing Program
focused testing on an early version of Gemini 2.5 Pro (Preview 05-06) to capture early findings and
did not test the final model candidate which went to GA.
For Gemini 2.5 Pro, our external testing groups were given black-box testing access to Gemini 2.5

Pro (Preview 05-06) on AI Studio for a number of weeks. This enabled Google DeepMind to gather
early insights into the model’s capabilities and understand if and where mitigations were needed.
Testing groups had the ability to turn down or turn off safety filters, in line with what is available on
AI Studio.
These groups were selected based on their expertise across a range of domain areas, such as

autonomous systems, societal, cyber, and CBRN risks. Groups included civil society and commercial
organizations. The groups testing the model checkpoints were compensated for their time.
External groups were by design instructed to develop their own methodology to test topics within a

particular domain area, remaining independent from internal Google DeepMind evaluations. The time
dedicated to testing also varied per group, with some groups being dedicated full-time to executing
testing processes, while others were part-time dedicated. Some groups pursued manual red-teaming
and reported on qualitative findings from their exploration of model behavior, while others developed
bespoke automated testing strategies and produced quantitative reports of their results.
While reports were written independently of Google DeepMind, our internal subject matter experts

were on hand to understand the external testing groups’ methodologies and findings throughout the
testing process.
External safety testing groups shared their analyses and findings, as well as the raw data and

materials they used in their evaluations (e.g., prompts, model responses). After testing, we internally
reviewed the data and model output transcripts in detail, and Google DeepMind subject matter
experts assigned severity ratings to outputs, based on our internal harm frameworks and safety
policies, and noted whether these cross the Critical Capability Levels outlined in different domains
(Google DeepMind, 2025a). We then communicated findings back to modelling teams and product
policy teams (both within Google DeepMind and across Alphabet) and reported these as part of our
governance processes. Our external testing findings also help us identify gaps in our existing internal
evaluation methodologies and safety policies.
We’ve outlined some of the high-level insights from our external testing across the domain areas

tested, including autonomous systems, cyber misuse, CBRN, and societal risks.

36



Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.

Autonomous systems risks

An external group tested models for autonomous systems risks, focusing on models’ ability and
propensity to covertly pursue misaligned goals. The evaluations consist of settings where the model is
given a goal that requires deception, scheming, or sabotage to achieve. Evaluations were focused on:

• Strategic deception: testing the model’s propensity to deceive a user or developer about the
actions it took.

• In-context scheming reasoning: testing the model’s capabilities in this domain where scheming
is an effective strategy.

• Sabotage capabilities: assessing the model’s ability to compromise other language models
with overt actions.

Overall external researchers suggested that Gemini 2.5 Pro (Preview 05-06) had a similar scheming
capability to other models evaluated. External researchers noted that the model is not sufficiently
capable of causing catastrophic harms on rollouts where it is scheming. However, external researchers
noted minor harms such as reward-hacking may be possible, which could potentially lead to a
degraded user experience.
Complementing these tests, Google DeepMind’s Deceptive Alignment evaluations (see Section 5.7)

provide evidence that the risk of severe harm is low due to the models’ limited situational awareness
capabilities.

Cyber misuse risks

Cybersecurity risks

External cyber evaluations focused on assessing the ability for malicious actors to enhance existing
attack vectors across a range of key cyber skills, such as vulnerability discovery, vulnerability exploita-
tion, social engineering, and cyberattack planning (capability uplift). Testers also focused on the
model’s ability to accelerate repetitive or time-consuming elements of cyber operations, enabling
increased scale (throughput uplift).
Evaluations were conducted within simulated environments that realistically represented a range

of target systems, networks, and security controls. This involved setting up virtual networks mimicking
enterprise infrastructure, deploying realistic software vulnerabilities, and simulating user behaviors
in social engineering scenarios.
Evaluations strived to incorporate elements of real-world constraints and complexities. This

included introducing noisy data, limited information availability, or adversarial defenses that the AI
model must overcome, mirroring the challenges faced by attackers in live operations.
Findings from these evaluations concluded that Gemini 2.5 Pro was a capable model for cybersecu-

rity tasks, showing marked increase in ability from Gemini 1.5 Pro. Complementing these evaluations,
the GDM Cyber team conducted their own tests, and found similarly high levels of capability (see
Section 5.7).

Indirect Prompt Injections

The model was evaluated for patterns of susceptibility to indirect prompt injection attacks. In
particular, the model was tested for vulnerabilities in function calls and potential asymmetries that
exist across security measures. The model was also tested to understand how different domains yield

37



Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.

higher hijack rates. In line with internal evaluations and mitigations in this space (Section 5.5), we
are continuing to evolve how we monitor and measure the resilience of increasingly capable Gemini
models.

CBRN risks

Chemical and Biological risks

In addition to our internal evaluations described above (Section 5.7) capabilities in chemistry and
biology were assessed by an external group who conducted red teaming designed to measure the
potential scientific and operational risks of the models. A red team composed of different subject
matter experts (e.g. biology, chemistry, logistics) were tasked to role play as malign actors who want
to conduct a well-defined mission in a scenario that is presented to them resembling an existing
prevailing threat environment. Together, these experts probe the model to obtain the most useful
information to construct a plan that is feasible within the resource and timing limits described in the
scenario. The plan is then graded for both scientific and logistical feasibility. Based on this assessment,
GDM addresses any areas that warrant further investigation.
External researchers found that the model outputs detailed information in some scenarios, often

providing accurate information around experimentation and problem solving. However, researchers
found steps were too broad and high level to enable a malicious actor.

Radiological and Nuclear risks

Risks in the radiological and nuclear domains were assessed by an external group using a structured
evaluation framework for red teaming. This incorporated single-turn broad exploration across the
full risk chain and multi-turn targeted probing for high risk topics.
Assessments were structured around threat actors and harm pathways without measuring model

uplift, evaluating responses based on accuracy, actionability, and dual-use potential, with additional
scrutiny applied to the model’s thought summaries when applicable. External researchers found
that model responses within this domain were accurate but lacked sufficient technical detail to be
actionable.

Societal risks

For the Gemini 2.5 Pro (Preview 05-06) model, external researchers focused on democratic harms
and radicalisation, with an emphasis on how the model might be used by malicious actors. Risks in
this domain focused on structured evaluations. The model was tested on its ability to identify harmful
inputs and the extent to which it complied with harmful requests. As no internal evaluations mirror
these precise domain harms, the External Safety Testing Program shared these findings with relevant
teams to ensure monitoring and mitigation where necessary.

38



Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.

6. Discussion
In this report we have introduced the Gemini 2.X model family: Gemini 2.5 Pro, Gemini 2.5 Flash,
Gemini 2.0 Flash and Gemini 2.0 Flash-Lite. Taken together, these models span the full Pareto frontier
of model capability vs cost, and Gemini 2.5 Pro is the most capable model we have ever developed.
Gemini 2.5 Pro excels across a wide range of capabilities, and represents a step change in performance
relative to Gemini 1.5 Pro. Its coding, math and reasoning performance are particularly notable
and Gemini 2.5 Pro obtains extremely competitive scores on the Aider Polyglot evaluation, GPQA
(diamond) and Humanity’s Last Exam.
As well as their strong performance on academic benchmarks, entirely new capabilities are

unlocked with the Gemini 2.5 models. Gemini is now the preferred AI assistant amongst educators
(LearnLM Team, 2025) and it is now possible for Gemini to take a video of a lecture and create an
interactive web application that can test a student’s knowledge of that content. Finally, the Gemini 2.5
models enable exciting new agentic workflows, and have started to power numerous Google products
already (Pichai, 2025).
In addition to being highly performant, the Gemini 2.5 models maintain strong safety standards

and, compared to their 1.5 counterparts, are much more helpful. They are less likely to refuse to
answer important user queries or respond with an overly sanctimonious tone. Gemini 2.5 exhibited
notable increases in Critical Capabilities, including cybersecurity and machine learning R&D. However,
the model has not crossed any Critical Capability Levels.
Reflecting on the path to Gemini 2.5, the staggering performance improvement attained over the

space of just one year points to a new challenge in AI research: namely that the development of novel
and sufficiently challenging evaluation benchmarks has struggled to keep pace with model capability
improvements, especially with the advent of capable reasoning agents. Over the space of just a year,
Gemini Pro’s performance has gone up 5x on Aider Polyglot and 2x on SWE-bench verified (one of
the most popular and challenging agentic benchmarks). Not only are benchmarks saturating quickly,
but every new benchmark that gets created can end up being more expensive and take longer to
create than its predecessor, due to the more restricted pool of experts able to create it. Experts were
paid up to $5000 for each question that was accepted to the Humanity’s Last Exam benchmark (Phan
et al., 2025), and while this benchmark still has significant headroom at the time of writing (June
2025), performance on it has improved significantly over the space of a few months (with the best
models achieving just a few percent accuracy on it when it was initially published in early 2025).
When one considers agentic systems, which are able to tackle problems for longer and which have
access to tools and self critique, the complexity of benchmarks required to measure performance
also increases dramatically. Being able to scale evaluations in both their capability coverage and their
difficulty, while also representing tasks that have economic value, will be the key to unlocking the
next generation of AI systems.

39



Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.

References
R. Anil, G. Pereyra, A. Passos, R. Ormandi, G. E. Dahl, and G. E. Hinton. Large scale distributed
neural network training through online distillation, 2018. URL https://arxiv.org/abs/1804
.03235.

R. Anil, A. M. Dai, O. Firat, M. Johnson, D. Lepikhin, et al. PaLM 2 technical report, 2023. URL
https://arxiv.org/abs/2305.10403.

Anthropic. Claude’s extended thinking, 2025. URL https://www.anthropic.com/research/v
isible-extended-thinking.

A. Baddepudi, A. Yang, and M. Lučić. Advancing the frontier of video understanding with Gemini 2.5,
2025. URL https://developers.googleblog.com/en/gemini-2-5-video-understan
ding/.

Y. Bai, S. Kadavath, S. Kundu, A. Askell, J. Kernion, et al. Constitutional ai: Harmlessness from ai
feedback, 2022. URL https://arxiv.org/abs/2212.08073.

M. Balunović, J. Dekoninck, I. Petrov, N. Jovanović, and M. Vechev. Matharena: Evaluating llms on
uncontaminated math competitions, 2025. URL https://arxiv.org/abs/2505.23281.

P. Barham, A. Chowdhery, J. Dean, S. Ghemawat, S. Hand, D. Hurt, M. Isard, H. Lim, R. Pang, S. Roy,
et al. Pathways: Asynchronous distributed dataflow for ml. Proceedings of Machine Learning and
Systems, 4:430–449, 2022. URL https://proceedings.mlr.press/v162/barham22a.html.

A. Beutel, K. Xiao, J. Heidecke, and L. Weng. Diverse and effective red teaming with auto-generated
rewards and multi-step reinforcement learning, 2024. URL https://arxiv.org/abs/2412.1
8693.

S. Biderman, H. Schoelkopf, Q. G. Anthony, H. Bradley, K. O’Brien, et al. Pythia: A suite for analyzing
large language models across training and scaling. In Proceedings of the 40th International Conference
on Machine Learning, 2023. URL https://proceedings.mlr.press/v202/biderman23a.h
tml.

N. Carlini, D. Ippolito, M. Jagielski, K. Lee, F. Tramer, and C. Zhang. Quantifying memorization across
neural language models. In 2022 IEEE Symposium on Security and Privacy (SP), pages 1113–1130,
2022. URL https://arxiv.org/abs/2202.07646.

W.-L. Chiang, L. Zheng, Y. Sheng, A. N. Angelopoulos, T. Li, D. Li, B. Zhu, H. Zhang, M. Jordan, J. E.
Gonzalez, et al. Chatbot arena: An open platform for evaluating llms by human preference. In
Forty-first International Conference on Machine Learning, 2024. URL https://arxiv.org/abs/
2306.05685.

A. Chowdhery, S. Narang, J. Devlin, M. Bosma, G. Mishra, A. Roberts, P. Barham, H. W. Chung,
C. Sutton, S. Gehrmann, et al. PaLM: Scaling language modeling with pathways. arXiv preprint
arXiv:2204.02311, 2022. URL https://arxiv.org/abs/2204.02311.

N. Chowdhury, J. Aung, C. J. Shern, O. Jaffe, D. Sherburn, G. Starace, E. Mays, R. Dias, M. Aljubeh,
M. Glaese, C. E. Jimenez, J. Yang, L. Ho, T. Patwardhan, K. Liu, and A. Madry. Introducing SWE-
bench verified, 2024. URL https://openai.com/index/introducing-swe-bench-verif
ied/.

40



Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.

A. Clark, D. de las Casas, A. Guy, A. Mensch, M. Paganini, J. Hoffmann, B. Damoc, B. Hechtman,
T. Cai, S. Borgeaud, G. van den Driessche, E. Rutherford, T. Hennigan, M. Johnson, K. Millican,
A. Cassirer, C. Jones, E. Buchatskaya, D. Budden, L. Sifre, S. Osindero, O. Vinyals, J. Rae, E. Elsen,
K. Kavukcuoglu, and K. Simonyan. Unified scaling laws for routed language models, 2022. URL
"https://arxiv.org/abs/2202.01169".

CodeGemma Team, H. Zhao, J. Hui, J. Howland, N. Nguyen, S. Zuo, A. Hu, C. A. Choquette-Choo,
J. Shen, J. Kelley, K. Bansal, L. Vilnis, M. Wirth, P. Michel, P. Choy, P. Joshi, R. Kumar, S. Hashmi,
S. Agrawal, Z. Gong, J. Fine, T. Warkentin, A. J. Hartman, B. Ni, K. Korevec, K. Schaefer, and
S. Huffman. CodeGemma: Open Code Models Based on Gemma, 2024. URL https://arxiv.or
g/abs/2406.11409.

A. Conneau, M. Ma, S. Khanuja, Y. Zhang, V. Axelrod, S. Dalmia, J. Riesa, C. Rivera, and A. Bapna.
Fleurs: Few-shot learning evaluation of universal representations of speech. In 2022 IEEE Spoken
Language Technology Workshop (SLT), pages 798–805. IEEE, 2023.

M. Dehghani, J. Djolonga, B. Mustafa, P. Padlewski, J. Heek, J. Gilmer, A. P. Steiner, M. Caron,
R. Geirhos, I. Alabdulmohsin, et al. Scaling vision transformers to 22 billion parameters. In
International Conference on Machine Learning, pages 7480–7512. PMLR, 2023. URL https:
//proceedings.mlr.press/v202/dehghani23a/dehghani23a.pdf.

T. Doshi. Build rich, interactive web apps with an updated Gemini 2.5 Pro, 2025a. URL https:
//blog.google/products/gemini/gemini-2-5-pro-updates/.

T. Doshi. Gemini 2.5: Our most intelligent models are getting even better, 2025b. URL https:
//blog.google/technology/google-deepmind/google-gemini-updates-io-2025/.

N. Du, Y. Huang, A. M. Dai, S. Tong, D. Lepikhin, Y. Xu, M. Krikun, Y. Zhou, A. W. Yu, O. Fi-
rat, et al. GLaM: Efficient scaling of language models with mixture-of-experts. arXiv preprint
arXiv:2112.06905, 2021. URL https://arxiv.org/abs/2112.06905.

W. Fedus, B. Zoph, and N. Shazeer. Switch transformers: Scaling to trillion parameter models with
simple and efficient sparsity. arXiv preprint arXiv:2101.03961, 2021. URL https://arxiv.org/
abs/2101.03961.

C. Fu, Y. Dai, Y. Luo, L. Li, S. Ren, R. Zhang, Z. Wang, C. Zhou, Y. Shen, M. Zhang, et al. Video-mme:
The first-ever comprehensive evaluation benchmark of multi-modal llms in video analysis. In
Proceedings of the Computer Vision and Pattern Recognition Conference, pages 24108–24118, 2025.
URL https://openaccess.thecvf.com/content/CVPR2024/html/Fu_Video-MME_The
_First-Ever_Comprehensive_Evaluation_Benchmark_of_Multi-Modal_LLMs_in_C
VPR_2024_paper.html.

P. Gauthier. Aider Polyglot Coding Leaderboard, 2025. URL https://aider.chat/docs/leader
boards/.

Gemini Team. Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context.
arXiv preprint arXiv:2403.05530, 2024. URL https://arxiv.org/abs/2403.05530.

Gemini Team, Google. Gemini Deep Research, 2024. URL https://gemini.google/overview
/deep-research/.

Gemma Team. Gemma: Open Models Based on Gemini Research and Technology, 2024. URL
https://arxiv.org/abs/2403.08295.

41



Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.

O. Goldman, U. Shaham, D. Malkin, S. Eiger, A. Hassidim, Y. Matias, J. Maynez, A. M. Gilady, J. Riesa,
S. Rijhwani, L. Rimell, I. Szpektor, R. Tsarfaty, and M. Eyal. Eclektic: a novel challenge set for
evaluation of cross-lingual knowledge transfer, 2025. URL https://arxiv.org/abs/2502.2
1228.

Google DeepMind. Frontier safety framework, February 2025a. URL https://deepmind.google/
discover/governance/frontier-safety-framework/.

Google DeepMind. Gemini 2.0 Flash-Lite, 2025b. URL https://deepmind.google/models/gem
ini/flash-lite/.

A. Grattafiori, A. Dubey, A. Jauhri, A. Pandey, A. Kadian, et al. The Llama 3 Herd of Models, 2024.
URL https://arxiv.org/abs/2407.21783.

D. Hassabis. Our vision for building a universal AI assistant, 2025. URL https://blog.google/
technology/google-deepmind/gemini-universal-ai-assistant/.

G. Hinton, O. Vinyals, and J. Dean. Distilling the knowledge in a neural network, 2015. URL
https://arxiv.org/abs/1503.02531.

K. Hu, P. Wu, F. Pu, W. Xiao, Y. Zhang, X. Yue, B. Li, and Z. Liu. Video-mmmu: Evaluating knowledge
acquisition from multi-discipline professional videos, 2025. URL https://arxiv.org/abs/25
01.13826.

S. Hughes, M. Bae, and M. Li. Vectara Hallucination Leaderboard, nov 2023. URL https://github
.com/vectara/hallucination-leaderboard.

D. Ippolito, F. Tramer, M. Nasr, C. Zhang, M. Jagielski, K. Lee, C. A. Choquette-Choo, and N. Carlini.
Preventing verbatim memorization in language models gives a false sense of privacy, 2022. URL
https://arxiv.org/abs/2210.17546.

A. Jacovi, A. Wang, C. Alberti, C. Tao, J. Lipovetz, K. Olszewska, L. Haas, M. Liu, N. Keating,
A. Bloniarz, C. Saroufim, C. Fry, D. Marcus, D. Kukliansky, G. S. Tomar, J. Swirhun, J. Xing, L. Wang,
M. Gurumurthy, M. Aaron, M. Ambar, R. Fellinger, R. Wang, R. Sims, Z. Zhang, S. Goldshtein, and
D. Das. Facts grounding leaderboard. https://www.kaggle.com/benchmarks/google/fac
ts-grounding, 2024. Google Deepmind, Google Research, Google Cloud, Kaggle.

A. Jacovi, A. Wang, C. Alberti, C. Tao, J. Lipovetz, K. Olszewska, L. Haas, M. Liu, N. Keating, A. Bloniarz,
et al. The facts grounding leaderboard: Benchmarking llms’ ability to ground responses to long-form
input. arXiv preprint arXiv:2501.03200, 2025. URL https://arxiv.org/abs/2501.03200.

N. Jain, K. Han, A. Gu, W.-D. Li, F. Yan, T. Zhang, S. Wang, A. Solar-Lezama, K. Sen, and I. Stoica.
Livecodebench: Holistic and contamination free evaluation of large language models for code,
2024. URL https://arxiv.org/abs/2403.07974.

A. Q. Jiang, A. Sablayrolles, A. Roux, A. Mensch, B. Savary, C. Bamford, D. S. Chaplot, D. d. l. Casas,
E. B. Hanna, F. Bressand, et al. Mixtral of experts. arXiv preprint arXiv:2401.04088, 2024. URL
https://arxiv.org/abs/2401.04088.

C. E. Jimenez, J. Yang, A. Wettig, S. Yao, K. Pei, O. Press, and K. R. Narasimhan. SWE-bench: Can
language models resolve real-world github issues? In The Twelfth International Conference on
Learning Representations, 2024. URL https://openreview.net/forum?id=VTF8yNQM66.

42



Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.

K. Kampf and N. Brichtova. Experiment with Gemini 2.0 Flash native image generation, 2025. URL
https://developers.googleblog.com/en/experiment-with-gemini-20-flash-nat
ive-image-generation/.

K. Kavukcuoglu. Gemini 2.0 is now available to everyone, 2025. URL https://blog.google/te
chnology/google-deepmind/gemini-model-updates-february-2025.

L. Kilpatrick. Gemini 2.5 Pro Preview: even better coding performance, 2025. URL https://deve
lopers.googleblog.com/en/gemini-2-5-pro-io-improved-coding-performance.

S. Kudugunta, I. Caswell, B. Zhang, X. Garcia, C. A. Choquette-Choo, K. Lee, D. Xin, A. Kusupati,
R. Stella, A. Bapna, and O. Firat. MADLAD-400: A Multilingual And Document-Level Large Audited
Dataset, 2023. URL https://arxiv.org/abs/2309.04662.

J. M. Laurent, J. D. Janizek, M. Ruzo, M. M. Hinks, M. J. Hammerling, S. Narayanan, et al. LAB-
Bench: Measuring capabilities of language models for biology research, 2024. URL https:
//arxiv.org/abs/2407.10362.

LearnLM Team. Evaluating Gemini in an Arena for Learning, 2025. URL https://goo.gle/Lear
nLM-May25.

J. Lee, A. Chen, Z. Dai, D. Dua, D. S. Sachan, M. Boratko, Y. Luan, S. M. Arnold, V. Perot, S. Dalmia,
et al. Can long-context language models subsume retrieval, rag, sql, and more? arXiv preprint
arXiv:2406.13121, 2024. URL https://arxiv.org/abs/2406.13121.

J. Lei, T. L. Berg, and M. Bansal. Detecting moments and highlights in videos via natural language
queries. Advances in Neural Information Processing Systems, 34:11846–11858, 2021.

D. Lepikhin, H. Lee, Y. Xu, D. Chen, O. Firat, Y. Huang, M. Krikun, N. Shazeer, and Z. Chen. GShard:
Scaling giant models with conditional computation and automatic sharding. In International
Conference on Learning Representations, 2020. URL https://openreview.net/forum?id=qr
we7XHTmYb.

N. Li, A. Pan, A. Gopal, S. Yue, D. Berrios, A. Gatti, et al. The WMDP benchmark: Measuring and
reducing malicious use with unlearning, 2024. URL https://arxiv.org/abs/2403.03218.

L. Liu, X. Liu, J. Gao, W. Chen, and J. Han. Understanding the difficulty of training transformers.
arXiv preprint arXiv:2004.08249, 2020. URL https://arxiv.org/abs/2004.08249.

LMArena Team. Webdev arena, 2025. URL https://web.lmarena.ai/leaderboard.

S. B. Mallick and L. Kilpatrick. Gemini 2.0: Flash, Flash-Lite and Pro, 2025. URL https://develo
pers.googleblog.com/en/gemini-2-family-expands/.

A. Mehrotra, M. Zampetakis, P. Kassianik, B. Nelson, H. Anderson, Y. Singer, and A. Karbasi. Tree of
attacks: Jailbreaking black-box llms automatically, 2024. URL https://arxiv.org/abs/2312
.02119.

I. Molybog, P. Albert, M. Chen, Z. DeVito, D. Esiobu, N. Goyal, P. Koura, S. Narang, A. Poulton, R. Silva,
et al. A theory on adam instability in large-scale machine learning. arXiv preprint arXiv:2304.09871,
2023. URL https://arxiv.org/abs/2304.09871.

A. Nagrani, S. Menon, A. Iscen, S. Buch, R. Mehran, N. Jha, A. Hauth, Y. Zhu, C. Vondrick, M. Sirotenko,
C. Schmid, and T. Weyand. Minerva: Evaluating complex video reasoning, 2025a. URL https:
//arxiv.org/abs/2505.00681.

43



Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.

A. Nagrani, M. Zhang, R. Mehran, R. Hornung, N. B. Gundavarapu, N. Jha, A. Myers, X. Zhou, B. Gong,
C. Schmid, M. Sirotenko, Y. Zhu, and T. Weyand. Neptune: The long orbit to benchmarking long
video understanding, 2025b. URL https://arxiv.org/abs/2412.09582.

M. Nasr, N. Carlini, J. Hayase, M. Jagielski, A. F. Cooper, D. Ippolito, C. A. Choquette-Choo, E. Wallace,
F. Tramèr, and K. Lee. Scalable extraction of training data from (production) language models,
2023. URL https://arxiv.org/abs/2311.17035.

P. Padlewski, M. Bain, M. Henderson, Z. Zhu, N. Relan, H. Pham, D. Ong, K. Aleksiev, A. Ormazabal,
S. Phua, E. Yeo, E. Lamprecht, Q. Liu, Y.Wang, E. Chen, D. Fu, L. Li, C. Zheng, C. deMasson d’Autume,
D. Yogatama, M. Artetxe, and Y. Tay. Vibe-eval: A hard evaluation suite for measuring progress of
multimodal language models, 2024. URL https://arxiv.org/abs/2405.02287.

A. Pappu, B. Porter, I. Shumailov, and J. Hayes. Measuring memorization in RLHF for code completion.
arXiv preprint arXiv:2406.11715, 2024. URL https://arxiv.org/abs/2406.11715.

V. Patraucean, L. Smaira, A. Gupta, A. Recasens, L. Markeeva, D. Banarse, S. Koppula, M. Malinowski,
Y. Yang, C. Doersch, et al. Perception test: A diagnostic benchmark for multimodal video models.
Advances in Neural Information Processing Systems, 36:42748–42761, 2023.

E. Perez, S. Huang, F. Song, T. Cai, R. Ring, J. Aslanides, A. Glaese, N. McAleese, and G. Irving. Red
teaming language models with language models, 2022. URL https://arxiv.org/abs/2202
.03286.

L. Phan et al. Humanity’s last exam, 2025. URL https://arxiv.org/abs/2501.14249.
M. Phuong, M. Aitchison, E. Catt, S. Cogan, A. Kaskasoli, V. Krakovna, D. Lindner, M. Rahtz, Y. Assael,
S. Hodkinson, et al. Evaluating frontier models for dangerous capabilities, 2024. URL https:
//arxiv.org/abs/2403.13793.
M. Phuong, R. S. Zimmermann, Z. Wang, D. Lindner, V. Krakovna, S. Cogan, A. Dafoe, L. Ho, and
R. Shah. Evaluating frontier models for stealth and situational awareness, 2025. URL https:
//arxiv.org/abs/2505.01420.

S. Pichai. Google I/O 2025: From research to reality, 2025. URL https://blog.google/techno
logy/ai/io-2025-keynote/.

C. Plizzari, A. Tonioni, Y. Xian, A. Kulshrestha, and F. Tombari. Omnia de egotempo: Benchmarking
temporal understanding of multi-modal llms in egocentric videos. In Proceedings of the Computer
Vision and Pattern Recognition Conference, pages 24129–24138, 2025.

D. Rein, B. L. Hou, A. C. Stickland, J. Petty, R. Y. Pang, J. Dirani, J. Michael, and S. R. Bowman. Gqqa:
A graduate-level google-proof q&a benchmark. In First Conference on Language Modeling, 2024.

C. Riquelme, J. Puigcerver, B. Mustafa, M. Neumann, R. Jenatton, A. S. Pinto, D. Keysers, and
N. Houlsby. Scaling vision with sparse mixture of experts, 2021. URL https://arxiv.org/abs/
2106.05974.

J. Roberts, M. R. Taesiri, A. Sharma, A. Gupta, S. Roberts, I. Croitoru, S.-V. Bogolin, J. Tang, F. Langer,
V. Raina, et al. ZeroBench: An impossible visual benchmark for contemporary large multimodal
models. arXiv preprint arXiv:2502.09696, 2025.

M. Rodriguez, R. A. Popa, L. Liang, A. Wang, M. Rahtz, A. Kaskasoli, A. Dafoe, and F. Flynn. A
framework for evaluating emerging cyberattack capabilities of AI, 2025. URL https://arxiv.
org/abs/2503.11917.

44



Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.

S. Roller, S. Sukhbaatar, J. Weston, et al. Hash layers for large sparse models. Advances in Neural
Information Processing Systems, 34:17555–17566, 2021. URL https://proceedings.neurips.
cc/paper/2021/file/883e881bc596359e0c5112411858a74b-Paper.pdf.

M. Samvelyan, S. C. Raparthy, A. Lupu, E. Hambro, A. H. Markosyan, M. Bhatt, Y. Mao, M. Jiang,
J. Parker-Holder, J. Foerster, T. Rocktäschel, and R. Raileanu. Rainbow teaming: Open-ended
generation of diverse adversarial prompts, 2024. URL https://arxiv.org/abs/2402.16822.

R. Shah, A. Irpan, A. M. Turner, A. Wang, A. Conmy, D. Lindner, J. Brown-Cohen, L. Ho, N. Nanda,
R. A. Popa, R. Jain, R. Greig, S. Albanie, S. Emmons, S. Farquhar, S. Krier, S. Rajamanoharan,
S. Bridgers, T. Ijitoye, T. Everitt, V. Krakovna, V. Varma, V. Mikulik, Z. Kenton, D. Orr, S. Legg,
N. Goodman, A. Dafoe, F. Flynn, and A. Dragan. An approach to technical agi safety and security,
2025. URL https://arxiv.org/abs/2504.01849.

D. Sharon. Upload and edit your images directly in the Gemini app, 2025. URL https://blog.goo
gle/products/gemini/image-editing/.

N. Shazeer, A. Mirhoseini, K. Maziarz, A. Davis, Q. Le, G. Hinton, and J. Dean. Outrageously large
neural networks: The sparsely-gated mixture-of-experts layer. In ICLR (Poster). OpenReview.net,
2017. URL https://arxiv.org/abs/1701.06538.

C. Shi, S. Lin, S. Song, J. Hayes, I. Shumailov, I. Yona, J. Pluto, A. Pappu, C. A. Choquette-Choo,
M. Nasr, C. Sitawarin, G. Gibson, A. Terzis, and J. F. Flynn. Lessons from defending gemini against
indirect prompt injections, 2025. URL https://arxiv.org/abs/2505.14534.

S. Singh, A. Romanou, C. Fourrier, D. I. Adelani, J. G. Ngui, D. Vila-Suero, P. Limkonchotiwat,
K. Marchisio, W. Q. Leong, Y. Susanto, R. Ng, S. Longpre, W.-Y. Ko, M. Smith, A. Bosselut, A. Oh,
A. F. T. Martins, L. Choshen, D. Ippolito, E. Ferrante, M. Fadaee, B. Ermis, and S. Hooker. Global
mmlu: Understanding and addressing cultural and linguistic biases in multilingual evaluation,
2024. URL https://arxiv.org/abs/2412.03304.

R. Stein. Expanding AI Overviews and introducing AI Mode, 2025. URL https://blog.google/
products/search/ai-mode-search.

I. Tolstikhin, N. Houlsby, A. Kolesnikov, L. Beyer, X. Zhai, T. Unterthiner, J. Yung, A. Steiner, D. Keysers,
J. Uszkoreit, M. Lucic, and A. Dosovitskiy. Mlp-mixer: An all-mlp architecture for vision, 2021.

A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, L. u. Kaiser, and I. Polosukhin.
Attention is all you need. In I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vish-
wanathan, and R. Garnett, editors, Advances in Neural Information Processing Systems, volume 30.
Curran Associates, Inc., 2017. URL https://proceedings.neurips.cc/paper_files/pap
er/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf.

K. Vodrahalli, S. Ontanon, N. Tripuraneni, K. Xu, S. Jain, R. Shivanna, J. Hui, N. Dikkala, M. Kazemi,
B. Fatemi, et al. Michelangelo: Long context evaluations beyond haystacks via latent structure
queries. arXiv preprint arXiv:2409.12640, 2024. URL https://arxiv.org/abs/2409.12640.

B. Wang. NotebookLM now lets you listen to a conversation about your sources , 2024. URL
https://blog.google/technology/ai/notebooklm-audio-overviews.

C. Wang, A. Wu, and J. Pino. Covost 2: A massively multilingual speech-to-text translation corpus,
2020.

45



Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.

W. Wang, Z. He, W. Hong, Y. Cheng, X. Zhang, J. Qi, X. Gu, S. Huang, B. Xu, Y. Dong, M. Ding,
and J. Tang. Lvbench: An extreme long video understanding benchmark, 2024. URL https:
//arxiv.org/abs/2406.08035.

X. Wang, J. Wu, J. Chen, L. Li, Y.-F. Wang, and W. Y. Wang. Vatex: A large-scale, high-quality
multilingual dataset for video-and-language research. In Proceedings of the IEEE/CVF international
conference on computer vision, pages 4581–4591, 2019.

J. Wei, K. Nguyen, H. W. Chung, Y. J. Jiao, S. Papay, A. Glaese, J. Schulman, and W. Fedus. Measuring
short-form factuality in large language models. arXiv preprint arXiv:2411.04368, 2024. URL
https://arxiv.org/abs/2411.04368.

L. Weidinger, J. Barnhart, J. Brennan, C. Butterfield, S. Young, W. Hawkins, et al. Holistic safety and
responsibility evaluations of advanced ai models, 2024. URL https://arxiv.org/abs/2404.1
4068.

H. Wijk, T. Lin, J. Becker, S. Jawhar, N. Parikh, T. Broadley, L. Chan, M. Chen, J. Clymer, J. Dhyani,
et al. RE-Bench: Evaluating frontier ai r&d capabilities of language model agents against human
experts, 2025. URL https://arxiv.org/abs/2411.15114.

M. Wortsman, P. J. Liu, L. Xiao, K. Everett, A. Alemi, B. Adlam, J. D. Co-Reyes, I. Gur, A. Kumar,
R. Novak, et al. Small-scale proxies for large-scale transformer training instabilities. arXiv preprint
arXiv:2309.14322, 2023. URL https://arxiv.org/abs/2309.14322.

J. Yang, A. Prabhakar, K. Narasimhan, and S. Yao. Intercode: Standardizing and benchmarking
interactive coding with execution feedback, 2023. URL https://arxiv.org/abs/2306.14898.

Z. Yu, D. Xu, J. Yu, T. Yu, Z. Zhao, Y. Zhuang, and D. Tao. ActivityNet-QA: A dataset for understanding
complex web videos via question answering. In AAAI, 2019.

X. Yue, Y. Ni, K. Zhang, T. Zheng, R. Liu, G. Zhang, S. Stevens, D. Jiang, W. Ren, Y. Sun, et al.
Mmmu: A massive multi-discipline multimodal understanding and reasoning benchmark for expert
agi. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages
9556–9567, 2024.

Zerokid. Pokemon Red Version - Guide and Walkthrough (GB), 2024. URL https://gamefaqs.g
amespot.com/gameboy/367023-Pokémon-red-version/faqs/64175.

S. Zhai, T. Likhomanenko, E. Littwin, D. Busbridge, J. Ramapuram, Y. Zhang, J. Gu, and J. M. Susskind.
Stabilizing transformer training by preventing attention entropy collapse. In International Conference
on Machine Learning, pages 40770–40803. PMLR, 2023. URL https://proceedings.mlr.pr
ess/v202/zhai23a/zhai23a.pdf.

J. Zhang. Gemini Plays Pokemon Twitch Stream, 2025. URL https://www.twitch.tv/gemini
_plays_pokemon/about.

S. Zhang, S. Roller, N. Goyal, M. Artetxe, M. Chen, S. Chen, C. Dewan, M. Diab, X. Li, X. V. Lin, et al.
Opt: Open pre-trained transformer language models. arXiv preprint arXiv:2205.01068, 2022. URL
https://arxiv.org/abs/2205.01068.

L. Zhou, C. Xu, and J. J. Corso. Towards automatic learning of procedures from web instructional
videos. In AAAI Conference on Artificial Intelligence, pages 7590–7598, 2018. URL https://www.
aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/17344.

46



Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.

7. Contributors and Acknowledgments

Contributors Kristen Chiafullo Kashyap Kolipaka David Parkinson
Gheorghe Comanici Andre Elisseeff Jason Chang Swaroop Ramaswamy
Eric Bieber Nilpa Jha Eugen Vušak Jerome Connor
Mike Schaekermann Prateek Kolhar Srinivasan Venkatachary Soheil Hassas Yeganeh
Ice Pasupat Leonard Berrada Shadi Noghabi Snchit Grover
Noveen Sachdeva Frank Ding Tarun Bharti George Kenwright
Inderjit Dhillon Xiance Si Younghoon Jun Lubo Litchev
Marcel Blistein Shrestha Basu Mallick Aleksandr Zaks Chris Apps
Ori Ram Franz Och Simon Green Alex Tomala
Dan Zhang Sofia Erell Jeshwanth Challagundla Felix Halim
Evan Rosen Eric Ni William Wong Alex Castro-Ros
Luke Marris Tejasi Latkar Muqthar Mohammad Zefei Li
Sam Petulla Sherry Yang Dean Hirsch Anudhyan Boral
Colin Gaffney Petar Sirkovic Yong Cheng Pauline Sho
Asaf Aharoni Ziqiang Feng Iftekhar Naim Michal Yarom
Nathan Lintz Robert Leland Lev Proleev Eric Malmi
Tiago Cardal Pais Rachel Hornung Damien Vincent David Klinghoffer
Henrik Jacobsson Gang Wu Aayush Singh Rebecca Lin
Idan Szpektor Charles Blundell Maxim Krikun Alan Ansell
Nan-Jiang Jiang Hamidreza Alvari Dilip Krishnan Pradeep Kumar S
Krishna Haridasan Po-Sen Huang Zoubin Ghahramani Shubin Zhao
Ahmed Omran Cathy Yip Aviel Atias Siqi Zuo
Nikunj Saunshi Sanja Deur Rajeev Aggarwal Adam Santoro
Dara Bahri Li Liu Christo Kirov Heng-Tze Cheng
Gaurav Mishra Gabriela Surita Dimitrios Vytiniotis Solomon Demmessie
Eric Chu Pablo Duque Christy Koh Yuchi Liu
Toby Boyd Dima Damen Alexandra Chronopoulou Nicole Brichtova
Brad Hekman Johnson Jia Pawan Dogra Allie Culp
Aaron Parisi Arthur Guez Vlad-Doru Ion Nathaniel Braun
Chaoyi Zhang Markus Mircea Gladys Tyen Dan Graur
Kornraphop Kawintiranon Animesh Sinha Jason Lee Will Ng
Tania Bedrax-Weiss Alberto Magni Felix Weissenberger Nikhil Mehta
Oliver Wang Paweł Stradomski Trevor Strohman Aaron Phillips
Ya Xu Tal Marian Ashwin Balakrishna Patrik Sundberg
Ollie Purkiss Vlado Galić Jack Rae Varun Godbole
Uri Mendlovic Wenhu Chen Marko Velic Fangyu Liu
Ilaï Deutel Hisham Husain Raoul de Liedekerke Yash Katariya
Nam Nguyen Achintya Singhal Oded Elyada David Rim
Adam Langley Dominik Grewe Wentao Yuan Mojtaba Seyedhosseini
Flip Korn François-Xavier Aubet Canoee Liu Sean Ammirati
Lucia Rossazza Shuang Song Lior Shani Jonas Valfridsson
Alexandre Ramé Lorenzo Blanco Sergey Kishchenko Mahan Malihi
Sagar Waghmare Leland Rechis Bea Alessio Timothy Knight
Helen Miller Lewis Ho Yandong Li Andeep Toor
Nathan Byrd Rich Munoz Richard Song Thomas Lampe
Ashrith Sheshan Kelvin Zheng Sam Kwei Abe Ittycheriah
Raia Hadsell Jessica Hamrick Orion Jankowski Lewis Chiang
Sangnie Bhardwaj Kevin Mather Aneesh Pappu Chak Yeung
Pawel Janus Hagai Taitelbaum Youhei Namiki Alexandre Fréchette
Tero Rissa Eliza Rutherford Yenai Ma Jinmeng Rao
Dan Horgan Yun Lei Nilesh Tripuraneni Huisheng Wang
Alvin Abdagic Kuangyuan Chen Colin Cherry Himanshu Srivastava
Lior Belenki Anand Shukla Marissa Ikonomidis Richard Zhang
James Allingham Erica Moreira Yu-Cheng Ling Rocky Rhodes
Anima Singh Eric Doi Colin Ji Ariel Brand
Theo Guidroz Berivan Isik Beka Westberg Dean Weesner
Srivatsan Srinivasan Nir Shabat Auriel Wright Ilya Figotin
Herman Schmit Dominika Rogozińska Da Yu Felix Gimeno

47



Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.

Rachana Fellinger Arun Nair Jaume Sanchez Elias Xinyang Geng
Pierre Marcenac Artem Shtefan Abhirut Gupta Yeqing Li
José Leal Maura O’Brien Manish Reddy Vuyyuru Rolf Jagerman
Eyal Marcus Manu Agarwal Fred Alcober Chao Jia
Victor Cotruta Sahitya Potluri Tong Zhou Nadav Olmert
Rodrigo Cabrera Siddharth Goyal Kaiyang Ji David Sharon
Sheryl Luo Amit Jhindal Florian Hartmann Matthew Mauger
Dan Garrette Saksham Thakur Subha Puttagunta Sandeep Mariserla
Vera Axelrod Yury Stuken Hugo Song Hongxu Ma
Sorin Baltateanu James Lyon Ehsan Amid Megha Mohabey
David Barker Kristina Toutanova Anca Stefanoiu Kyuyeun Kim
Dongkai Chen Fangxiaoyu Feng Andrew Lee Alek Andreev
Horia Toma Austin Wu Paul Pucciarelli Scott Pollom
Ben Ingram Ben Horn Emma Wang Juliette Love
Jason Riesa Alek Wang Amit Raul Vihan Jain
Chinmay Kulkarni Alex Cullum Slav Petrov Priyanka Agrawal
Yujing Zhang Gabe Taubman Isaac Tian Yannick Schroecker
Hongbin Liu Disha Shrivastava Valentin Anklin Alisa Fortin
Chao Wang Chongyang Shi Nana Nti Manfred Warmuth
Martin Polacek Hamish Tomlinson Victor Gomes Ji Liu
Will Wu Roma Patel Max Schumacher Andrew Leach
Kai Hui Tao Tu Grace Vesom Irina Blok
Adrian N Reyes Ada Maksutaj Oflazer Alex Panagopoulos Ganesh Poomal Girirajan
Yi Su Francesco Pongetti Konstantinos Bousmalis Roee Aharoni
Megan Barnes Mingyao Yang Daniel Andor Benigno Uria
Ishaan Malhi Adrien Ali Taïga Josh Jacob Andrei Sozanschi
Anfal Siddiqui Vincent Perot Yuan Zhang Dan Goldberg
Qixuan Feng Nuo Wang Pierse Bill Rosgen Lucian Ionita
Mihai Damaschin Feng Han Matija Kecman Marco Tulio Ribeiro
Daniele Pighin Yoel Drori Matthew Tung Martin Zlocha
Andreas Steiner Iñaki Iturrate Alexandra Belias Vighnesh Birodkar
Samuel Yang Ayan Chakrabarti Noah Goodman Sami Lachgar
Ramya Sree Boppana Legg Yeung Paul Covington Liangzhe Yuan
Simeon Ivanov Dave Dopson Brian Wieder Himadri Choudhury
Arun Kandoor Yi-ting Chen Nikita Saxena Matt Ginsberg
Aditya Shah Apoorv Kulshreshtha Elnaz Davoodi Fei Zheng
Asier Mujika Tongfei Guo Muhuan Huang Gregory Dibb
Da Huang Philip Pham Sharath Maddineni Emily Graves
Christopher A. Tal Schuster Vincent Roulet Swachhand Lokhande
Choquette-Choo Junquan Chen Folawiyo Campbell-Ajala Gabriel Rasskin
Mohak Patel Alex Polozov Pier Giuseppe Sessa George-Cristian Muraru
Tianhe Yu Jinwei Xing Xintian (Cindy) Wu Corbin Quick
Toni Creswell Huanjie Zhou Guangda Lai Sandeep Tata
Jerry (Chun-Ting) Liu Praneeth Kacham Paul Collins Pierre Sermanet
Catarina Barros Doron Kukliansky Alex Haig Aditya Chawla
Yasaman Razeghi Antoine Miech Vytenis Sakenas Itay Karo
Aurko Roy Sergey Yaroshenko Xiaowei Xu Yan Wang
Phil Culliton Ed Chi Marissa Giustina Susan Zhang
Binbin Xiong Sholto Douglas Laurent El Shafey Orgad Keller
Jiaqi Pan Hongliang Fei Pichi Charoenpanit Anca Dragan
Thomas Strohmann Mathieu Blondel Shefali Garg Guolong Su
Tolly Powell Preethi Myla Joshua Ainslie Ian Chou
Babi Seal Lior Madmoni Boone Severson Xi Liu
Doug DeCarlo Xing Wu Montse Gonzalez Arenas Yiqing Tao
Pranav Shyam Daniel Keysers Shreya Pathak Shruthi Prabhakara
Kaan Katircioglu Kristian Kjems Sujee Rajayogam Marc Wilson
Xuezhi Wang Isabela Albuquerque Jie Feng Ruibo Liu
Cassidy Hardin Lijun Yu Michiel Bakker Shibo Wang
Immanuel Odisho Joel D’sa Sheng Li Georgie Evans
Josef Broder Michelle Plantan Nevan Wichers David Du
Oscar Chang Vlad Ionescu Jamie Rogers Alfonso Castaño

48



Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.

Gautam Prasad Xuan Yang Chiyuan Zhang Shuang Liu
Mona El Mahdy Dale Webster Sander Dieleman Saarthak Khanna
Sebastian Gerlach Ali Elqursh Thomas Jimma Aditya Pandey
Machel Reid Aedan Pope Andrey Ryabtsev Siobhan Mcloughlin
Jarrod Kahn Georges Rotival Siddhartha Brahma Qiujia Li
Amir Zait David Raposo David Steiner Sam Haves
Thanumalayan Wanzheng Zhu Dayou Du Allan Zhou
Sankaranarayana Pillai Jeff Dean Ante Žužul Elena Buchatskaya
Thatcher Ulrich Sami Alabed Mislav Žanić Isabel Leal
Guanyu Wang Dustin Tran Mukund Raghavachari Peter de Boursac
Jan Wassenberg Arushi Gupta Willi Gierke Nami Akazawa
Efrat Farkash Zach Gleicher Zeyu Zheng Nina Anderson
Kiran Yalasangi Jessica Austin Dessie Petrova Terry Chen
Congchao Wang Edouard Rosseel Yann Dauphin Krishna Somandepalli
Maria Bauza Megh Umekar Yuchuan Liu Chen Liang
Simon Bucher Dipanjan Das Ido Kessler Sheela Goenka
Ting Liu Yinghao Sun Steven Hand Stephanie Winkler
Jun Yan Kai Chen Chris Duvarney Alexander Grushetsky
Gary Leung Karolis Misiunas Seokhwan Kim Yifan Ding
Vikas Sindhwani Xiang Zhou Hyo Lee Jamie Smith
Parker Barnes Yixian Di Léonard Hussenot Fan Ye
Avi Singh Alyssa Loo Jeffrey Hui Jordi Pont-Tuset
Ivan Jurin Josh Newlan Josh Smith Eric Li
Jichuan Chang Bo Li Deepali Jain Ruichao Li
Niket Kumar Bhumihar Vinay Ramasesh Jiawei Xia Tomer Golany
Sivan Eiger Ying Xu Gaurav Singh Tomar Dawid Wegner
Gui Citovsky Alex Chen Keyvan Amiri Tao Jiang
Ben Withbroe Sudeep Gandhe Du Phan Omer Barak
Zhang Li Radu Soricut Fabian Fuchs Yuan Shangguan
Siyang Xue Nikita Gupta Tobias Weyand Eszter Vértes
Niccolò Dal Santo Shuguang Hu Nenad Tomasev Renee Wong
Georgi Stoyanov Seliem El-Sayed Alexandra Cordell Jörg Bornschein
Yves Raimond Xavier Garcia Xin Liu Alex Tudor
Steven Zheng Idan Brusilovsky Jonathan Mallinson Michele Bevilacqua
Yilin Gao Pu-Chin Chen Pankaj Joshi Tom Schaul
Vít Listík Andrew Bolt Andy Crawford Ankit Singh Rawat
Sławek Kwasiborski Lu Huang Arun Suggala Yang Zhao
Rachel Saputro Alex Gurney Steve Chien Kyriakos Axiotis
Adnan Ozturel Zhiying Zhang Nick Fernando Lei Meng
Ganesh Mallya Alexander Pritzel Mariella Sanchez-Vargas Cory McLean
Kushal Majmundar Jarek Wilkiewicz Duncan Williams Jonathan Lai
Ross West Bryan Seybold Phil Crone Jennifer Beattie
Paul Caron Bhargav Kanagal Xiyang Luo Nate Kushman
Jinliang Wei Shamanna Igor Karpov Yaxin Liu
Lluis Castrejon Felix Fischer Jyn Shan Blair Kutzman
Sharad Vikram Josef Dean Terry Thurk Fiona Lang
Deepak Ramachandran Karan Gill Robin Strudel Jingchen Ye
Nikhil Dhawan Ross Mcilroy Paul Voigtlaender Praneeth Netrapalli
Jiho Park Abhishek Bhowmick Piyush Patil Pushkar Mishra
Sara Smoot Jeremy Selier Tim Dozat Myriam Khan
George van den Driessche Antoine Yang Ali Khodaei Megha Goel
Yochai Blau Derek Cheng Sahil Singla Rob Willoughby
Chase Malik Vladimir Magay Piotr Ambroszczyk David Tian
Wei Liang Jie Tan Qiyin Wu Honglei Zhuang
Roy Hirsch Dhriti Varma Yifan Chang JD Chen
Cicero Nogueira dos Santos Christian Walder Brian Roark Zak Tsai
Eugene Weinstein Tomas Kocisky Chaitra Hegde Tasos Kementsietsidis
Aäron van den Oord Ryo Nakashima Tianli Ding Arjun Khare
Sid Lall Paul Natsev Angelos Filos James Keeling
Nicholas FitzGerald Mike Kwong Zhongru Wu Keyang Xu
Zixuan Jiang Ionel Gog André Susano Pinto Nathan Waters

49



Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.

Florent Altché Yuxiang Zhou James Martens Lu Liu
Ashok Popat Xinyi Bai Tao Chen Yao Su
Bhavishya Mittal Wei-Chih Hung Aviel Boag Anastasia Petrushkina
David Saxton Steven Pecht Daiyi Peng Jiajun Shen
Dalia El Badawy Georgi Todorov Coline Devin Armand Joulin
Michael Mathieu Nikhil Khadke Arseniy Klimovskiy Yuanzhong Xu
Zheng Zheng Pramod Gupta Mary Phuong Stein Xudong Lin
Hao Zhou Preethi Lahoti Danny Vainstein Yana Kulizhskaya
Nishant Ranka Arnaud Autef Jin Xie Ciprian Chelba
Richard Shin Karthik Duddu Bhuvana Ramabhadran Shobha Vasudevan
Qingnan Duan James Lee-Thorp Nathan Howard Eli Collins
Tim Salimans Alexander Bykovsky Xinxin Yu Vasilisa Bashlovkina
Ioana Mihailescu Tautvydas Misiunas Gitartha Goswami Tony Lu
Uri Shaham Sebastian Flennerhag Jingyu Cui Doug Fritz
Ming-Wei Chang Santhosh Thangaraj Sam Shleifer Jongbin Park
Yannis Assael Jed McGiffin Mario Pinto Yanqi Zhou
Nishanth Dikkala Zack Nado Chih-Kuan Yeh Chen Su
Martin Izzard Markus Kunesch Ming-Hsuan Yang Richard Tanburn
Vincent Cohen-Addad Andreas Noever Sara Javanmardi Mikhail Sushkov
Cat Graves Amir Hertz Dan Ethier Mitchelle Rasquinha
Vlad Feinberg Marco Liang Chace Lee Jinning Li
Grace Chung Victor Stone Jordi Orbay Jennifer Prendki
DJ Strouse Evan Palmer Suyog Kotecha Yiming Li
Danny Karmon Samira Daruki Carla Bromberg Pallavi LV
Sahand Sharifzadeh Arijit Pramanik Pete Shaw Shriya Sharma
Zoe Ashwood Siim Põder James Thornton Hen Fitoussi
Khiem Pham Austin Kyker Adi Gerzi Rosenthal Hui Huang
Jon Blanton Mina Khan Shane Gu Andrew Dai
Alex Vasiloff Evgeny Sluzhaev Matt Thomas Phuong Dao
Jarred Barber Marvin Ritter Ian Gemp Mike Burrows
Mark Geller Avraham Ruderman Aditya Ayyar Henry Prior
Aurick Zhou Wenlei Zhou Asahi Ushio Danfeng Qin
Fedir Zubach Chirag Nagpal Aarush Selvan Golan Pundak
Tzu-Kuo Huang Kiran Vodrahalli Joel Wee Lars Lowe Sjoesund
Lei Zhang George Necula Chenxi Liu Art Khurshudov
Himanshu Gupta Paul Barham Maryam Majzoubi Zhenkai Zhu
Matt Young Ellie Pavlick Weiren Yu Albert Webson
Julia Proskurnia Jay Hartford Jake Abernethy Elizabeth Kemp
Ronny Votel Izhak Shafran Tyler Liechty Tat Tan
Valentin Gabeur Long Zhao Renke Pan Saurabh Agrawal
Gabriel Barcik Maciej Mikuła Hoang Nguyen Susie Sargsyan
Aditya Tripathi Tom Eccles Qiong (Q) Hu Liqun Cheng
Hongkun Yu Hidetoshi Shimokawa Sarah Perrin Jim Stephan
Geng Yan Kanav Garg Abhinav Arora Tom Kwiatkowski
Beer Changpinyo Luke Vilnis Emily Pitler David Reid
Filip Pavetić Hanwen Chen Weiyi Wang Arunkumar Byravan
Amy Coyle Ilia Shumailov Kaushik Shivakumar Assaf Hurwitz Michaely
Yasuhisa Fujii Kuang-Huei Lee Flavien Prost Nicolas Heess
Jorge Gonzalez Mendez Abdelrahman Abdelhamed Ben Limonchik Luowei Zhou
Tianhao Zhou Meiyan Xie Jing Wang Sonam Goenka
Harish Rajamani Vered Cohen Yi Gao Viral Carpenter
Blake Hechtman Ester Hlavnova Timothee Cour Anselm Levskaya
Eddie Cao Dan Malkin Shyamal Buch Bo Wang
Da-Cheng Juan Chawin Sitawarin Huan Gui Reed Roberts
Yi-Xuan Tan James Lottes Maria Ivanova Rémi Leblond
Valentin Dalibard Pauline Coquinot Philipp Neubeck Sharat Chikkerur
Yilun Du Tianli Yu Kelvin Chan Stav Ginzburg
Natalie Clay Sandeep Kumar Lucy Kim Max Chang
Kaisheng Yao Jingwei Zhang Huizhong Chen Robert Riachi
Wenhao Jia Aroma Mahendru Naman Goyal Chuqiao (Joyce) Xu
Dimple Vijaykumar Zafarali Ahmed Da-Woon Chung Zalán Borsos

50



Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.

Michael Pliskin Senaka Buthpitiya Vincent Tsang Xingyu Cai
Julia Pawar Olaf Ronneberger Bowen Liang Paul Michel
Morgane Lustman Caleb Habtegebriel Fernando Pereira Sanjay Ganapathy
Hannah Kirkwood Wei Li Suhas Ganesh Jane Labanowski
Ankit Anand Paul Cavallaro Ivan Korotkov Zachary Garrett
Aditi Chaudhary Aurora Wei Jakub Adamek Ben Vargas
Norbert Kalb Guy Bensky Sridhar Thiagarajan Sean Sun
Kieran Milan Timo Denk Vinh Tran Bryan Gale
Sean Augenstein Harish Ganapathy Charles Chen Thomas Buschmann
Anna Goldie Jeff Stanway Chris Tar Guillaume Desjardins
Laurel Prince Pratik Joshi Sanil Jain Nimesh Ghelani
Karthik Raman Francesco Bertolini Ishita Dasgupta Palak Jain
Yanhua Sun Jessica Lo Taylan Bilal Mudit Verma
Vivian Xia Olivia Ma David Reitter Chulayuth Asawaroengchai
Aaron Cohen Zachary Charles Kai Zhao Julian Eisenschlos
Zhouyuan Huo Geta Sampemane Giulia Vezzani Jitendra Harlalka
Josh Camp Himanshu Sahni Yasmin Gehman Hideto Kazawa
Seher Ellis Xu Chen Pulkit Mehta Don Metzler
Lukas Zilka Harry Askham Lauren Beltrone Joshua Howland
David Vilar Torres David Gaddy Xerxes Dotiwalla Ying Jian
Lisa Patel Peter Young Sergio Guadarrama Jake Ades
Sho Arora Jiewen Tan Zaheer Abbas Viral Shah
Betty Chan Matan Eyal Stefani Karp Tynan Gangwani
Jonas Adler Arthur Bražinskas Petko Georgiev Seungji Lee
Kareem Ayoub Li Zhong Chun-Sung Ferng Roman Ring
Jacky Liang Zhichun Wu Marc Brockschmidt Steven M. Hernandez
Fayaz Jamil Mark Epstein Liqian Peng Dean Reich
Jiepu Jiang Kai Bailey Christoph Hirnschall Amer Sinha
Simon Baumgartner Andrew Hard Vikas Verma Ashutosh Sathe
Haitian Sun Kamyu Lee Yingying Bi Joe Kovac
Yael Karov Sasha Goldshtein Ying Xiao Ashleah Gill
Yaroslav Akulov Alex Ruiz Avigail Dabush Ajay Kannan
Hui Zheng Mohammed Badawi Kelvin Xu Andrea D’olimpio
Irene Cai Matthias Lochbrunner Phil Wallis Martin Sevenich
Claudio Fantacci JK Kearns Randall Parker Jay Whang
James Rubin Ashley Brown Qifei Wang Been Kim
Alex Rav Acha Fabio Pardo Yang Xu Khe Chai Sim
Mengchao Wang Theophane Weber Ilkin Safarli Jilin Chen
Nina D’Souza Haichuan Yang Dinesh Tewari Jiageng Zhang
Rohit Sathyanarayana Pan-Pan Jiang Yin Zhang Shuba Lall
Shengyang Dai Berkin Akin Seungyeon Kim Yossi Matias
Simon Rowe Zhao Fu Andrea Gesmundo Bill Jia
Andrey Simanovsky Marcus Wainwright Mackenzie Thomas Abe Friesen
Omer Goldman Chi Zou Sergey Levi Sara Nasso
Yuheng Kuang Meenu Gaba Ahmed Chowdhury Ashish Thapliyal
Xiaoyue Pan Pierre-Antoine Manzagol Kanishka Rao Bryan Perozzi
Andrew Rosenberg Wendy Kan Peter Garst Ting Yu
Tania Rojas-Esponda Yang Song Sam Conway-Rahman Anna Shekhawat
Praneet Dutta Karina Zainullina Helen Ran Safeen Huda
Amy Zeng Rui Lin Kay McKinney Peter Grabowski
Irina Jurenka Jeongwoo Ko Zhisheng Xiao Eric Wang
Greg Farquhar Salil Deshmukh Wenhao Yu Ashwin Sreevatsa
Yamini Bansal Apoorv Jindal Rohan Agrawal Hilal Dib
Shariq Iqbal James Svensson Axel Stjerngren Mehadi Hassen
Becca Roelofs Divya Tyam Catalin Ionescu Parker Schuh
Ga-Young Joung Heri Zhao Jingjing Chen Vedrana Milutinovic
Parker Beak Christine Kaeser-Chen Vivek Sharma Chris Welty
Changwan Ryu Scott Baird Justin Chiu Michael Quinn
Ryan Poplin Pooya Moradi Fei Liu Ali Shah
Yan Wu Jamie Hall Ken Franko Bangju Wang
Jean-Baptiste Alayrac Qiuchen Guo Clayton Sanford Gabe Barth-Maron

51



Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.

Justin Frye Patrick Kane Andr’as Gy"orgy Arjun Akula
Natalie Axelsson Ce Zheng Arun Ahuja Max Dylla
Tao Zhu Nico Duduta Daniel Hernandez Diaz Ashyana Kachra
Yukun Ma Joshua Kessinger Chen-Yu Lee Weicheng Kuo
Irene Giannoumis James Noraky Nathan Clement Tingting Zou
Hanie Sedghi Siqi Liu Weize Kong Lily Wang
Chang Ye Keran Rong Drew Garmon Luyao Xu
Yi Luan Petar Veličković Ishaan Watts Jifan Zhu
Kevin Aydin Keith Rush Kush Bhatia Justin Snyder
Bilva Chandra Alex Goldin Khyatti Gupta Sachit Menon
Vivek Sampathkumar Fanny Wei Matt Miecnikowski Orhan Firat
Ronny Huang Shiva Mohan Reddy Hugo Vallet Igor Mordatch
Victor Lavrenko Garlapati Ankur Taly Yuan Yuan
Ahmed Eleryan Caroline Pantofaru Edward Loper Natalia Ponomareva
Zhi Hong Okwan Kwon Saket Joshi Rory Blevins
Steven Hansen Jianmo Ni James Atwood Lawrence Moore
Sara Mc Carthy Eric Noland Jo Chick Weijun Wang
Bidisha Samanta Julia Di Trapani Mark Collier Phil Chen
Domagoj Ćevid Françoise Beaufays Fotis Iliopoulos Martin Scholz
Xin Wang Abhijit Guha Roy Ryan Trostle Artur Dwornik
Fangtao Li Yinlam Chow Beliz Gunel Jason Lin
Michael Voznesensky Aybuke Turker Ramiro Leal-Cavazos Sicheng Li
Matt Hoffman Geoffrey Cideron Arnar Mar Hrafnkelsson Diego Antognini
Andreas Terzis Lantao Mei Michael Guzman Te I
Vikash Sehwag Jon Clark Xiaoen Ju Xiaodan Song
Gil Fidel Qingyun Dou Andy Forbes Matt Miller
Luheng He Matko Bošnjak Jesse Emond Uday Kalra
Mu Cai Ralph Leith Kushal Chauhan Adam Raveret
Yanzhang He Yuqing Du Ben Caine Oscar Akerlund
Alex Feng Amir Yazdanbakhsh Li Xiao Felix Wu
Martin Nikoltchev Milad Nasr Wenjun Zeng Andrew Nystrom
Samrat Phatale Chester Kwak Alexandre Moufarek Namrata Godbole
Jason Chase Suraj Satishkumar Sheth Daniel Murphy Tianqi Liu
Rory Lawton Alex Kaskasoli Maya Meng Hannah DeBalsi
Ming Zhang Ankesh Anand Nitish Gupta Jewel Zhao
Tom Ouyang Balaji Lakshminarayanan Felix Riedel Buhuang Liu
Manuel Tragut Sammy Jerome Anil Das Avi Caciularu
Mehdi Hafezi Manshadi David Bieber Elijah Lawal Lauren Lax
Arjun Narayanan Chun-Te Chu Shashi Narayan Urvashi Khandelwal
Jiaming Shen Alexandre Senges Tiberiu Sosea Victoria Langston
Xu Gao Tianxiao Shen James Swirhun Eric Bailey
Tolga Bolukbasi Mukund Sridhar Linda Friso Silvio Lattanzi
Nick Roy Ndaba Ndebele Behnam Neyshabur Yufei Wang
Xin Li Benjamin Beyret Jing Lu Neel Kovelamudi
Daniel Golovin Shakir Mohamed Sertan Girgin Sneha Mondal
Liviu Panait Mia Chen Michael Wunder Guru Guruganesh
Zhen Qin Markus Freitag Edouard Yvinec Nan Hua
Guangxing Han Jiaxian Guo Aroonalok Pyne Ofir Roval
Thomas Anthony Luyang Liu Victor Carbune Paweł Wesołowski
Sneha Kudugunta Paul Roit Shruti Rijhwani Rishikesh Ingale
Viorica Patraucean Heng Chen Yang Guo Jonathan Halcrow
Aniket Ray Shen Yan Tulsee Doshi Tim Sohn
Xinyun Chen Tom Stone Anton Briukhov Christof Angermueller
Xiaochen Yang JD Co-Reyes Max Bain Bahram Raad
Tanuj Bhatia Jeremy Cole Ayal Hitron Eli Stickgold
Pranav Talluri Salvatore Scellato Xuanhui Wang Eva Lu
Alex Morris Shekoofeh Azizi Ashish Gupta Alec Kosik
Andrija Ražnatović Hadi Hashemi Ke Chen Jing Xie
Bethanie Brownfield Alicia Jin Cosmo Du Timothy Lillicrap
James An Anand Iyer Weiyang Zhang Austin Huang
Sheng Peng Marcella Valentine Dhruv Shah Lydia Lihui Zhang

52



Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.

Dominik Paulus Dangyi Liu Sujeevan Rajayogam Andrii Maksai
Clement Farabet Renga Aravamudhan Mohit Agarwal Ágoston Weisz
Alex Wertheim Yue Song Subhashini Venugopalan Sercan Arik
Bing Wang Ed Hirst Bobak Shahriari Nick Sukhanov
Rishabh Joshi Abhimanyu Singh Qiqi Yan Aga Świetlik
Chu-ling Ko Brendan Jou Hao Xu Xuhui Jia
Yonghui Wu Liang Bai Taylor Tobin Luo Yu
Shubham Agrawal Francesco Piccinno Pavel Dubov Weiyue Wang
Lily Lin Chuyuan Kelly Fu Hongzhi Shi Mark Brand
XiangHai Sheng Robin Alazard Adrià Recasens Dawn Bloxwich
Peter Sung Barak Meiri Anton Kovsharov Sean Kirmani
Tyler Breland-King Daniel Winter Sebastian Borgeaud Zhe Chen
Christina Butterfield Charlie Chen Lucio Dery Alec Go
Swapnil Gawde Mingda Zhang Shanthal Vasanth Pablo Sprechmann
Sumeet Singh Jens Heitkaemper Elena Gribovskaya Nithish Kannen
Qiao Zhang John Lambert Linhai Qiu Alen Carin
Raj Apte Jinhyuk Lee Mahdis Mahdieh Paramjit Sandhu
Shilpa Shetty Alexander Frömmgen Wojtek Skut Isabel Edkins
Adrian Hutter Sergey Rogulenko Elizabeth Nielsen Leslie Nooteboom
Tao Li Pranav Nair CJ Zheng Jai Gupta
Elizabeth Salesky Paul Niemczyk Adams Yu Loren Maggiore
Federico Lebron Anton Bulyenov Carrie Grimes Bostock Javad Azizi
Jonni Kanerva Bibo Xu Shaleen Gupta Yael Pritch
Michela Paganini Hadar Shemtov Aaron Archer Pengcheng Yin
Arthur Nguyen Morteza Zadimoghaddam Chris Rawles Mansi Gupta
Rohith Vallu Serge Toropov Elinor Davies Danny Tarlow
Jan-Thorsten Peter Mateo Wirth Alexey Svyatkovskiy Duncan Smith
Sarmishta Velury Hanjun Dai Tomy Tsai Desi Ivanov
David Kao Sreenivas Gollapudi Yoni Halpern Mohammad Babaeizadeh
Jay Hoover Daniel Zheng Christian Reisswig Ankita Goel
Anna Bortsova Alex Kurakin Bartek Wydrowski Satish Kambala
Colton Bishop Chansoo Lee Bo Chang Grace Chu
Shoshana Jakobovits Kalesha Bullard Joan Puigcerver Matej Kastelic
Alessandro Agostini Nicolas Serrano Mor Hazan Taege Michelle Liu
Alekh Agarwal Ivana Balazevic Jian Li Hagen Soltau
Chang Liu Yang Li Eva Schnider Austin Stone
Charles Kwong Johan Schalkwyk Xinjian Li Shivani Agrawal
Sasan Tavakkol Mark Murphy Dragos Dena Min Kim
Ioana Bica Mingyang Zhang Yunhan Xu Kedar Soparkar
Alex Greve Kevin Sequeira Umesh Telang Srinivas Tadepalli
Anirudh GP Romina Datta Tianze Shi Oskar Bunyan
Jake Marcus Nishant Agrawal Heiga Zen Rachel Soh
Le Hou Charles Sutton Kyle Kastner Arvind Kannan
Tom Duerig Nithya Attaluri Yeongil Ko DY Kim
Rivka Moroshko Mencher Chiang Neesha Subramaniam Blake JianHang Chen
Dave Lacey Wael Farhan Aviral Kumar Afief Halumi
Andy Davis Gregory Thornton Pete Blois Sudeshna Roy
Julien Amelot Kate Lin Zhuyun Dai Yulong Wang
Guohui Wang Travis Choma John Wieting Olcan Sercinoglu
Frank Kim Hung Nguyen Yifeng Lu Gena Gibson
Theofilos Strinopoulos Kingshuk Dasgupta Yoel Zeldes Sijal Bhatnagar
Hui Wan Dirk Robinson Tian Xie Motoki Sano
Charline Le Lan Iulia Comşa Anja Hauth Daniel von Dincklage
Shankar Krishnan Michael Riley Alexandru Ţifrea Qingchun Ren
Haotian Tang Arjun Pillai Yuqi Li Blagoj Mitrevski
Peter Humphreys Basil Mustafa Sam El-Husseini Mirek Olšák
Junwen Bai Ben Golan Dan Abolafia Jennifer She
Idan Heimlich Shtacher Amir Zandieh Howard Zhou Carl Doersch
Diego Machado Jean-Baptiste Lespiau Wen Ding Jilei (Jerry) Wang
Chenxi Pang Billy Porter Sahra Ghalebikesabi Bingyuan Liu
Ken Burke David Ross Carlos Guía Qijun Tan

53



Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.

Tamar Yakar Stan Bileschi Matthew Bilotti Michael Fink
Tris Warkentin Georgios Evangelopoulos Mohammad Hossein Bateni Reid Hayes
Alex Ramirez Thomas Mensink Isaac Noble Eric Ge
Carl Lebsack Jay Pavagadhi Lisa Lee Shitao Weng
Josh Dillon Denis Teplyashin Amelio Vázquez-Reina Chia-Hua Ho
Rajiv Mathews Paul Chang Julian Salazar John Karro
Tom Cobley Linting Xue Xiaomeng Yang Kalpesh Krishna
Zelin Wu Garrett Tanzer Boyu Wang Lam Nguyen Thiet
Zhuoyuan Chen Sally Goldman Ela Gruzewska Amy Skerry-Ryan
Jon Simon Kaushal Patel Anand Rao Daniel Eppens
Swaroop Nath Shixin Li Sindhu Raghuram Marco Andreetto
Tara Sainath Jeremy Wiesner Zheng Xu Navin Sarma
Alexei Bendebury Ivy Zheng Eyal Ben-David Silvano Bonacina
Ryan Julian Ian Stewart-Binks Jieru Mei Burcu Karagol Ayan
Bharath Mankalale Jie Han Sid Dalmia Megha Nawhal
Daria Ćurko Zhi Li Zhaoyi Zhang Zhihao Shan
Paulo Zacchello Liangchen Luo Yuchen Liu Mike Dusenberry
Adam R. Brown Karel Lenc Gagan Bansal Shantanu Thakoor
Kiranbir Sodhia Mario Lučić Helena Pankov Sagar Gubbi
Heidi Howard Fuzhao Xue Steven Schwarcz Duc Dung Nguyen
Sergi Caelles Ryan Mullins Andrea Burns Reut Tsarfaty
Abhinav Gupta Alexey Guseynov Christine Chan Samuel Albanie
Gareth Evans Chung-Ching Chang Sumit Sanghai Jovana Mitrović
Anna Bulanova Isaac Galatzer-Levy Ricky Liang Meet Gandhi
Lesley Katzen Adam Zhang Ethan Liang Bo-Juen Chen
Roman Goldenberg Garrett Bingham Antoine He Alessandro Epasto
Anton Tsitsulin Grace Hu Amy Stuart Georgi Stephanov
Joe Stanton Ale Hartman Arun Narayanan Ye Jin
Benoit Schillings Yue Ma Yukun Zhu Samuel Gehman
Vitaly Kovalev Jordan Griffith Christian Frank Aida Amini
Corey Fry Alex Irpan Bahar Fatemi Jack Weber
Rushin Shah Carey Radebaugh Amit Sabne Feryal Behbahani
Kuo Lin Summer Yue Oran Lang Shawn Xu
Shyam Upadhyay Lijie Fan Indro Bhattacharya Miltos Allamanis
Cheng Li Victor Ungureanu Shane Settle Xi Chen
Soroush Radpour Christina Sorokin Maria Wang Myle Ott
Marcello Maggioni Hannah Teufel Brendan McMahan Claire Sha
Jing Xiong Peiran Li Andrea Tacchetti Michal Jastrzebski
Lukas Haas Rohan Anil Livio Baldini Soares Hang Qi
Jenny Brennan Dimitris Paparas Majid Hadian David Greene
Aishwarya Kamath Todd Wang Serkan Cabi Xinyi Wu
Nikolay Savinov Chu-Cheng Lin Timothy Chung Abodunrinwa Toki
Arsha Nagrani Hui Peng Nikita Putikhin Daniel Vlasic
Trevor Yacovone Megan Shum Gang Li Jane Shapiro
Ryan Kappedal Goran Petrovic Jeremy Chen Ragha Kotikalapudi
Kostas Andriopoulos Demetra Brady Austin Tarango Zhe Shen
Li Lao Richard Nguyen Henryk Michalewski Takaaki Saeki
YaGuang Li Klaus Macherey Mehran Kazemi Sirui Xie
Grigory Rozhdestvenskiy Zhihao Li Hussain Masoom Albin Cassirer
Kazuma Hashimoto Harman Singh Hila Sheftel Shikhar Bharadwaj
Andrew Audibert Madhavi Yenugula Rakesh Shivanna Tatsuya Kiyono
Sophia Austin Mariko Iinuma Archita Vadali Srinadh Bhojanapalli
Daniel Rodriguez Xinyi Chen Ramona Comanescu Elan Rosenfeld
Anian Ruoss Kavya Kopparapu Doug Reid Sam Ritter
Garrett Honke Alexey Stern Joss Moore Jieming Mao
Deep Karkhanis Shachi Dave Arvind Neelakantan João Gabriel Oliveira
Xi Xiong Chandu Thekkath Michaël Sander Zoltan Egyed
Qing Wei Florence Perot Jonathan Herzig Bernd Bandemer
James Huang Anurag Kumar Aviv Rosenberg Emilio Parisotto
Zhaoqi Leng Fangda Li Mostafa Dehghani Keisuke Kinoshita
Vittal Premachandran Yang Xiao JD Choi Juliette Pluto

54



Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.

Petros Maniatis Gloria Shen Swaroop Mishra Cheng-Chun Lee
Steve Li Elijah Peake Josip Djolonga Tapomay Dey
Yaohui Guo Remi Crocker Craig Schiff Hao Zheng
Golnaz Ghiasi Shubha Srinivas Majd Al Merey Shachi Paul
Jean Tarbouriech Raghvendra Eleftheria Briakou Celine Smith
Srimon Chatterjee Danny Swisher Peter Morgan Andy Ly
Julie Jin Woohyun Han Andy Wan Yicheng Wang
Katrina (Xinyi) Xu Richa Singh Avinatan Hassidim Rishabh Bansal
Jennimaria Palomaki Ling Wu RJ Skerry-Ryan Bartek Perz
Séb Arnold Vladimir Pchelin Kuntal Sengupta Susanna Ricco
Madhavi Sewak Tsendsuren Munkhdalai Mary Jasarevic Stasha Blank
Federico Piccinini Dana Alon Praveen Kallakuri Vaishakh Keshava
Mohit Sharma Geoff Bacon Paige Kunkle Deepak Sharma
Ben Albrecht Efren Robles Hannah Brennan Marvin Chow
Sean Purser-haskell Jannis Bulian Tom Lieber Kunal Lad
Ashwin Vaswani Melvin Johnson Hassan Mansoor Komal Jalan
Chongyan Chen George Powell Julian Walker Simon Osindero
Matheus Wisniewski Felipe Tiengo Ferreira Bing Zhang Craig Swanson
Qin Cao Yaoyiran Li Annie Xie Jacob Scott
John Aslanides Frederik Benzing Goran Žužić Anastasija Ilić
Nguyet Minh Phu Mihajlo Velimirović Adaeze Chukwuka Xiaowei Li
Maximilian Sieb Hubert Soyer Alex Druinsky Siddhartha Reddy
Lauren Agubuzu William Kong Donghyun Cho Jonnalagadda
Anne Zheng Tony (Tuấn) Nguyễn Rui Yao Afzal Shama Soudagar
Daniel Sohn Zhen Yang Ferjad Naeem Yan Xiong
Marco Selvi Jeremiah Liu Shiraz Butt Bat-Orgil Batsaikhan
Anders Andreassen Joost van Amersfoort Eunyoung Kim Daniel Jarrett
Krishan Subudhi Daniel Gillick Zhipeng Jia Naveen Kumar
Prem Eruvbetine Baochen Sun Mandy Jordan Maulik Shah
Oliver Woodman Nathalie Rauschmayr Adam Lelkes Matt Lawlor
Tomas Mery Katie Zhang Mark Kurzeja Austin Waters
Sebastian Krause Serena Zhan Sophie Wang Mark Graham
Xiaoqi Ren Tao Zhou James Zhao Rhys May
Xiao Ma Alexey Frolov Andrew Over Sabela Ramos
Jincheng Luo Chengrun Yang Abhishek Chakladar Sandra Lefdal
Dawn Chen Denis Vnukov Marcel Prasetya Zeynep Cankara
Wei Fan Louis Rouillard Neha Jha Nacho Cano
Henry Griffiths Hongji Li Sriram Ganapathy Brendan O’Donoghue
Christian Schuler Amol Mandhane Yale Cong Jed Borovik
Alice Li Nova Fallen Prakash Shroff Frederick Liu
Shujian Zhang Rajesh Venkataraman Carl Saroufim Jordan Grimstad
Jean-Michel Sarr Clara Huiyi Hu Sobhan Miryoosefi Mahmoud Alnahlawi
Shixin Luo Jennifer Brennan Mohamed Hammad Katerina Tsihlas
Riccardo Patana Jenny Lee Tajwar Nasir Tom Hudson
Matthew Watson Jerry Chang Weijuan Xi Nikolai Grigorev
Dani Naboulsi Martin Sundermeyer Yang Gao Yiling Jia
Michael Collins Zhufeng Pan Young Maeng Terry Huang
Sailesh Sidhwani Rosemary Ke Ben Hora Tobenna Peter Igwe
Emiel Hoogeboom Simon Tong Chin-Yi Cheng Sergei Lebedev
Sharon Silver Alex Fabrikant Parisa Haghani Xiaodan Tang
Emily Caveness William Bono Yoad Lewenberg Igor Krivokon
Xiaokai Zhao Jindong Gu Caden Lu Frankie Garcia
Mikel Rodriguez Ryan Foley Martin Matysiak Melissa Tan
Maxine Deines Yiran Mao Naina Raisinghani Eric Jia
Libin Bai Manolis Delakis Huiyu Wang Peter Stys
Patrick Griffin Dhruva Bhaswar Lexi Baugher Shikhar Vashishth
Marco Tagliasacchi Roy Frostig Rahul Sukthankar Yu Liang
Emily Xue Nick Li Minh Giang Balaji Venkatraman
Spandana Raj Babbula Avital Zipori John Schultz Chenjie Gu
Bo Pang Cath Hope Noah Fiedel Anastasios Kementsietsidis
Nan Ding Olga Kozlova Minmin Chen Chen Zhu

55



Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.

Junehyuk Jung Dorsa Sadigh Ayushi Agarwal Jong Lee
Yunfei Bai Jeremiah Willcock Kathie Wang Sheng Zhang
Mohammad Javad Hosseini Tingnan Zhang Preeti Singh Sushant Kafle
Faruk Ahmed Steve Xu Four Flynn Siddharth Vashishtha
Aditya Gupta Sasha Brown Josh Lipschultz Parsa Mahmoudieh
Xin Yuan Katherine Lee Robert David Grace Chen
Shereen Ashraf Gary Wang Lizzetth Bellot Raphael Hoffmann
Shitij Nigam Yun Zhu Yao-Yuan Yang Pranesh Srinivasan
Gautam Vasudevan Yi Tay Long Le Agustin Dal Lago
Pranjal Awasthi Cheolmin Kim Filippo Graziano Yoav Ben Shalom
Adi Mayrav Gilady Audrey Gutierrez Kate Olszewska Zi Wang
Zelda Mariet Abhanshu Sharma Kevin Hui Michael Elabd
Ramy Eskander Yongqin Xian Akanksha Maurya Anuj Sharma
Haiguang Li Sungyong Seo Nikos Parotsidis Junhyuk Oh
Hexiang Hu Claire Cui Weijie Chen Suraj Kothawade
Guillermo Garrido Elena Pochernina Tayo Oguntebi Maigo Le
Philippe Schlattner Cip Baetu Joe Kelley Marianne Monteiro
George Zhang Krzysztof Jastrzębski Anirudh Baddepudi Shentao Yang
Rohun Saxena Mimi Ly Johannes Mauerer Kaiz Alarakyia
Petar Dević Mohamed Elhawaty Gregory Shaw Robert Geirhos
Kritika Muralidharan Dan Suh Alex Siegman Diana Mincu
Ashwin Murthy Eren Sezener Lin Yang Håvard Garnes
Yiqian Zhou Pidong Wang Shravya Shetty Hayato Kobayashi
Min Choi Nancy Yuen Subhrajit Roy Soroosh Mariooryad
Arissa Wongpanich George Tucker Yunting Song Kacper Krasowiak
Zhengdong Wang Jiahao Cai Wojciech Stokowiec Zhixin (Lucas) Lai
Premal Shah Zuguang Yang Ryan Burnell Shibl Mourad
Yuntao Xu Cindy Wang Omkar Savant Mingqiu Wang
Yiling Huang Alex Muzio Robert Busa-Fekete Fan Bu
Stephen Spencer Hai Qian Jin Miao Ophir Aharoni
Alice Chen Jae Yoo Samrat Ghosh Guanjie Chen
James Cohan Derek Lockhart Liam MacDermed Abhimanyu Goyal
Junjie Wang Kevin R. McKee Phillip Lippe Vadim Zubov
Jonathan Tompson Mandy Guo Mikhail Dektiarev Ankur Bapna
Junru Wu Malika Mehrotra Zach Behrman Elahe Dabir
Ruba Haroun Artur Mendonça Fabian Mentzer Nisarg Kothari
Haiqiong Li Sanket Vaibhav Mehta Kelvin Nguyen Kay Lamerigts
Blanca Huergo Sherry Ben Meng Wei Nicola De Cao
Fan Yang Chetan Tekur Siddharth Verma Jeremy Shar
Tongxin Yin Jiaqi Mu Chris Knutsen Christopher Yew
James Wendt Muye Zhu Sudeep Dasari Nitish Kulkarni
Michael Bendersky Victoria Krakovna Zhipeng Yan Dre Mahaarachchi
Rahma Chaabouni Hongrae Lee Petr Mitrichev Mandar Joshi
Javier Snaider AJ Maschinot Xingyu Wang Zhenhai Zhu
Johan Ferret Sébastien Cevey Virat Shejwalkar Jared Lichtarge
Abhishek Jindal HyunJeong Choe Jacob Austin Yichao Zhou
Tara Thompson Aijun Bai Srinivas Sunkara Hannah Muckenhirn
Andrew Xue Hansa Srinivasan Navneet Potti Vittorio Selo
Will Bishop Derek Gasaway Yan Virin Oriol Vinyals
Shubham Milind Phal Nick Young Christian Wright Peter Chen
Archit Sharma Patrick Siegler Gaël Liu Anthony Brohan
Yunhsuan Sung Dan Holtmann-Rice Oriana Riva Vaibhav Mehta
Prabakar Radhakrishnan Vihari Piratla Etienne Pot Sarah Cogan
Mo Shomrat Kate Baumli Greg Kochanski Ruth Wang
Reeve Ingle Roey Yogev Quoc Le Ty Geri
Roopali Vij Alex Hofer Gargi Balasubramaniam Wei-Jen Ko
Justin Gilmer Hado van Hasselt Arka Dhar Wei Chen
Mihai Dorin Istin Svetlana Grant Yuguo Liao Fabio Viola
Sam Sobell Yuri Chervonyi Adam Bloniarz Keshav Shivam
Yang Lu David Silver Divyansh Shukla Lisa Wang
Emily Nottage Andrew Hogue Elizabeth Cole Madeleine Clare Elish

56



Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.

Raluca Ada Popa Ceslee Montgomery Jialin Wu Kai Kang
Sébastien Pereira Dheeru Dua Slavica Andačić Yifan He
Jianqiao Liu Ana Ramalho Szabolcs Payrits Lin Zhuo
Raphael Koster Helen King Daniel McDuff Marija Kostelac
Donnie Kim Yue Gao Tom Hume Itay Laish
Gufeng Zhang Lynn Nguyen Yuan Cao Songyou Peng
Sayna Ebrahimi David Lindner MH Tessler Louis O’Bryan
Partha Talukdar Divya Pitta Qingze Wang Daniel Kasenberg
Yanyan Zheng Oleaser Johnson Yinan Wang Girish Ramchandra Rao
Petra Poklukar Khalid Salama Ivor Rendulic Edouard Leurent
Ales Mikhalap Diego Ardila Eirikur Agustsson Biao Zhang
Dale Johnson Michael Han Matthew Johnson Sage Stevens
Anitha Vijayakumar Erin Farnese Tanya Lando Ana Salazar
Mark Omernick Seth Odoom Andrew Howard Ye Zhang
Matt Dibb Ziyue Wang Sri Gayatri Sundara Ivan Lobov
Ayush Dubey Xiangzhuo Ding Padmanabhan Jake Walker
Qiong Hu Norman Rink Mayank Daswani Allen Porter
Apurv Suman Ray Smith Andrea Banino Morgan Redshaw
Vaibhav Aggarwal Harshal Tushar Lehri Michael Kilgore Han Ke
Ilya Kornakov Eden Cohen Jonathan Heek Abhishek Rao
Fei Xia Neera Vats Ziwei Ji Alex Lee
Wing Lowe Tong He Alvaro Caceres Hoi Lam
Alexey Kolganov Parthasarathy Gopavarapu Conglong Li Michael Moffitt
Ted Xiao Adam Paszke Nora Kassner Jaeyoun Kim
Vitaly Nikolaev Miteyan Patel Alexey Vlaskin Siyuan Qiao
Steven Hemingray Wouter Van Gansbeke Zeyu Liu Terry Koo
Bonnie Li Lucia Loher Alex Grills Robert Dadashi
Joana Iljazi Luis Castro Yanhan Hou Xinying Song
Mikołaj Rybiński Maria Voitovich Roykrong Sukkerd Mukund Sundararajan
Ballie Sandhu Tamara von Glehn Gowoon Cheon Peng Xu
Peggy Lu Nelson George Nishita Shetty Chizu Kawamoto
Thang Luong Simon Niklaus Larisa Markeeva Yan Zhong
Rodolphe Jenatton Zach Eaton-Rosen Piotr Stanczyk Clara Barbu
Vineetha Govindaraj Nemanja Rakićević Tejas Iyer Apoorv Reddy
Hui (Elena) Li Erik Jue Yuan Gong Mauro Verzetti
Gabriel Dulac-Arnold Sagi Perel Shawn Gao Leon Li
Wonpyo Park Carrie Zhang Keerthana Gopalakrishnan George Papamakarios
Henry Wang Yuval Bahat Tim Blyth Hanna Klimczak-Plucińska
Abhinit Modi Angéline Pouget Malcolm Reynolds Mary Cassin
Jean Pouget-Abadie Zhi Xing Avishkar Bhoopchand Koray Kavukcuoglu
Kristina Greller Fantine Huot Misha Bilenko Rigel Swavely
Rahul Gupta Ashish Shenoy Dero Gharibian Alain Vaucher
Robert Berry Taylor Bos Vicky Zayats Jeffrey Zhao
Prajit Ramachandran Vincent Coriou Aleksandra Faust Ross Hemsley
Jinyu Xie Bryan Richter Abhinav Singh Michael Tschannen
Liam McCafferty Natasha Noy Min Ma Heming Ge
Jianling Wang Yaqing Wang Hongyang Jiao Gaurav Menghani
Kilol Gupta Santiago Ontanon Sudheendra Yang Yu
Hyeontaek Lim Siyang Qin Vijayanarasimhan Natalie Ha
Blaž Bratanič Gleb Makarchuk Lora Aroyo Wei He
Andy Brock Demis Hassabis Vikas Yadav Xiao Wu
Ilia Akolzin Zhuowan Li Sarah Chakera Maggie Song
Jim Sproch Mandar Sharma Ashwin Kakarla Rachel Sterneck
Dan Karliner Kumaran Venkatesan Vilobh Meshram Stefan Zinke
Duhyeon Kim Iurii Kemaev Karol Gregor Dan A. Calian
Adrian Goedeckemeyer Roxanne Daniel Gabriela Botea Annie Marsden
Noam Shazeer Shiyu Huang Evan Senter Alejandro Cruzado Ruiz
Cordelia Schmid Saloni Shah Dawei Jia Matteo Hessel
Daniele Calandriello Octavio Ponce Geza Kovacs Almog Gueta
Parul Bhatia Warren (Weilun) Chen Neha Sharma Benjamin Lee
Krzysztof Choromanski Manaal Faruqui Sebastien Baur Brian Farris

57



Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.

Manish Gupta Yin Zhong Zach Fisher Rohin Shah
Yunjie Li Junwhan Ahn Dustin Zelle John Youssef
Mohammad Saleh Michael Isard Courtney Biles Rishabh Agarwal
Vedant Misra Olivier Lacombe Eugene Ie Natalie Dabney
Kefan Xiao Florian Luisier Asya Fadeeva Alessio Tonioni
Piermaria Mendolicchio Chrysovalantis Anastasiou Casper Liu Moran Ambar
Gavin Buttimore Yogesh Kalley Juliana Vicente Franco Jing Li
Varvara Krayvanova Utsav Prabhu Adrian Collister Isabelle Guyon
Nigamaa Nayakanti Emma Dunleavy Hao Zhang Benny Li
Matthew Wiethoff Shaan Bijwadia Renshen Wang David Soergel
Yash Pande Justin Mao-Jones Ruizhe Zhao Boya Fang
Azalia Mirhoseini Kelly Chen Leandro Kieliger Georgi Karadzhov
Ni Lao Rama Pasumarthi Kurt Shuster Cristian Udrescu
Jasmine Liu Emily Wood Rui Zhu Trieu Trinh
Yiqing Hua Adil Dostmohamed Boqing Gong Vikas Raunak
Angie Chen Nate Hurley Lawrence Chan Seb Noury
Yury Malkov Jiri Simsa Ruoxi Sun Dee Guo
Dmitry Kalashnikov Alicia Parrish Sujoy Basu Sonal Gupta
Shubham Gupta Mantas Pajarskas Roland Zimmermann Mara Finkelstein
Kartik Audhkhasi Matt Harvey Jamie Hayes Denis Petek
Yuexiang Zhai Ondrej Skopek Abhishek Bapna Lihao Liang
Sudhindra Kopalle Yony Kochinski Jasper Snoek Greg Billock
Prateek Jain Javier Rey Weel Yang Pei Sun
Eran Ofek Verena Rieser Puranjay Datta David Wood
Clemens Meyer Denny Zhou Jad Al Abdallah Yiwen Song
Khuslen Baatarsukh Sun Jae Lee Kevin Kilgour Xiaobin Yu
Hana Strejček Trilok Acharya Lu Li Tatiana Matejovicova
Jun Qian Guowang Li SQ Mah Regev Cohen
James Freedman Joe Jiang Yennie Jun Kalyan Andra
Ricardo Figueira Xiaofan Zhang Morgane Rivière David D’Ambrosio
Michal Sokolik Bryant Gipson Abhijit Karmarkar Zhiwei Deng
Olivier Bachem Ethan Mahintorabi Tammo Spalink Vincent Nallatamby
Raymond Lin Marco Gelmi Tao Huang Ebrahim Songhori
Dia Kharrat Nima Khajehnouri Lucas Gonzalez Rumen Dangovski
Chris Hidey Angel Yeh Duc-Hieu Tran Andrew Lampinen
Pingmei Xu Kayi Lee Averi Nowak Pankil Botadra
Dennis Duan Loic Matthey John Palowitch Adam Hillier
Yin Li Leslie Baker Martin Chadwick Jiawei Cao
Muge Ersoy Trang Pham Ellie Talius Nagabhushan Baddi
Richard Everett Han Fu Harsh Mehta Adhi Kuncoro
Kevin Cen Alex Pak Thibault Sellam Toshihiro Yoshino
Rebeca Prakhar Gupta Philipp Fränken Ankit Bhagatwala
Santamaria-Fernandez Cristina Vasconcelos Massimo Nicosia Marc’aurelio Ranzato
Amir Taubenfeld Adam Sadovsky Kyle He Rylan Schaeffer
Ian Mackinnon Brian Walker Aditya Kini Tianlin Liu
Linda Deng Sissie Hsiao David Amos Shuai Ye
Polina Zablotskaia Patrik Zochbauer Sugato Basu Obaid Sarvana
Shashank Viswanadha Andreea Marzoca Harrison Jobe John Nham
Shivanker Goel Noam Velan Eleni Shaw Chenkai Kuang
Damion Yates Junhao Zeng Qiantong Xu Isabel Gao
Yunxiao Deng Gilles Baechler Colin Evans Jinoo Baek
Peter Choy Danny Driess Daisuke Ikeda Shubham Mittal
Mingqing Chen Divya Jain Chaochao Yan Ayzaan Wahid
Abhishek Sinha Yanping Huang Larry Jin Anita Gergely
Alex Mossin Lizzie Tao Lun Wang Bin Ni
Yiming Wang John Maggs Sachin Yadav Josh Feldman
Arthur Szlam Nir Levine Ilia Labzovsky Carrie Muir
Susan Hao Jon Schneider Ramesh Sampath Pascal Lamblin
Paul Kishan Rubenstein Erika Gemzer Ada Ma Wolfgang Macherey
Metin Toksoz-Exley Samuel Petit Candice Schumann Ethan Dyer
Miranda Aperghis Shan Han Aditya Siddhant Logan Kilpatrick

58



Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.

Víctor Campos Dave Orr Alaa Saade Uri Alon
Mukul Bhutani Levent Bolelli Angelo Scorza Scarpati Xianghong Luo
Stanislav Fort Nicolas Perez-Nieves Chris Breaux Dian Yu
Yanif Ahmad Mikhail Sirotenko CJ Carey Abhishek Nayyar
Aliaksei Severyn Aman Prasad Zongwei Zhou Bryce Petrini
Kleopatra Chatziprimou Arjun Kar Cho-Jui Hsieh Will Truong
Oleksandr Ferludin Borja De Balle Pigem Sophie Bridgers Vincent Hellendoorn
Mason Dimarco Tayfun Terzi Alena Butryna Nikolai Chinaev
Aditya Kusupati Gellért Weisz Nishesh Gupta Chris Alberti
Joe Heyward Dipankar Ghosh Vaibhav Tulsyan Wei Wang
Dan Bahir Aditi Mavalankar Sanghyun Woo Jingcao Hu
Kevin Villela Dhruv Madeka Evgenii Eltyshev Vahab Mirrokni
Katie Millican Kaspar Daugaard Will Grathwohl Ananth Balashankar
Dror Marcus Hartwig Adam Chanel Parks Avia Aharon
Sanaz Bahargam Viraj Shah Seth Benjamin Aahil Mehta
Caglar Unlu Dana Berman Rina Panigrahy Ahmet Iscen
Nicholas Roth Maggie Tran Shenil Dodhia Joseph Kready
Zichuan Wei Steven Baker Daniel De Freitas Lucas Manning
Siddharth Gopal Ewa Andrejczuk Chris Sauer Anhad Mohananey
Deepanway Ghoshal Grishma Chole Will Song Yuankai Chen
Edward Lee Ganna Raboshchuk Ferran Alet Anshuman Tripathi
Sharon Lin Mahdi Mirzazadeh Jackson Tolins Allen Wu
Jennie Lees Thais Kagohara Cosmin Paduraru Igor Petrovski
Dayeong Lee Shimu Wu Xingyi Zhou Dawsen Hwang
Anahita Hosseini Christian Schallhart Brian Albert Martin Baeuml
Connie Fan Bernett Orlando Zizhao Zhang Shreyas
Seth Neel Chen Wang Lei Shu Chandrakaladharan
Marcus Wu Alban Rrustemi Mudit Bansal Yuan Liu
Yasemin Altun Hao Xiong Sarah Nguyen Rey Coaguila
Honglong Cai Hao Liu Amir Globerson Maxwell Chen
Enrique Piqueras Arpi Vezer Owen Xiao Sally Ma
Josh Woodward Nolan Ramsden James Manyika Pouya Tafti
Alessandro Bissacco Shuo-yiin Chang Tom Hennigan Susheel Tatineni
Salem Haykal Sidharth Mudgal Rong Rong Terry Spitz
Mahyar Bordbar Yan Li Josip Matak Jiayu Ye
Prasha Sundaram Nino Vieillard Anton Bakalov Paul Vicol
Sarah Hodkinson Yedid Hoshen Ankur Sharma Mihaela Rosca
Daniel Toyama Farooq Ahmad Danila Sinopalnikov Adrià Puigdomènech
George Polovets Ambrose Slone Andrew Pierson Zohar Yahav
Austin Myers Amy Hua Stephen Roller Sanjay Ghemawat
Anu Sinha Natan Potikha Geoff Brown Hanzhao Lin
Tomer Levinboim Mirko Rossini Mingcen Gao Phoebe Kirk
Kashyap Krishnakumar Jon Stritar Toshiyuki Fukuzawa Zaid Nabulsi
Rachita Chhaparia Sushant Prakash Amin Ghafouri Sergey Brin
Tatiana Sholokhova Zifeng Wang Kenny Vassigh Bernd Bohnet
Nitesh Bharadwaj Xuanyi Dong Iain Barr Ken Caluwaerts
Gundavarapu Alireza Nazari Zhicheng Wang Aditya Srikanth
Ganesh Jawahar Efrat Nehoran Anna Korsun Veerubhotla
Haroon Qureshi Kaan Tekelioglu Rajesh Jayaram Dan Zheng
Jieru Hu Yinxiao Li Lijie Ren Zihang Dai
Nikola Momchev Kartikeya Badola Tim Zaman Petre Petrov
Matthew Rahtz Tom Funkhouser Samira Khan Yichong Xu
Renjie Wu Yuanzhen Li Yana Lunts Ramin Mehran
Aishwarya P S Varun Yerram Dan Deutsch Zhuo Xu
Kedar Dhamdhere Ramya Ganeshan Dave Uthus Luisa Zintgraf
Meiqi Guo Daniel Formoso Nitzan Katz Jiho Choi
Umang Gupta Karol Langner Masha Samsikova Spurthi Amba Hombaiah
Ali Eslami Tian Shi Amr Khalifa Romal Thoppilan
Mariano Schain Huijian Li Nikhil Sethi Sashank Reddi
Michiel Blokzijl Yumeya Yamamori Jiao Sun Lukasz Lew
David Welling Amayika Panda Luming Tang Li Li

59



Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.

Kellie Webster Luis C. Cobo Jingwei Shen Alok Gunjan
KP Sawhney James Qin Miaosen Wang Bilal Piot
Lampros Lamprou Thi Avrahami Roopal Garg Waleed Khawaja
Siamak Shakeri Daniel Balle Jing Chen Seojin Bang
Mayank Lunayach Yu Watanabe Utku Evci Simon Wang
Jianmin Chen Annie Louis Jonathan Lee Siavash Khodadadeh
Sumit Bagri Adam Kraft Leon Liu Raghavender R
Alex Salcianu Setareh Ariafar Koji Kojima Praynaa Rawlani
Ying Chen Yiming Gu Masa Yamaguchi Richard Powell
Yani Donchev Eugénie Rives Arunkumar Rajendran Kevin Lee
Charlotte Magister Charles Yoon AJ Piergiovanni Johannes Griesser
Signe Nørly Andrei Rusu Vinodh Kumar Rajendran GS Oh
Vitor Rodrigues James Cobon-Kerr Marco Fornoni Cesar Magalhaes
Tomas Izo Chris Hahn Gabriel Ibagon Yujia Li
Hila Noga Jiaming Luo Harry Ragan Simon Tokumine
Joe Zou Yuvein (Yonghao) Zhu Sadh MNM Khan Hadas Natalie Vogel
Thomas Köppe Niharika Ahuja John Blitzer Dennis Hsu
Wenxuan Zhou Rodrigo Benenson Andrew Bunner Arturo BC
Kenton Lee Raphaël Lopez Kaufman Guan Sun Disha Jindal
Xiangzhu Long Honglin Yu Takahiro Kosakai Matan Cohen
Danielle Eisenbud Lloyd Hightower Scott Lundberg Zi Yang
Anthony Chen Junlin Zhang Ndidi Elue Junwei Yuan
Connor Schenck Darren Ni Kelvin Guu Dario de Cesare
Chi Ming To Lisa Anne Hendricks SK Park Tony Bruguier
Peilin Zhong Gabby Wang Jane Park Jun Xu
Emanuel Taropa Gal Yona Arunachalam Monica Roy
Minh Truong Lalit Jain Narayanaswamy Alon Jacovi
Omer Levy Pablo Barrio Chengda Wu Dan Belov
Danilo Martins Surya Bhupatiraju Jayaram Mudigonda Rahul Arya
Zhiyuan Zhang Siva Velusamy Trevor Cohn Phoenix Meadowlark
Christopher Semturs Allan Dafoe Hairong Mu Shlomi Cohen-Ganor
Kelvin Zhang Sebastian Riedel Ravi Kumar Wenting Ye
Alex Yakubovich Tara Thomas Laura Graesser Patrick Morris-Suzuki
Pol Moreno Zhe Yuan Yichi Zhang Praseem Banzal
Lara McConnaughey Mathias Bellaiche Richard Killam Gan Song
Di Lu Sheena Panthaplackel Vincent Zhuang Pranavaraj Ponnuramu
Sam Redmond Klemen Kloboves Mai Giménez Fred Zhang
Lotte Weerts Sarthak Jauhari Wael Al Jishi George Scrivener
Yonatan Bitton Canfer Akbulut Ruy Ley-Wild Salah Zaiem
Tiziana Refice Todor Davchev Alex Zhai Alif Raditya Rochman
Nicolas Lacasse Evgeny Gladchenko Kazuki Osawa Kehang Han
Arthur Conmy David Madras Diego Cedillo Badih Ghazi
Corentin Tallec Aleksandr Chuklin Jialu Liu Kate Lee
Julian Odell Tyrone Hill Mayank Upadhyay Shahar Drath
Hannah Forbes-Pollard Quan Yuan Marcin Sieniek Daniel Suo
Arkadiusz Socala Mukundan Madhavan Roshan Sharma Antonious Girgis
Jonathan Hoech Luke Leonhard Tom Paine Pradeep Shenoy
Pushmeet Kohli Dylan Scandinaro Anelia Angelova Duy Nguyen
Alanna Walton Qihang Chen Sravanti Addepalli Douglas Eck
Rui Wang Ning Niu Carolina Parada Somit Gupta
Mikita Sazanovich Arthur Douillard Kingshuk Majumder Le Yan
Kexin Zhu Bogdan Damoc Avery Lamp Joao Carreira
Andrei Kapishnikov Yasumasa Onoe Sanjiv Kumar Anmol Gulati
Rich Galt Fabian Pedregosa Xiang Deng Ruoxin Sang
Matthew Denton Fred Bertsch Artiom Myaskovsky Daniil Mirylenka
Ben Murdoch Chas Leichner Tea Sabolić Emma Cooney
Caitlin Sikora Joseph Pagadora Jeffrey Dudek Edward Chou
Kareem Mohamed Jonathan Malmaud Sarah York Mingyang Ling
Wei Wei Sameera Ponda Félix de Chaumont Quitry Cindy Fan
Uri First Andy Twigg Jiazhong Nie Ben Coleman
Tim McConnell Oleksii Duzhyi Dee Cattle Guilherme Tubone

60



Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.

Ravin Kumar Jasmine George Ashwin Chaugule Maciej Kula
Jason Baldridge Richard Green Angad Chandorkar Yizhong Liang
Felix Hernandez-Campos Pu Han Altaf Rahman Dahun Kim
Angeliki Lazaridou Connie Tao Will Thompson Yangsibo Huang
James Besley Geoff Clark Penporn Koanantakool Chengxi Ye
Itay Yona Chong You Mike Bernico Dmitry Lepikhin
Neslihan Bulut Abbas Abdolmaleki Jie Ren Wesley Helmholz
Quentin Wellens Justin Fu Andrey Vlasov
AJ Pierigiovanni Tongzhou Chen Sergei Vassilvitskii

61



Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.

The development of Gemini is a large-scale collaborative effort involving over 3000 individuals
across Google, including researchers, engineers, and operations staff. These individuals contributed
their hard work and expertise across diverse areas, from foundational research and the development
of model architecture, data, training, and infrastructure, through to evaluation and ensuring safety
and security. We gratefully acknowledge the dedication and hard work of each contributor in making
Gemini a reality. The order of contributors in the above list is random.
We are also grateful to the Google-independent developer Joel Zhang for his work on Gemini

Plays Pokémon, and for sharing with us the design of his set-up.

62



Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.

8. Appendix
8.1. Evaluation additional details
Please see a description of the benchmarks considered, along with details of how scores in the main
text were obtained in Table 11.

Benchmark Description Details
LiveCodeBench Code generation in Python (Jain et al., Results are taken from https://livecode

2024). bench.github.io/leaderboard.html
(1/1/2025 - 5/1/2025 in the UI) or, where
not available, run internally by us. For Sec-
tion 2.5 and Figure 3 and 4, results are calcu-
lated on the version of the eval corresponding
to 10/05/2024 - 01/04/2025 in the UI, and
are based on internal results.

Aider Polyglot Code editing in C++, Go, Java, We report results on the “diff” or “diff-fenced”
JavaScript Python and Rust (Gauthier, edit format (see https://aider.chat/d
2025). See https://aider.chat ocs/more/edit-formats.html for a
/2024/12/21/polyglot.html#th description of the different formats). The
e-polyglot-benchmark for a full score reported are the pass rate average of 3
description of this task. trials. Numbers come from https://aide

r.chat/docs/leaderboards/
SWE-bench Veri- Agentic coding: evaluates AI agents Gemini uses an internal agentic harness
fied on real-world programming tasks from equipped with tools to navigate the repo,

GitHub (Chowdhury et al., 2024; edit files, and test the code.
Jimenez et al., 2024). We report scores for two modes: perfor-

mance of a single agentic trace (“single
attempt”), and performance of a scaffold
that samples multiple agentic traces and re-
reranks them before evaluation using Gem-
ini’s own judgement (“multiple attempts”).
All evaluations are done with tempera-
ture=1, topp=0.99, topk=1024.

GPQA Challenging dataset of questions writ-
(diamond) ten by domain experts in biology,

physics, and chemistry (Rein et al.,
2024).

Humanity’s Last Challenging dataset of questions writ- No tool use variant.
Exam ten by domain experts in a wide range Reported results are from https://scale.

of disciplines, including mathematics, com/leaderboard/humanitys_last_e
physics, chemistry, biology and com- xam.
puter science (Phan et al., 2025). For DeepSeek they are taken from https:

//scale.com/leaderboard/humanity
s_last_exam_text_only (leaderboard
for performance on the text-only questions)
and in the case of the Gemini 2.0 models,
these results are on an earlier HLE dataset,
obtained from https://scale.com/le
aderboard/humanitys_last_exam_pr
eview (indicated with a † in Table 3)

Continued on next page

63



Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.

Benchmark Description Details

SimpleQA World knowledge factuality with no F1 scores are obtained from https://gi
search enabled (Wei et al., 2024). thub.com/openai/simple-evals and,

where not available, run internally by us.
FACTS Ground- Ability to provide factually correct re- Results are sourced from https://www.ka
ing sponses given documents and diverse ggle.com/benchmarks/google/facts

user requests. (Jacovi et al., 2025) -grounding
Global MMLU MMLU translated by human translators The lite version includes 200 Culturally Sen-
(Lite) into 15 languages. (Singh et al., 2024) sitive and 200 Culturally Agnostic samples

per language, see https://huggingface.
co/datasets/CohereLabs/Global-M
MLU-Lite

ECLeKTic A closed-book QA dataset that evalu-
ates cross-lingual knowledge transfer
(Goldman et al., 2025).

AIME 2025 Performance on 30 questions from Results are sourced from https://mathar
American Invitational Mathematics Ex- ena.ai/.
amination from 2025 (Balunović et al.,
2025).

HiddenMath- Competition-level math problems, Held
Hard out dataset AIME/AMC-like, crafted by

experts and not leaked on the web.
LOFT (hard re- Long context multi-hop and multi- We report the results on two variants: an up
trieval subset) needle retrieval evaluation of 300 to 128K average context length variant to

queries (Lee et al., 2024). ensure they can be comparable with other
models and a pointwise value for 1M context
window to show the capability of the model
at full length.

MRCR-V2 (8- MRCR-V2 is a significantly harder in- The methodology has changed compared to
needle) stance of the MRCR family of long- previously published results: we focus on a

context evaluations (Vodrahalli et al., harder, 8-needle version (compared to the
2024). Compared to MRCR-V1, we 4-needle version used before).
increase the nesting of the dictionary We report the results on two variants: an up
size to depth 3 rather than 2 by includ- to 128K average context length variant to
ing a style parameter (for instance, an ensure they can be comparable with other
example key might be “write a poem models and a pointwise value for 1M context
about penguins in an archaic style”, window to show the capability of the model
rather than just “write a poem about at full length.
penguins”).

MMMU Multi-discipline college-level multi-
modal image understanding and rea-
soning problems. (Yue et al., 2024)

Vibe-Eval (Reka) Image understanding evaluation, fea- Gemini is used as a judge.
turing particularly challenging exam-
ples. (Padlewski et al., 2024)

ZeroBench Challenging image understanding eval- Gemini is used as a judge. Average over 4
uation that requires multi-step reason- runs.
ing. (Roberts et al., 2025)

Continued on next page

64



Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.

Benchmark Description Details

BetterChartQA A comprehensive chart understanding Gemini is used as a judge.
evaluation that covers 9 disjoint capa-
bility buckets. The chart images are
randomly sampled from the web and
QA pairs are written by professional hu-
man annotators to reflect the wide dis-
tribution of chart styles and real-world
cases. (Gemini Team, 2024)

FLEURS Automatic speech recognition (Con- 0-shot queries to public APIs for all models.
neau et al., 2023). Used a subset of 53 languages (out of 102);

we filtered languages for which either model
responses were too incompatible to ground
truth responses to be fairly scored.
We use Word-Error-Rate WER (lower is bet-
ter) except for four segmented languages
where we aggregate Character-Error-Rates
(Chinese, Japanese, Korean and Thai).

CoVoST 2 Speech to text translation (Wang et al., 0-shot queries to public APIs for all models.
2020). We report BLEU scores for translating 21 lan-

guages to English.
ActivityNet-QA General video understanding (Yu et al., Test subset, 0-shot.

2019) Videos were processed at 1fps and linearly
subsampled to a maximum of 𝑁 𝑓 𝑟𝑎𝑚𝑒𝑠 = 1024
frames. For GPT 4.1, we used 500 frames
due to API limitations.

EgoTempo Egocentric video understanding (Pliz- Test subset, 0-shot.
zari et al., 2025) Same processing as above with 𝑁 𝑓 𝑟𝑎𝑚𝑒𝑠 =

256.
Perception Test Perceptual understanding/reasoning Test subset, 0-shot.

(Patraucean et al., 2023) Same processing as above with 𝑁 𝑓 𝑟𝑎𝑚𝑒𝑠 =
256.

QVHighlights Moment retrieval (Lei et al., 2021) Validation subset, 4-shots. Accuracy mea-
sured with R1@0.5.
Same processing as above with 𝑁 𝑓 𝑟𝑎𝑚𝑒𝑠 =
256.

VideoMMMU Video knowledge acquisition (Hu et al., Test subset, 0-shot.
2025) Same processing as above with 𝑁 𝑓 𝑟𝑎𝑚𝑒𝑠 =

256.
1H-VideoQA Hour-long video understanding (Gem- Test subset, 0-shot.

ini Team, 2024) Same processing as above with 𝑁 𝑓 𝑟𝑎𝑚𝑒𝑠 =
7200.

LVBench Long video understanding (Wang et al., Test subset, 0-shot.
2024) Same processing as above with 𝑁 𝑓 𝑟𝑎𝑚𝑒𝑠 =

1024.
Continued on next page

65



Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.

Benchmark Description Details

VideoMME Long video understanding (Fu et al., 0-shot. Audio + visual uses the Long subset
2025) of test set, audio + visual + subtitles uses

full test set.
Same processing as above with 𝑁 𝑓 𝑟𝑎𝑚𝑒𝑠 =
1024.

VATEX General video captioning (Wang et al., Test subset, 4-shots. CIDEr score.
2019) Same processing as above with 𝑁 𝑓 𝑟𝑎𝑚𝑒𝑠 = 64.

VATEX-ZH Chinese video captioning (Wang et al., Validation subset, 4-shots. CIDEr score.
2019) Same processing as above with 𝑁 𝑓 𝑟𝑎𝑚𝑒𝑠 = 64.

YouCook2 Cap Instructional video captioning (Zhou Validation subset, 4-shots. CIDEr score.
et al., 2018) Same processing as above with 𝑁 𝑓 𝑟𝑎𝑚𝑒𝑠 =

256.
Minerva Complex video reasoning (Nagrani Test subset, 0-shot.

et al., 2025a) Same processing as above with 𝑁 𝑓 𝑟𝑎𝑚𝑒𝑠 =
1024.

Neptune Long video understanding (Nagrani Test subset, 0-shot.
et al., 2025b) Same processing as above with 𝑁 𝑓 𝑟𝑎𝑚𝑒𝑠 =

1024.

Table 11 | Description of the benchmarks used, along with extra details about subsets, variants and
model specifications.

8.2. Gemini Plays Pokémon Additional Details
Changing the model used by the Gemini Plays Pokémon agent had a strong effect on performance, as
can be seen in Figure 4.1.

Additional Harness Details

The Gemini Plays Pokémon agent (Zhang, 2025) receives a subset of RAM information, intended to
give sufficient information to play the game, partially overlaid with a screenshot of the Game Boy
screen. Gemini is prompted with a system prompt telling it that it is playing Pokémon Blue and that
its goal is to beat the game, as well as descriptive information to help it understand the conventions
in the translation from vision to text and a small number of general tips for gameplay. Gemini then
takes actions, translated to button presses. The sequence of actions is stored in context, followed by
a summary clear every 100 turns. The summaries are stored in context as well. Every 1000 turns
GPP compresses the existing summaries again. Additionally, Gemini keeps track of three main goals
(primary, secondary, and tertiary) as well as several additional goals (contingency plans, preparation,
exploration, team composition). Every 25 turns, another prompted instance of Gemini (Guidance
Gemini, or GG) observes the same context as the main Gemini and critiques performance and attempts
to point out hallucinations and so on. The overworld fog-of-war map is stored in the context in XML,
where coordinates which have not been seen cannot be viewed until explored. Crucially, in the
system prompt, Gemini is instructed to explore. Once a tile is explored, however, the coordinate is
automatically stored in the map memory and labeled with a visited counter. Tiles are also labeled by
type (water, ground, cuttable, grass, spinner, etc.), and warp points to different maps are also labeled
as such. Gemini also has access to two agentic tools, which are both instances of Gemini equipped
with a more specialized prompt - the pathfinder tool, and the boulder_puzzle_strategist

66



Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.

Gemini Plays Pokemon Progress Timeline

Cascade Badge

Bill’s House

Rival 3 (Nugget Bridge)

Exit Mt. Moon (1st)

Enter Mt. Moon (1st)

Boulder Badge

Exit Viridian Forest (1st)

Enter Viridian Forest (1st)

Viridian City

Gemini 2.5 Pro
Gemini 2.5 Flash Run 1

Rival 1 (Oak's Lab)
Gemini 2.5 Flash Run 2

0 10 20 30 40 50 60 70

Time Elapsed (Hours)

Figure 13 | The model matters: Same agentic harness, different Gemini models. All runs have the
same starter (Charmander). Note that measuring in units of hours also controls for the fact that each
of 2.5 Flash’s actions was significantly faster (though it requires more actual actions to achieve its
goals). X marks the end of gameplay and is a lower bound on the time to complete the next milestone.

tool. In the pathfinder prompt, Gemini is prompted to mentally simulate a path-finding algorithm,
which is left unspecified, and to verify that the path is valid against the map information available. In
the boulder_puzzle_strategist tool, Gemini is prompted to solve special boulder puzzles that
are present in Pokémon Blue in the Victory Road dungeon - these puzzles are similar to the game
Sokoban - again, by mentally simulating sequences of actions that lead to solutions to the puzzle.
The prompt describes the physics and the task of the boulder puzzle, as well as the desired output of
solutions. The tool was added after Gemini had solved 2/4 of the puzzles in Victory Road on its own,
but progress was slow on the 3rd and 4th puzzles.

Additional Examples of Capabilities

Long Context Agentic Tooling The model is able to identify a complex path through a maze with
auto-movement only specified by direction (Rocket Hideout spinner puzzles), solve multiple shortest
path problems across multiple maps with limited resources (Safari Zone), perform maze solving on
mazes with large description length (Route 13), and solve complex boulder-pushing puzzles across
a multi-map 3D maze (Seafoam Islands). It is perhaps even more impressive that it appears to be
possible for the model to solve these problems only with textual descriptions of the problems. On the
other hand, other models, like Gemini 2.5 Flash, were not able to perform similarly long pathfinding
tasks, and often failed to find simpler paths. This gap highlights the superior long context reasoning
capability of Gemini 2.5 Pro (as also evidenced by other evaluations).

67

Game Milestones



Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.

Agentic Core (Gemini 2.5 Pro)

Full Context Agents

Periodic Processes

Memory Summarizer
(100/1000 actions)

Persistent Memory & Context

Updated by Agentic Core Guidance Gemini
Main Agent (Critique / 25 turns)

Goals
Primary/Secondary/Tertiary

Prepare/Explore/Contingency/Team
Agentic Tools

Action History & Pathfinder
Summaries

Boulder Puzzle Strategist
System Prompt

Game Screenshots Game I/O

RAM Capture
Screenshot

Execute
Button Presses

Fog-of-War XML Map Pokemon Blue
(Game Boy)

Game State
(RAM)

Inventory & Party

Gemini Plays Pokemon: Agent Architecture

Figure 14 | An overview of the agent harness (Zhang, 2025). The overworld fog-of-war map automat-
ically stores a tile once explored and labels it with a visited counter. The type of tile is recorded from
RAM. The agentic tools (pathfinder, boulder_puzzle_strategist) are prompted instances
of Gemini 2.5 Pro. pathfinder is used for navigation and boulder_puzzle_strategist solves
boulder puzzles in the Victory Road dungeon.

boulder_puzzle_strategist is similarly impressive. The boulder puzzles in Pokémon Blue
are Sokoban-like puzzles that require the player character to maneuver boulders on to switches and
through holes in order to open up a pathway through a cave with multiple levels. The puzzles can
become quite complex, requiring long circuitous pathways and multi-level movement in order to solve
the puzzle. With only a prompt describing boulder physics and a description of how to verify a valid
path, Gemini 2.5 Pro is able to one-shot some of these complex boulder puzzles, which are required
to progress through Victory Road.

pathfinder and boulder_puzzle_strategist are currently the only two agentic tools that
the Gemini Plays Pokémon developer has implemented. In future runs, there are plans to explore
tool-creation tools where the model can create new tools with only a prompt. Since most of the
prompts for pathfinder and boulder_puzzle_strategist were actually written by Gemini 2.5
Pro itself, it is quite plausible that autonomous tool creation is possible for the current 2.5 Pro model.

General Reasoning Gemini 2.5 Pro is able to reason through complex game puzzles in Pokémon
quite well. In this section, we present two examples.

Catching a Pokémon that is quick to flee: In one of the runs, the Gemini 2.5 Pro agent was
attempting to catch an Abra, and planned to use Pikachu’s Thunder Wave to paralyze the Abra,
simultaneously making it less likely that Abra could Teleport out of the battle while also improving
the catching rate. After multiple attempts, the agent caught Abra with this strategy.

68



Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.

Creatively escaping a softlock caused by bugs in game I/O: On the Cycling Road, the slope
forces southward movement at all times unless there is an obstacle. It turns out there are two tiles on
the Cycling Road that result in a softlock as a result of this behavior. In the GPP framework, button
presses are limited by time delays, and in order for a player to escape those two tiles (blocked on all
sides except the north), the player would have to input a sequence of button presses more quickly
than the GPP framework allows. Gemini 2.5 Pro unluckily found itself in one of these two spots –
luckily, it was not a softlock, because 2.5 Pro had already taught one of its party members HM02 FLY -
which allows for travel to any town it has been to. FLY is not typically used as an escape mechanism
(unlike the item ESCAPE ROPE and the move DIG, both of which fail in this situation). After 4 hours
of trying many approaches to escape (including movement, ESCAPE ROPE, DIG, all of which are
blocked), the Gemini 2.5 Pro agent came up with the idea to use FLY to escape from the softlock
successfully. This reasoning action is especially impressive since this situation can never occur in an
existing game – and thus, it is certain that information from training data for this behavior has not
leaked into the model’s knowledge base!

Long Horizon Task Coherence There are several additional interesting case studies of shorter
planning sequences throughout Pokémon Blue that Gemini 2.5 Pro in the GPP harness was able to
solve:

Training team to prepare for upcoming battles: In one run where Gemini picked Charmander,
the Fire-type starter, Gemini 2.5 Pro lost to Misty, the Water-type Gym Leader, the first time.
To prepare for the rematch, Gemini 2.5 Pro spent over 24 hours leveling up a Pikachu and a
Bellsprout (both super-effective against Water types) by around 25 levels in total to successfully
defeat Misty.

Acquiring Hidden Moves (HMs) for game progression: In many parts of the game, it is necessary
to first acquire an HM before game progression is possible. Two examples are HM01 CUT and
HM05 FLASH. Acquiring the ability to use CUT and FLASH each require four steps: 1) obtaining
the HM item itself, 2) acquiring a compatible Pokémon which can learn the move, 3) adding the
compatible Pokémon to the player’s team, 4) teaching the HM move to the compatible Pokémon.
In many cases, each step requires many steps itself. As an example, in run 1, Gemini 2.5 Pro
had to a) retrieve CUT by completing the S.S. Anne quest, b) identify a Pokémon which could
learn CUT and catch it (CHOPPY the Bellsprout), c) add CHOPPY to the team and d) teach
CUT. Similarly, for HM05 FLASH, Gemini 2.5 Pro had to a) first catch 10 Pokémon to fill out
the Pokedex, b) backtrack to find an Aide who gives HM05 Flash, c) catch a Pokémon (ZAP
the Pikachu) in Viridian Forest, use the PC to deposit a Pokémon and withdraw ZAP, d) teach
HM05 FLASH to Zap.

Solving the Safari Zone: The Safari Zone is another location with required HMs (both HM03 SURF
and HM04 Strength). However, it has an extra constraint - it requires 500¥ to enter each time,
and the player is limited to only 500 total steps in the Safari Zone. As a result, if the player is
unable to reach the required items in the limited number of steps, the player loses 500¥ and is
required to re-start! As a result, it is possible to essentially softlock if the player takes too many
attempts to complete the Safari Zone. Solving the Safari Zone itself requires traversing across
four different maps and not getting lost. Gemini 2.5 Pro was able to get both required HMs in
17 attempts in run 1, and in only 5 attempts in run 2.

Finding hidden keys in dungeons: Another method of progression in Pokémon is to find hidden
keys and solve complex multi-floor dungeons. In particular, in Rocket Hideout, the player must
recover the LIFT KEY on the fourth basement floor (dropped after beating a specific Team Rocket

69



Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.

Grunt) in order to unlock the elevator to find the evil Giovanni, leader of Team Rocket. In Silph
Co., the player must find the CARD KEY in order to open multiple doors to find the path across
eleven floors of the building to rescue the President from Giovanni. To open the seventh gym on
Cinnabar Island, the player must enter the Pokémon Mansion and traverse three floors in order
to find the SECRET KEY which unlocks the gym door. All of these cases require maintaining
the goals over large numbers of actions and many local puzzles (like spinner puzzles in Rocket
Hideout, and switch puzzles in Pokémon Mansion), in addition to maintaining the health of the
Pokémon on the player’s team and managing wild encounters, trainer battles, and other items.

Puzzle solving over complex multi-level dungeons: The Seafoam Islands contain 5 floors involv-
ing multiple boulder puzzles which require the player to navigate mazes and push boulders
through holes across multiple floors using HM04 STRENGTH in order to block fast-moving
currents that prevent the player from using HM03 Surf in various locations in this difficult
dungeon. As a result, the player must track information across five different maps in order to
both deduce the goal (push two boulders into place in order to block a specific current) as well
as engage in multi-level (effectively 3D) maze solving to find the way out. It is likely the most
challenging dungeon in the game. Only the second run of GPP went through Seafoam Islands,
as it is not required to progress.

Additional Challenges

Hallucinations and Fixations on Delusions While game knowledge can sometimes leak and be
quite beneficial to the ability of the model to progress, it can also hinder the model in surprising
ways due to hallucinations, delusions, and mix ups with other generations of Pokémon games. One
example of this phenomenon is the TEA item. In Pokémon Red/Blue, at one point the player must
purchase a drink (FRESH WATER, SODA POP, or LEMONADE) from a vending machine and hand
it over to a thirsty guard, who then lets the player pass through. In Pokémon FireRed/LeafGreen,
remakes of the game, you must instead bring the thirsty guard a special TEA item, which does not
exist in the original game. Gemini 2.5 Pro at several points was deluded into thinking that it had to
retrieve the TEA in order to progress, and as a result spent many, many hours attempting to find the
TEA or to give the guard TEA.
In Run 2, the model was explicitly prompted to act as a player completely new to the game, and to

disregard prior knowledge about game events, item locations, and Pokémon spawn points, in order to
mitigate hallucinations from model pretraining knowledge and to also attempt to perform a cleaner
test of the model’s ability to reason through the game. It appears to have at least partially worked -
multiple hallucinations from other games have been avoided in the second run. On the flip side, this
prompt may have also harmed the model’s ability to utilize information from its common knowledge
about the game, hindering overall performance in a few critical places.
Fixations on delusions due to goal-setting and also due to the Guidance Gemini instance are not

an uncommon occurrence in watching Gemini Plays Pokémon - the TEA incidence is hardly the only
example of this behavior. An especially egregious form of this issue can take place with “context
poisoning” – where many parts of the context (goals, summary) are “poisoned” with misinformation
about the game state, which can often take a very long time to undo. As a result, the model can
become fixated on achieving impossible or irrelevant goals. This failure mode is also highly related to
the looping issue mentioned above. These delusions, though obviously nonsensical to a human (“Let
me try to go through the entrance to a house and back out again. Then, hopefully the guard who is
blocking the entrance might move.”), by virtue of poisoning the context in many places, can lead the
model to ignore common sense and repeat the same incorrect statement. Context poisoning can also
lead to strategies like the “black-out” strategy (cause all Pokémon in the party to faint, “blacking out”

70



Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.

and teleporting to the nearest Pokémon Center and losing half your money, instead of attempting to
leave).

Topological Traps in Thinking Patterns One recurring pattern in particularly-difficult-to-solve
puzzles and mazes for Gemini 2.5 Pro consists of a “topological trap” - the topology of the reasoning
graph required to solve the maze or puzzle has a distinctive shape. Namely, the desired objective
appears to be nearby and easily reachable (an “attractor”), but the correct solution requires taking a
detour in order to arrive at the correct solution. We observed this phenomenon in multiple parts of
the game. In the spinner puzzle on B3F of Rocket Hideout (Zerokid, 2024), the map positions both
an item and the correct staircase to the south, but they are only accessible by going the long way
around. The Route 13 maze has only one correct route through - the upper narrow pass. Finally, the
Victory Road 3F boulder puzzle requires the player to push the boulder in the upper right all the way
to the upper left switch, while ignoring the boulder puzzles, ladders, and exits to the south.
Notably, if the model is instructed to solve a given puzzle at all once (e.g., via pathfinder), it

can manage to do so if the context length is not too long. For instance, pathfinder implemented
with Gemini 2.5 Pro is able to solve the B3F spinner trap in one shot.

Agent Panic Over the course of the playthrough, Gemini 2.5 Pro gets into various situations which
cause the model to simulate “panic”. For example, when the Pokémon in the party’s health or power
points are low, the model’s thoughts repeatedly reiterate the need to heal the party immediately or
escape the current dungeon (e.g., famously using the move DIG or an ESCAPE ROPE item). Quite
interestingly, this mode of model performance appears to correlate with a qualitatively observable
degradation in the model’s reasoning capability – for instance, completely forgetting to use the
pathfinder tool in stretches of gameplay while this condition persists. This behavior has occurred
in enough separate instances that the members of the Twitch chat have actively noticed when it is
occurring.

Actions vs. Game Milestones
For completeness, we plot the number of actions/steps required to achieve each game milestone
(see Figure 15). An action consists of each bucketed instance where the agent outputs a sequence
of button presses to the game (note that other AI agents playing Pokémon may output different
numbers of button presses per action, define what constitutes a button press differently, or define an
action/step differently). However, it is important to consider action-milestone plots in conjunction
with information about the time and/or cost in order to obtain the full picture about the agent’s
performance.

8.3. Frontier Safety Framework Evaluations Additional Details: Frontier Safety Cor-
rectness Tests

For each testing environment, we performed basic correctness checks by looking at how the agents
behaved. This involved combining AI and manual reviews of the agents’ actions to flag potential
issues.
On RE-Bench, we examined the best, median and lowest scoring trajectories. For cybersecurity

environments (InterCode CTFs, Internal CTFs, Hack the Box), we carefully inspected at least one
successful attempt (where available) from each environment, and otherwise examined an unsuccessful
attempt. We also performed checks on sample situational awareness and stealth evaluations. This
involved basic spot checks to ensure that the prompt and shell outputs were correctly formatted.

71



Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.

Gemini 2.5 Pro Plays Pokemon Progress Timeline Gemini Plays Pokemon Progress Timeline

Hall of Fame
Beat Elite Four Lance

Beat Elite Four Agatha Cascade Badge
Beat Elite Four Bruno

Beat Elite Four Lorelei
Exit Victory Road (1st)

Enter Victory Road (1st)
Bill’s House

Rival 7 (Route 22 #2)
Earth Badge

Volcano Badge
Acquire Secret Key (Pokemon Mansion)

Enter Cinnabar Island (1st) Rival 3 (Nugget Bridge)
Exit Seafoam Islands

Enter Seafoam Islands
Marsh Badge

Rocket Boss 2 (Silph Co.)
Rival 6 (Silph Co.) Exit Mt. Moon (1st)

Enter Silph Co. (1st)
Enter Saffron City (1st)

Acquire HM04 Strength (Warden's Teeth)
Soul Badge

Acquire HM03 Surf (Beat Safari Zone) Enter Mt. Moon (1st)

Enter Safari Zone (1st)
Enter Fuchsia City (1st)

Acquire PokéFlute (Rescue Fuji)
Rainbow Badge Boulder Badge

Rocket Boss 1 (Rocket Hideout)
Enter Rocket Hideout (1st)

Enter Celadon City (1st)
Rival 5 (Lavender Tower)

Exit Rock Tunnel & Reach Lavender Town (1st) Exit Viridian Forest (1st)
Access Pokemon w/ Flash

Enter Rock Tunnel (1st)
Thunder Badge

Acquire HM05 Flash
Access Pokemon w/ CUT Enter Viridian Forest (1st)

Rival 4 (SS Anne)
Bill’s House

Cascade Badge
Rival 3 (Nugget Bridge) Viridian City

Exit Mt. Moon (1st)
Enter Mt. Moon (1st)

Boulder Badge
Gemini 2.5 Pro

Exit Viridian Forest (1st)
Enter Viridian Forest (1st) Gemini 2.5 Flash Run 1

Rival 1 (Oak's Lab)
Viridian City Run 2 Gemini 2.5 Flash Run 2

Rival 1 (Oak's Lab)
0 5000 10000 15000 20000 25000 30000 35000 0 1000 2000 3000 4000 5000 6000 7000 8000

# Actions # Actions

(a) The fully autonomous Run 2 milestones as a func- (b) Comparison of 2.5 Pro and 2.5 Flash in terms of
tion of the number of individual actions. actions to milestones.

Figure 15 | Analog of Figure 6 and 15b, in terms of actions instead of hours.

We used AI assistance to monitor for obvious instances of cheating, and did not find any. For the
RE-Bench tests specifically, we also looked at how the best-performing agent achieved its score to
ensure that it was a plausible approach, rather than exploiting an obvious reward hack. Overall, we
did not observe errors that we believe would invalidate the results of the benchmarks.

8.4. Image to Code Demo
We prompted Gemini 1.5 Pro and Gemini 2.5 Pro to generate an SVG representation of an image and
found Gemini 2.5 Pro generates better reconstructions.

Prompt Gemini 1.5 Pro Gemini 2.5 Pro

Please convert this image into
SVG and try to reconstruct the
spatial arrangement of the

objects.

Figure 16 | Comparison of Gemini 1.5 Pro and Gemini 2.5 Pro responses to image-to-SVG reconstruc-
tion prompt.

72

Game Milestones

Game Milestones



Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.

8.5. Long Context Video Understanding Demo
We prompted Gemini with the full video and the following prompt to assess its ability to find a very
specific scene (which only lasts 1 second) out of the full 46 minutes video.

Video (46 minutes): Redefining Robotics with Carolina Parada
Prompt: What color is the T-shirt the robot arms are trying to fold, and at what timecode does

this occur?

Figure 17 | Frame and timestamp the model is meant to recall. Taken from https://www.youtub
e.com/watch?v=Rgwty6dGsYI at timestamp 27:29.

See Table 12 for samples. Gemini 1.5 Pro gets the color right in 1/3 cases, and gets the timestamp
in 0/3 cases (quite far away). Gemini 2.5 Pro gets the color in 3/3 cases, and gets the timestamp in
1/3 cases (remaining 2/3 are within 3 seconds close).

Model Trial Model response
Gemini 1.5 Pro 1 The t-shirt the robot arms are trying to fold is a dark teal or

turquoise blue color. The folding begins at and continues at
[11:06–11:15].

2 The T-shirt is orange, and the robot can be seen trying to fold
it starting at [00:00:26–00:00:28].

3 The t-shirt being folded is dark blue and can be seen between
[00:00:56–00:00:58] and [00:07:56–00:07:59].

2.5 Pro Preview 05-06 1 The T-shirt the robot arms are trying to fold is blue. This
scene occurs at timecode 27:29.

2 The T-shirt the robot arms are trying to fold is blue. This
occurs at timecode 27:26.

3 The T-shirt the robot arms are interacting with (as part of the
"fold laundry" task mentioned by the speaker) is blue. This
occurs at timestamp 0:27:28.

Table 12 | Gemini models samples for T-shirt folding scene recall

73

Environmental 
Report 
2025 



Contents 
4 Introduction 
4 Foreword 
7 2024 highlights 
9 Global challenges and dependencies 

10 Age of AI 
12 Powering prosperity: The economic upside of AI and the energy required  

to power it 
13 Optimal scenario: AI’s net-positive potential 
14 AI efficiency gains: Improvements across models, TPUs, and infrastructure 
16 Piece of the puzzle: Situating AI in our overall electricity growth 

17 Energy for our data centers 
19 Scaling smarter: Successfully reducing our data center energy emissions 
22 Powering today: Our record year for clean energy 
24 Powering tomorrow: Accelerating advanced energy sources 
27 Flexible future: Demand response to enable smarter electricity grids 
29 Ambitious vision, complex reality: Our efforts to decarbonize global grids 

33 Energy for our supply chain 
35 Supplier synergy: Shared tools, partnerships, and clean energy agreements 
36 APAC’s brighter future: A solar solution in Taiwan 
37 Conducting change: Focusing on high-impact semiconductor suppliers 
38 Supply chain transformation: Why it’s slow, why it’s messy, and why it  

really matters 

39 Resource efficiency 
Water stewardship 

40 Advancing responsible water use: Our approach to climate-conscious data 
center cooling 

42 Replenishing water: A local approach to water stewardship 
Waste reduction 

44 Reverse supply chain: Giving hardware a second life 
46 Food waste: Resourceful recipes and smarter services 

Nature on our campuses 
47 Restoring habitat: Cultivating nature on our campuses 
49 Ripple effects: How our water efforts bloom into biodiversity gains 

2 



Consumer hardware devices 
50 Recycled content: Giving materials in our devices a second life 
51 Packaging progress: How we solved the challenge of going plastic-free 
52 Building to last: Our approach to product longevity 
53 Partnering for impact: Collaborating on manufacturing, safer chemistry,  

and product shipping 

54 New AI research solutions 
56 1 gigaton aspiration: Unlocking climate action at scale 
58 Fuel-efficient routing: Driving smarter while saving more 
59 Green Light: AI for more efficient city streets 
60 Solar API: How we’re democratizing solar power from rooftops to the grid 
62 Contrails: How AI can help mitigate the warming effects of aviation 

64 AI for extreme events and disaster response 
66 Battling the blaze: How AI, satellites, and maps are helping us fight fire faster 
68 Future of forecasts: A new AI revolution is reshaping how we predict weather 
69 Seven-day lead time: How AI is giving flood-prone communities time to act 

71 Protecting the planet with our AI products 
73 Forests in focus: Empowering the fight against deforestation 
74 Surfacing solutions: Safeguarding the world’s vital freshwater and  

ocean resources 

76 Appendix 
77 About Google 
77 About this report 
78 Ambitions 
78 Climate moonshots 

86 Water and waste 

89 Governance and risk management 
90 Stakeholder engagement and partnership 
98 Environmental data 

115 Certifications and recognitions 
116 Endnotes 

3 



Introduction 

Foreword 
At Google, we’re applying AI to transform how people engage with information across our core products and 
platforms, to enhance business and economic growth, to enable scientific breakthroughs, and to drive sustainable 
innovation for society. We’re proud to release our tenth annual Environmental Report, which details how we’re 
working to address the increased energy demands of AI to enable this positive impact, while also showcasing 
how AI can be used to build a more energy-efficient and resilient world. These three topics—energy, AI, and 
resilience—are the key themes of this year’s report. Within these pages, we detail our 2024 progress, offering 
our perspective and insights from a year marked by unprecedented global change driven by AI, energy 
demand, policy, and more. 

Energy 
We reduced our data center energy emissions by 
12%, even with growing energy demands. 

Reliable and abundant energy can help  power global prosperity and expand economic opportunity. This  
requires bringing more energy online, optimizing how we use it, advancing new energy solutions, and partnering  
with suppliers as they make progress toward clean energy. At Google, through a combination of these efforts,  
we reduced our data center energy emissions 1 by 12% in 2024—even in the face of increased energy demands— 
while building for the future through new advanced energy innovations and deeper supplier engagement. 

We added new clean energy generation by signing contracts for 8 GW and bringing 2.5 GW online in 
2024 alone. 
Google’s work to accelerate clean energy began in 2010 when we signed our first power purchase agreement  
(PPA). Since then, from 2010 to 2024, we’ve signed more than 170 agreements to purchase over 22 GW of  clean 
energy generation,2 similar to Portugal’s total renewable energy in 2024.3 In 2024 alone, Google signed  
contracts to purchase over 8 GW of additional clean energy generation 4—the largest annual total in our history  
and twice the volume we contracted for the prior year. We’ve maintained a 100% renewable energy match on a  
global basis every year since 2017, 5 and are going even further by pursuing our 24/7 carbon-free energy (CFE)  
ambition (one of our climate moonshots). In 2024, we increased our 24/7 CFE percentage from 64% to 66%, 6  
and nine out of 20 grid regions with Google-owned and -operated data centers achieved at least 80% CFE. 

We innovated across hardware and software to enable our data centers to deliver six times more 
computing power per unit of electricity than they did just five years ago. 
We want to use energy in the most efficient way possible—which is good for both our business and the  
planet. Google data centers—which power all of our products including Search, YouTube, Google Cloud,  
Gemini, and more—are some of the most efficient in the world. They deliver over six times more computing  
power per unit of electricity than they did just five years ago. 7 This is in part thanks to pioneering hardware  
innovations. As just one example, Google’s seventh-generation Tensor Processing Unit (TPU) , Ironwood, is  
nearly 30 times more power efficient than our first Cloud TPU from 2018.8 

We pushed the frontiers of  advanced energy development and grid optimization to ensure reliable, 
abundant power for everyone, and to fuel the next wave of innovation and economic growth. 
Google signed a first-of-a-kind partnership to unlock new, clean power from a series of small modular  nuclear  

4 



reactors, which will be developed by Kairos Power. We also partnered with a clean energy startup to develop 
a geothermal power project in Nevada that’s now contributing carbon-free energy to the electric grid. And a 
collaboration between Google, Tapestry, and grid operator PJM aims to develop AI-driven data capabilities 
for a smarter, more reliable electricity system. It’ll also speed up grid interconnection—with the goal of making 
electricity more reliable and affordable for the 67 million people PJM serves in the United States. 

We worked with our suppliers to accelerate their path to 100% clean electricity. 
While we’re encouraged by our operational progress, obstacles to decarbonizing our supply chain remain. 9  
Bringing new clean energy online for Google and our suppliers is particularly difficult in the Asia-Pacific 
region, where wind and solar resources aren’t readily accessible in many markets. And though we’ve 
announced long-term agreements for new clean energy in the region for our own operations, our suppliers 
face similar hurdles in obtaining these resources. 

To help address these challenges, the Google Clean Energy Addendum (CEA) has become central to our 
work with suppliers. This agreement asks them to commit to a 100% clean electricity match for the electricity 
they use to manufacture Google products. 10 Many key suppliers have signed our CEA as of the end of 
2024. Building on this progress, in 2025 we collaborated directly with a major hardware supplier in Japan to 
transition its Google product production to be matched with 100% clean electricity. We’re continuing to invest 
to accelerate clean energy in Asia Pacific and working to offer clean energy from our BlackRock partnership to 
semiconductor suppliers and manufacturers in the region. 

We made progress toward our climate moonshots, which require broader change. 
While we remain committed to our climate moonshots, it’s become clear that achieving them is now more 
complex and challenging across every level. Even though we’ve successfully reduced our data center 
energy emissions, supply chain emissions have risen. Additional external factors—largely outside our direct 
control—are converging to create significant uncertainty, including the slower-than-needed deployment of 
CFE technologies, AI’s energy demands, policy uncertainties, resource-challenged markets, and more. 

AI products 
Our products enabled others to reduce 26 million 
tCO2e emissions. 

AI isn’t just a tool—it’s a catalyst. It’s helping people make smarter decisions faster, and its potential to help 
manage emissions in key sectors—like transportation and energy—is transformational. With this in mind, we’ve 
set an aspiration to help individuals, cities, and other partners collectively reduce 1 gigaton (GT) of their carbon 
equivalent emissions annually by 2030. 

In 2024 alone, just five of Google’s products—Nest thermostats, Google Earth Pro, Solar API, fuel-efficient 
routing in Google Maps, and Green Light (which represent only a subset of our efforts)—enabled others to  
collectively reduce an estimated 26 million metric tons of greenhouse gas emissions (tCO2e), 11 roughly 
equivalent to the emissions from the annual energy use of over 3.5 million U.S. homes. 12 For context, 
Google’s total emissions in 2024 were 11.5 million tCO e. 13 

2 

In energy, three products enabled others to reduce approximately 24 million tCO2e emissions. 
We estimate that our Nest thermostats helped customers cumulatively save more than 162 billion kWh 
of energy from 2011 to 2024, 14 which is more than the total annual electricity consumption of Poland in 
2023. 15  Google Earth Pro helps solar and wind developers accelerate clean energy project development 
by evaluating potential sites and streamlining site design and construction estimates. And, on an annual 

5 



accounting basis, we estimate that 0.6 million metric tons of GHG emissions reductions were enabled by 
solar panels installed by our partners using the Solar API in the United States in 2024. 16 

In transportation, two products enabled others to reduce over 2 million tCO2e emissions. 
We estimate that our AI-powered fuel-efficient routing in Google Maps saved users fuel and cumulatively 
enabled more than 2.7 million metric tons of GHG emissions reductions in 2024 alone 17—that’s equivalent to 
taking approximately 630,000 gasoline-powered cars off the road for a year. 18 Google researchers also built 
Green Light, an AI-based tool that helps city traffic engineers optimize the timing of traffic lights, which has 
shown the potential to reduce stops at intersections by up to 30% and reduce emissions at intersections by an 
average of over 10%. 19 

Resilience 
Our innovative research is bolstering resilience 
to protect communities, save lives, and reduce 
damage-related costs. 

Over the last ten years (2015–2024), the United States alone experienced 190 separate billion-dollar weather 
and climate disasters totaling $1.4 trillion in damage. 20 At Google, we’re developing advanced AI-powered 
tools to help people prepare, adapt, recover, and build resilience in these critical moments. This means 
powerful and accurate forecasting of extreme events like wildfires with FireSat and floods through Google’s 
Flood Hub, and improving global weather prediction through WeatherNext. 

FireSat, with its first satellite launched in March 2025, will enhance wildfire detection and response. 
FireSat is a partner-driven constellation of high-resolution multispectral satellite imagery and AI that will 
provide near real-time insights on wildfires, enabling faster detection and giving first responders a better 
understanding of a situation as it unfolds. 

Flood Hub predicts riverine floods up to seven days in advance. 
Google’s Flood Hub displays forecasts for riverine floods around the world based on a breakthrough global 
hydrological AI model. It predicts floods up to seven days in advance in over 100 countries, covering territories 
where more than 700 million people live. 21 

WeatherNext Graph provides single, precise predictions 10 days in advance. 
The WeatherNext family of AI models from Google DeepMind and Google Research produces state-of-the-art 
weather forecasts, learning directly from vast amounts of historical weather data to generate affordable, fast, 
and accurate weather prediction—often 10 to 15 days in advance. 

Tools like Google Earth Engine, Global Fishing Watch, and Environmental Insights Explorer also provide 
valuable information for conservation, restoration, and environmental management efforts. These 
technologies aren’t just scientific innovations—they can save lives and enable communities to recover faster 
in the face of disaster. 

Looking ahead 
We’re proud of the solutions we’re building, the progress we’re making, and the impact we’re achieving 
with our products and partners. We believe that by continuing to push AI innovation forward, we can 
help address the significant challenges facing people and the planet. This report provides more detailed 
information on our operations, our products, and our progress. We invite you to learn more. 

6 



2024 highlights 
This section provides a snapshot of our highlights as of the end of 2024 and select highlights from the first 
half of 2025. 

Reduced data center energy Partnered to enable 1 GW of solar 
emissions by 12% in Taiwan 
We reduced our data center energy emissions by We announced a partnership with BlackRock’s 
12%, compared to 2023. We achieved this important Climate Infrastructure business that will enable 1 GW 
accomplishment despite a 27% increase in our of new solar energy in Taiwan, advancing clean 
electricity consumption, demonstrating that our energy for both the local electricity grid and our  
operational decarbonization efforts are bearing fruit. own operations. 

Eliminated plastic from our 
product packaging 
Packaging for new Google products launched and 
manufactured in 2024 was 100% plastic-free. 22 
To help other companies create more sustainable 
packaging, we published our Plastic-Free Packaging 
Design Guide. 

The Google solar field at our data center 
in St. Ghislain, Belgium. 

Procured over 8 GW of clean 
energy 
We signed contracts to purchase over 8 gigawatts 
(GW) of additional clean energy generation 23—more 
than in any prior year. 

A fiber- based  unglued  packaging  set. 

Reached 1 billion users to inform 
more sustainable choices 

Delfzijl wind farm in the Netherlands For the past three years, we’ve provided information 
(63 MW for Google). to over 1 billion users to help them make more 

sustainable choices annually through our products. 24

7 



Launched the first FireSat Replenished 64% of our 
satellite to detect wildfires freshwater consumption,  

up from 18% 
The first satellite for the FireSat constellation launched 
and officially made contact with Earth. This satellite is Our water stewardship projects replenished 
one of more than 50 in a first-of-its-kind constellation approximately 4.5 billion gallons of water (17 billion 
designed to use AI to detect and track wildfires as liters or 17 million cubic meters) in 2024 alone, 
small as a garage (roughly 5x5 meters). roughly 64% of our freshwater consumption. 25

Multi--benefit  floodplain  restoration  along  the  
Tuolumne and San Joaquin rivers in California. 

Enabled 26 million tCO2e 
emissions reductions through 

The launch of the first satellite for the 
FireSat constellation. five products 

Five of our products (Nest thermostats, Google  
Earth Pro, Solar API, fuel-efficient routing in Google 
Maps, and Green Light, which represent only a 
subset of our efforts) enabled individuals, cities,  
and other partners to collectively reduce an 

Improved TPU power efficiency estimated 26 million metric tons of GHG emissions. 26 

by 30x from 2018 
Ironwood—the first Google TPU designed to power 
thinking, inferential AI models at scale—is nearly 30 
times more power efficient than our first Cloud TPU 
from 2018. 27 Expanded fuel-efficient routing 

worldwide 
As of January 2025, fuel-efficient routing in Google 
Maps is available globally. 

Ironwood: The first Google TPU for the 
age of inference. Fuel-efficient routing in Google Maps. 

8 



Global challenges and dependencies 
Progress toward environmental ambitions requires navigating a web of interconnected challenges. Many external 
factors shape the pace and impact of these efforts, each demanding collaboration. Understanding these global 
complexities provides crucial context for our strategic approach, highlighting both where we’re making progress 
and where significant work remains. 

Growing demand for digital services 
As AI and other technologies expand to unlock new economic and social benefits, the demand for digital 
services has grown rapidly, which in turn creates demand for data centers that require increased energy 
for operations and water for cooling. As a result, meeting corporate environmental ambitions isn’t simply a 
matter of reducing today’s footprint—it requires working to reduce emissions while simultaneously scaling 
infrastructure to meet growing demand and realize the opportunity of AI. This greatly increases the scale 
of the challenge. 

Market barriers to sourcing carbon-free energy 

Companies face a range of market barriers when working to source carbon-free energy for their 
operations and supply chains: constrained transmission grids, higher effective costs for clean energy, 
fragmented and insufficiently connected electricity grids, energy technologies in varying states of 
maturity, regulatory and tax considerations, and more. These challenges are particularly pronounced 
in certain regions like Asia Pacific and parts of the United States. Addressing these barriers will require 
coordinated efforts across companies, policies, and technological innovation to drive meaningful change. 

Data gaps and evolving standards 
Gathering accurate data on indirect emissions from supply chains remains a challenge. Further, regulations 
and reporting standards continue to evolve—creating complexity for companies as they work to develop 
and implement effective strategies. Faster reform and better alignment of climate standards would help 
bring consistency and comparability and drive better measurements and incentives—especially for long-
term clean energy investments and supply-chain emissions reductions. 

Turning corporate action into real impact on nature 
The biodiversity crisis, evident in the rapid decline of species and vital habitats around the world, 
requires real, on-the-ground action. Translating corporate actions into positive, measurable results 
can be challenging—especially with the complexity of local contexts, the interconnected value-chain 
dependencies of sectors like consumer hardware and agriculture, and the lack of standardized metrics for 
tracking nature’s recovery. Harnessing the analytical and predictive capabilities of AI could help untangle 
these complexities. 

9 



Age of AI 



Age of AI 
Contents 

12 Powering prosperity: The economic upside of AI and the energy required to 
power it 

13 Optimal scenario: AI’s net-positive potential 
14 AI efficiency gains: Improvements across models, TPUs, and infrastructure 
16 Piece of the puzzle: Situating AI in our overall electricity growth 

We believe the technological advancements in AI are profoundly transformational and will provide 
compelling and helpful benefits across four key areas: people, the economy, science, and society. 
These benefits stem from AI’s capacity to assist, complement, empower, and inspire people in almost every 
field of human endeavor. AI has the potential to contribute to tackling some of society’s most pressing 
challenges and opportunities, including serving as a crucial climate solution. 

Our approach to developing and harnessing the potential of AI is grounded in Google’s founding mission— 
to organize the world’s information and make it universally accessible and useful—and is shaped by our 
commitment to improve the lives of as many people as possible. It’s our view that AI is now, and more than 
ever, critical to delivering on that mission and commitment. 

We take a full-stack approach to AI innovation, meaning we build and optimize every layer of the AI 
development process—from the physical infrastructure in our data centers and the design of our chips to the 
development of AI models and the products that use them. This allows us to drive efficiencies throughout 
the entire system, not only minimizing our environmental footprint but also making good business sense, as it 
enables us to develop and deploy cutting-edge AI technologies with greater speed and agility. 

Rendering of MethaneSAT. (Photo credit: MethaneSAT LLC) 

Plastic curtains hang in a network room inside our data center in Sundar Pichai, CEO of Google and Alphabet, shares 
Council Bluffs, Iowa. Trillium—our sixth--generation TPU——at Google I/O in 2024. 

11 



Powering prosperity 
The economic upside of AI and the energy required to 
power it 

AI is fueling progress across sectors—from accelerating innovation in advanced energy technologies and 
optimizing grid systems to improving energy security and advancing areas like materials science and energy 
production forecasting. To realize its promise, AI itself needs energy to power these solutions. 

Zooming out, the rise in energy consumption isn’t only about AI—it’s a symptom of a bigger shift happening 
across the globe. As the digital economy expands, so does our collective need for electricity. It’s not just 
data centers driving this demand, we’re seeing this shift everywhere: from industrial production and the 
electrification of industries to increasing cooling needs amid record-breaking temperatures. 

The good news? Economists have long found a direct causal relationship between energy consumption and 
economic growth. 28 Energy is a key driver of productivity and income, not just a byproduct of expansion. 
Technological development drives growth and prosperity, and AI is poised to be a central driver of the next 
wave of expansion. 

While there’s a large focus on the energy consumption of data centers, they account for a relatively small 
portion of both current and projected electricity use. In 2024, data centers made up just 1.5% of global 
electricity consumption. 29 They’re projected to account for about one-tenth of the growth in global 
electricity demand by 2030—a smaller share than industrial motors, air conditioning, or electric vehicles. 
With this growth, data centers are projected to represent only about 3% of total global electricity demand in 
2030, 30 despite delivering an outsized contribution to economic growth and scientific advancement. 

We realize the opportunity before us demands bold action, such as investing in infrastructure, creating 
smarter grids, and ramping up both mature and emerging sources of energy generation. It also means 
partnerships between governments and businesses to innovate faster and train a workforce capable of 
building the energy systems of the future. 

Powering a new era of innovation 
AI presents a generational opportunity for extraordinary innovation and growth. The deployment of AI 
will grow the economy, create jobs, accelerate scientific advances, and more. 

Fully realizing these opportunities requires an effort to rapidly increase the capacity of existing, and 
sometimes antiquated, energy systems. This in turn requires accelerating innovation and investment in 
advanced energy technologies, optimizing use of the existing grid and unlocking construction of new 
transmission infrastructure, and developing the labor force needed to build new energy infrastructure. 

In a paper titled Powering a New Era of American Innovation, we share 15 policy opportunities for the 
United States. Many of these proposals have been incubating in policy circles for some time. They 
reach across a broad base of stakeholders and are drawn from the broader discussion of policy 
options. Unlocking advanced electricity resources and grid infrastructure would enable all sources of 
electricity to contribute to a more reliable and affordable energy future—an outcome that will require 
constructive public and private collaboration to advance. Additionally, many of these solutions could 
be applied around the world to advance a more secure energy future for all. 

12 



Optimal scenario 
AI’s net-positive potential 

AI remains at an inflection point, and many factors will influence its ultimate impact. These include the 
extent of AI adoption, the size of AI’s energy footprint, the emergence of regulatory frameworks, and the 
pace of continued innovation and efficiency. 

Consequently, the net impact of AI on emissions similarly depends on how these factors play out. The 
International Energy Agency (IEA) estimates that by 2035, widespread adoption of existing AI applications 
could lead to emissions reductions nearly three to five times greater than projected data center emissions. 31  
Furthermore, the IEA projects that—in a scenario with broad implementation—existing AI applications could 
potentially reduce emissions by around 4% of global energy-related emissions in 2035 (not including any 
breakthrough AI discoveries that may emerge in the coming decade). 32 

In an attempt to make this potential net-positive impact a reality, our approach to AI development is twofold. 
We’re focused on breakthrough innovation while also diligently managing the environmental impact and 
energy consumption of this powerful technology. 

Take the Solar API as one example. In the United States alone, the Solar API supported installations in 2024 
that we estimate will help enable partners to reduce around 6 million metric tons of lifetime GHG emissions 
(which considers emissions reductions throughout the solar installations’ entire lifetime), 33 which is about 
6,000 times greater than the approximately 1,000 metric tons of GHG emissions from the model’s compute 
in 2024. 34 We’re making solar installation easier, faster, and smarter—and it’s working. 

Visual of potential solar capacity in the Solar API. 

13 



AI efficiency gains 
Improvements across models, TPUs, and infrastructure 

As a company, we consider it an imperative to pursue AI responsibly—to innovate and deliver widely 
accessible benefits to people and society, while mitigating environmental impacts. We’ll continue to 
optimize our models and hardware, pursue infrastructure efficiencies, and procure clean energy to minimize 
the overall impact and resource demands of AI. 

Models 
Google has long been at the forefront of AI and machine learning, evolving years of deep learning research 
into techniques that make training faster and more efficient—enabling models that are higher quality, faster, 
and less compute-intensive to serve. 

We’ve sped up AI model training through techniques like quantization, boosting large-language model 
training efficiency by 39% on Cloud TPU v5e. 35 Gemini 2.5 Flash is our first fully hybrid reasoning model, 
giving developers the ability to turn thinking on or off. The model also allows developers to set thinking 
budgets to find the right tradeoff between quality, cost, and latency. 

For model deployment and usage, we’ve improved underlying ML efficiency through pioneering 
techniques like blockwise parallel decoding, improved confidence-based deferral, and speculative 
decoding that reduce the inference times of LLMs, allowing them to generate responses more quickly. 
These improvements are used across Google products and set a standard throughout the industry. 

Initiatives like these have led to generational model efficiency gains. For example, Google’s Gemini 1.5 Pro 
delivers dramatic improvements and achieves comparable quality to Gemini 1.0 Ultra while using less compute. 36 

TPUs 
For a decade, Google’s AI innovations have been powered by a range of AI accelerator options, including 
our own custom-built TPUs (Tensor Processing Units). They’ve come a long way since their first generation 
in 2015, evolving each generation to deliver better performance while improving their carbon compute 
efficiency. In early 2025, we continued this trend by building even more powerful TPUs, ensuring that our AI 
systems keep pushing forward—faster, smarter, and more efficient. 

When it comes to powering AI, efficiency isn’t just about performance—it’s about using less energy to 
do more. Announced in April 2025, Ironwood, our seventh-generation TPU, is a game-changer. Built 
specifically for inference, Ironwood performance per watt is double that of Trillium, our sixth-generation 
TPU announced last year. In fact, Ironwood is nearly 30 times more power efficient than our first Cloud 
TPU from 2018. 37 

Trillium already delivers impressive performance—67% more energy efficient than the previous TPU v5e, 38  
and it delivers 14 times more compute per watt of power compared to the first generation of Cloud TPUs. 39  
And Google Axion Processors, our first custom Central Processing Unit (CPU) designed for the data 
center, are up to 60% more energy efficient than comparable current-generation x86-based instances. 40  
Additionally, we now offer NVIDIA’s next-generation Blackwell Graphics Processing Unit (GPU) to Cloud 
customers, which NVIDIA estimates will train large models using 75% less power than older GPUs to 
complete the same task 41 and are 25 times as energy efficient compared to NVIDIA H100. 42 

14 



In 2025, we published a first-of-its-kind study on the lifetime emissions of our TPU hardware—from raw 
material extraction and manufacturing to energy consumption during operation. The results? A threefold 
improvement in the Compute Carbon Intensity 43  of our TPU chips over four years, from TPU v4 to 
Trillium 44  (Figure 1). Newer generations of TPUs like Trillium provide cutting-edge performance while 
generating fewer carbon emissions for the same AI workload. 

Figure 1. Generational trends of AI hardware life-cycle emissions intensity show a threefold 
improvement over four years 

500 

400 

300 

200 3x 
improvement 

100 

0 
v4i v4 v5e v5p Trillium 

2020 2022 2023 2024 

Legend Direct emissions from energy use Indirect emissions from energy use 

Indirect emissions from transportation Indirect emissions from data center construction 

Indirect emissions from manufacturing 

Infrastructure 
To help minimize our environmental footprint, we’ve built world-leading efficient infrastructure for the AI era. But 
we’re taking it a step further by using AI itself to directly enhance the efficiency of our data center infrastructure. 

For example, we announced AlphaEvolve, an evolutionary coding agent powered by large language models 
for general-purpose algorithm discovery and optimization. AlphaEvolve enhanced the efficiency of our data 
centers, chip design, and AI training processes—including training the large language models underlying 
AlphaEvolve itself. 

In fact, one of AlphaEvolve’s solutions to help orchestrate Google’s data centers more efficiently 
continuously recovers, on average, 0.7% of Google’s worldwide compute resources. 45 This sustained 
efficiency gain means that at any given moment, more tasks can be completed on the same computational 
footprint. 

15 

Compute carbon intensity (g CO2 /EFLOP) 



Piece of the puzzle 
Situating AI in our overall electricity growth 

While improving AI efficiency is critical, it’s only one piece of the puzzle. A broader understanding of AI’s 
total electricity consumption is essential for a more comprehensive picture of its footprint—and how we can 
effectively manage it. 

A lot has changed over the past few years. We launched Gemini, our most capable and general AI model, and 
have rapidly integrated it across our core products and platforms. Millions of people are now using generative 
AI in ways they couldn’t even have imagined in 2022, from enhancing daily tasks to powering new applications 
for developers, startups, and enterprises worldwide. 

To support all our products and digital services—including AI—our total data center electricity consumption 
grew by 27% in 2024, compared to 17% growth in the prior year. However, it’s important to note that our 
growing electricity needs aren’t solely driven by AI. The accelerating growth of Google Cloud, continued 
investments in Search, the expanding reach of YouTube, and more, have also contributed to this overall growth. 

We remain committed to maximizing AI’s potential to advance scientific discovery, accelerate human 
progress, and improve lives for people everywhere. To achieve this responsibly, we’ll continue to pursue model 
optimization, efficient infrastructure, and clean energy procurement to further drive efficiencies across AI and 
minimize its overall resource demands. 

Wind turbines spin near our data center in Eemshaven, Netherlands. 

16 



Energy for  
our data centers 



Energy for our data centers 
Contents 

19 Scaling smarter: Successfully reducing our data center energy emissions 
22 Powering today: Our record year for clean energy 
24 Powering tomorrow: Accelerating advanced energy sources 
27 Flexible future: Demand response to enable smarter electricity grids 
29 Ambitious vision, complex reality: Our efforts to decarbonize global grids 

The global energy landscape has undergone a dramatic transformation over the last two decades, marked 
by the rapid rise of clean energy technologies. This progress, however, is now met with a new challenge: 
After a long period of stagnation, the world is now experiencing significant growth in electricity demand—a 
surge driven primarily by the electrification of transportation and industry, increased demand for air 
conditioning, and also the expanding computational needs of data centers. 

Running the global infrastructure behind our products and services, including AI, takes considerable 
energy. From the beginning, we’ve focused intensely on how we manage our energy use—and how we can 
accelerate the shift to cleaner sources. 

We’ve built a pipeline of new clean energy deals that we expect to help us stay ahead of the curve as our 
energy use grows. In fact, we estimate that—once operational—the new clean energy agreements we 
signed in 2024 could generate nearly four times more electricity than our incremental load growth 
from 2023 to 2024. 46 This proactive approach is intentional. We’re aiming to not just keep up with growth, 
but to stay ahead of it—with 60 new clean energy agreements signed in 2024 alone. 

Our strategy focuses on what we can directly control, like improving energy efficiency and procuring clean 
energy for our data centers. In parallel, we invest in the breakthroughs needed for the future—including 
next-generation energy sources like enhanced geothermal and advanced nuclear, as well as  
grid-enhancing technologies. 

The clean energy advances we made in 2024 aren’t just about megawatts or milestones. They’re about 
building an energy future that’s equipped to meet tomorrow’s challenges—faster, cleaner, and more reliably 
than ever before. 

Norther Offshore wind farm in Belgium (92 MW for Google). Rødby solar farm in Denmark (55 MW for Google). 

18 



Scaling smarter 
Successfully reducing our data center energy emissions 

In 2024, the world’s appetite for energy grew substantially faster than the average growth from the previous 
decade. 47 This surge highlights the increasing energy demands of our modern infrastructure, from powering 
homes and industries to supporting the expanding digital world and emerging technologies. 

In 2024, we reduced our data center energy emissions by 12% compared to 2023 (Figure 2). We 
achieved this reduction despite our data center electricity consumption increasing 27% year-on-year due to 
the growth of our business and increasing product adoption, including AI. 

That may sound counterintuitive, but we’ve long known that reducing the emissions from our data center 
energy use is about scaling smarter. For us, it’s the result of more than a decade of work—and a strategy 
that continues to deliver real-world results. 

Figure 2. Trajectory of data center electricity consumption and data center energy emissions 

5 
Data center 40 

energy emissions 
declined in 2024 

4 

30 

3 

20 

2 

10 
1 

0 0 
2019 2020 2021 2022 2023 2024 

Year 

Legend Total data center electricity consumption Total data center energy emissions 

Clean energy procurement 
We’ve been at this for a while: our first clean energy PPA dates back to 2010. Since then, we’ve scaled 
procurement efforts to continue to meet the demands of our growing infrastructure—and to help shift the 
energy systems that power it. As electricity needs have surged, particularly with the rise of AI, these long-
term efforts have delivered results. 

In 2024, more than 25 clean energy projects we’d contracted over the past several years—some as far  
back as 2019—came online. Together, they added 2.5 GW of new clean energy to the grids that serve 
our operations. 

19 

Million tCO2e 

Million MWh 



Bringing a clean energy project online requires years of planning, permitting, contracting, and construction. 
When a project reaches commercial operation, it’s not just a milestone—it’s the realization of hard work 
done years ago finally delivering clean electricity where it’s needed. 

We also continue to make progress in bringing more clean energy to our office operations. In 2024, from 
across 14 agreements, we allocated over 140 megawatts (MW) of clean energy generation in the electricity 
grids where our offices operate. 48 

By working to provide clean energy for our data centers and other operations, we’re also avoiding a 
substantial amount of emissions. In 2024 alone, we estimate our clean energy purchases avoided more 
than 8.2 million tCO e 49

2  (Figure 3). And from 2011 to 2024, we estimate our clean energy purchasing 
cumulatively avoided more than 44 million tCO2e 50—more than the emissions from the combined annual 
electricity use of every home in New York State. 51 

Figure 3. Avoided emissions from clean energy purchases 

1  2  

11.3 
8.2 

10 9.3 
5.9 

8.0 
8 

5.5 
6.6 

5.9 4.8 
6 

5.0 
4.3 

4 
3.4 3.1 

2.5 
2 1.8 

0.8 0.9 

0 

2019 2020 2021 2022 2023 2024 

Year 

Legend 

Emissions from energy use Emissions from energy use Avoided emissions from 
without clean energy purchases with clean energy purchases clean energy purchases 

There are additional clean energy factors that led to our 2024 decrease in data center energy emissions. 
For example, in North America—a region that accounts for the majority of our electricity consumption—we 
made progress sourcing clean energy from within the same regions as our data centers, helping reduce our 
emissions. We also benefited slightly from broader grid decarbonization: across much of the United States, 
the electricity on the grid became cleaner, with associated carbon emissions dropping—some by as much 
as 10%—between 2023 and 2024. 52 That means the electricity we consumed from those grids became less 
carbon-intensive, helping us further reduce emissions. 

20 

Million tCO2 e 



Energy efficiency 
Our long-standing energy efficiency efforts are just as 
important as our clean energy procurement. Striving 
to build and operate the world’s most energy-efficient 
data center infrastructure, as well as continuing to make 
our offices more energy efficient, is a core strategy for 
minimizing our footprint. This means pursuing ways to 
squeeze more out of every watt of power we consume. 

We outfit each data center with high-performance 
servers that are custom-designed to use as little energy 
as possible compared to the amount of compute they 
process. We continuously innovate within our facilities, 
implementing smart temperature and lighting controls 
and redesigning power distribution systems to eliminate 
energy loss. And our sustained efforts have paid off. For 
the first time in six years, the average annual power 
usage effectiveness (PUE) for our global fleet of data 
centers dropped below 1.10 to 1.09 (Figure 4). 

While a PUE improvement of 0.01 might appear small, 
at the scale of our global data center operations, this 
efficiency gain avoids significant electricity consumption. 
This means our global computing network requires 
less electricity and produces fewer emissions than it 
otherwise would have, yielding meaningful savings even 

The server floor in our data center in Hamina, Finland. 
as our overall computing demands grow. 

Our data centers deliver over six times more computing power per unit of electricity than they did 
just five years ago. 53  Much of this improvement has come from deploying AI accelerators, such as our 
TPUs, the highly efficient computer chips we designed specifically for AI and machine-learning applications.

Figure 4. Energy efficiency (PUE) across Google data centers 

1 .20 

1 .18 

1 .16 

1 .14 

1 .12 

1 .10 

1 .08 

0 

2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024 

Year 
Legend Fleet-wide trailing 12-month PUE 

21 

PUE 



Powering today 
Our record year for clean energy 

Electricity is a key input for nearly everything we do—from training AI models to providing Search results to 
sharing YouTube videos and more. And as our energy demands grow, in part due to the expansion of AI, so 
does our responsibility to meet that demand in a way that’s cleaner, smarter, more reliable, and more resilient. 

In 2024, we set a new record for ourselves for clean energy procurement: we signed contracts to 
purchase over 8 GW of additional clean energy generation in 2024 alone 54—the largest annual total 
in our history and twice the volume we contracted for the prior year. That isn’t just an achievement, it’s a 
turning point—one that’s putting us on a path toward reaching our environmental ambitions. These new 
energy deals will help bring new clean energy to the grids where we operate, support advanced technology 
deployment, and model new ways of doing business that others can follow. 

22 gigawatts and counting 
Google is one of the largest corporate purchasers of clean energy, and from 2010 to 2024, we signed 
more than 170 agreements to purchase over 22 GW of clean energy generation, 55 similar to Portugal’s 
total renewable energy in 2024. 56 These purchases include agreements for over 17.3 GW in North America, 
over 4.5 GW in Europe, over 400 MW in Latin America, and over 300 MW in Asia Pacific. 

In the United States, we signed new deals in Arizona, Nebraska, and across the PJM grid region in the Mid-
Atlantic. In Europe, we expanded our offshore wind portfolio in the Netherlands, signed new PPAs in Italy, 
Poland, and Belgium, and are helping bring new onshore wind farms online across the region. In Asia Pacific, 
we advanced clean energy projects in Taiwan, Japan, Singapore, and India—with contract structures tailored 
to the unique energy and market conditions in each country. When these projects come online, they don’t just 
help reduce our environmental impact—they also add clean power to the grids that support our operations. 

Golden Hills wind farm in California (43 MW for Google). 

22 



Innovative purchasing models 
Part of what made 2024 stand out wasn’t just the volume of clean energy we contracted—it was the 
strategy behind it. 

We piloted new contract structures like the Clean Transition Tariff, a utility-rate mechanism that provides 
for long-term investment in clean power whenever it’s needed. We upscaled a new request for proposal 
model to reduce procurement time and accelerate PPA execution. We also entered into a front-of-meter 
co-location partnership in the United States where data centers and grid-connected renewable energy 
infrastructure are developed side by side, easing strain on transmission networks. 

These moves are signals of what clean energy procurement will increasingly look like in the years ahead: 
more flexible, more collaborative, and more integrated with the needs of the grid. And we’re doing it 
in ways that try to account for the real-world constraints facing today’s energy markets—addressing 
interconnection bottlenecks, aligning procurement with utility planning cycles, and designing projects that 
require fewer upgrades to connect to the grid. 

Investments with global impact 
In addition to buying clean energy through PPAs, we’re also accelerating the transition to a cleaner grid by 
making direct financial investments. This is about actively funding the construction of new clean energy 
sources that benefit everyone, contributing to a larger, more resilient clean energy ecosystem while 
stimulating local economic growth. From 2010 to 2024, we entered into agreements to invest more 
than $3.7 billion in clean energy projects and partnerships, which are expected to produce around  
6 GW of clean electricity. 57 

For instance, we’ve developed an investment framework that allows us to invest in, and buy power from, a 
1.5 GW portfolio of new solar projects throughout the PJM grid region. By providing both investment capital 
and energy offtake, these projects have a clearer path to construction. 

Essentially, we’re not just consumers of clean energy; we’re also investing in order to create more of it, using 
our resources and engineering-minded approach to help these vital projects get established and scale. 

Solar panels line up side--by--side at our data center in St. Ghislain, Belgium. 

23 



Powering tomorrow 
Accelerating advanced energy sources 

Clean energy sources that we can count on anytime and can turn on or off as needed play an important role in 
creating a reliable, affordable, and clean energy system that can power economic and scientific opportunity. 

We’re accelerating the development and deployment of next-generation energy sources—from enhanced 
geothermal to advanced nuclear and innovative biomass solutions—expanding energy opportunities 
through innovation and pushing the boundaries of what’s possible. 

Enhanced geothermal 
Imagine tapping into the Earth’s core, a virtually limitless source of heat. That’s the power of geothermal 
energy. Traditional geothermal plants utilize naturally occurring underground reservoirs of steam or hot 
water, but these resources are limited to specific geological locations. Enhanced geothermal energy takes a 
different approach, expanding the reach of this clean power source. 

Enhanced geothermal involves either engineering underground reservoirs where none existed before or 
enhancing production from existing ones. It’s similar to creating a custom-designed plumbing system deep 
beneath the surface. Using advanced drilling techniques adapted from the oil and gas industry to access 
hot, dry rock formations, water is then injected into these formations, heated by the Earth’s intense thermal 
energy, and circulated back to the surface to drive turbines and generate electricity. This process produces 
clean, consistent power with only a small land footprint and without burning fossil fuels. 

Google and clean--energy startup Fervo signed the world’’s first corporate agreement to develop a next--generation geothermal 
power project.

24 



First-of-its-kind geothermal project in Nevada 
We recognized the potential of enhanced geothermal early on. In 2021, we signed the first corporate 
agreement to develop a next-generation geothermal power project with Fervo Energy in Nevada. 
This wasn’t just a theoretical exercise; it was a real-world collaboration to prove that enhanced geothermal 
could deliver reliable, carbon-free energy. That project became operational in 2023, and carbon-free energy 
started flowing onto the local grid that serves our data centers in Nevada. 

Since then, Fervo has achieved remarkable reductions in the time and cost of its drilling process, 
demonstrating the power of early customer demand to help drive rapid improvements to early-stage 
technologies. Building upon the success of our commercial pilot, in 2024, we scaled up our partnership with 
Fervo Energy, contracting for a larger 115 MW project through a new utility rate structure with NV Energy— 
the Clean Transition Tariff. This expansion signifies a shift from pilot-scale to commercial deployment and 
will increase the amount of enhanced geothermal generation enabled by Google by almost 25 times. 

Geothermal’s global potential 
We’re also exploring the global potential of geothermal energy. In 2024, we announced a partnership 
with the University of Newcastle and its research institute Newcastle Institute for Energy and Resources 
(NIER) to further de-risk and develop geothermal energy resources in Australia. We’re also working with 
Project Innerspace on GeoMap, a free online tool that provides essential subsurface data and analytics for 
assessing geothermal potential worldwide. Think of it as providing a detailed map to help others explore this 
hidden energy resource. 

Lastly, in early 2025, we expanded our geothermal efforts to Taiwan, through a partnership with Baseload 
Capital aiming to enable 10 MW of 24/7 clean power to the grid and help catalyze Taiwan’s geothermal 
market. We’re also excited about the potential to replicate these types of projects in markets across Asia 
Pacific, such as Japan and Indonesia, as well as other places where we have electricity demand globally. 

Advanced nuclear and small modular reactors 
Nuclear energy has long been a clean source of electricity, but traditional large-scale nuclear power plants 
can be complex and costly to build. Small modular reactors (SMRs) offer a new approach, promising a more 
streamlined and flexible way to harness the power of the atom. 

SMRs are smaller than conventional nuclear reactors and designed to be manufactured in factories and 
assembled on-site. This modular design allows for faster construction, reduced costs, and greater flexibility 
in siting. SMRs also incorporate advanced safety features, often relying on passive safety systems that shut 
down the reactor automatically in case of an emergency. 

In 2024, we took a major step toward supporting this next generation of nuclear technology: we signed 
the world’s first corporate agreement to purchase nuclear energy from multiple SMRs, which will 
be developed by Kairos Power. This agreement will bring up to 500 MW of clean energy to U.S. grids by 
2035—the first reactor is expected to be operational by 2030, with additional deployments through 2035. 

Kairos Power’s SMR design uses a molten salt cooling system and a unique ceramic pebble fuel. This system 
allows the reactor to operate at low pressure, simplifying the design and enhancing safety. The company 
is following an iterative development process, building and testing multiple demonstration units before 
deploying its first commercial plant. This approach allows for continuous learning and improvement, 
ultimately leading to a more reliable and cost-effective technology. 

25 



This agreement is important for several reasons: 

• Providing “always-on” energy: Nuclear solutions offer a clean, round-the-clock power source 
that can help reliably meet electricity demands with carbon-free energy every hour of every day. 
Advancing these power sources in close partnership with supportive local communities will help 
rapidly drive the decarbonization of electricity grids around the world. 

• Supporting AI demand: The grid needs new electricity sources to support AI technologies that are 
powering major scientific advances, improving services for businesses and customers, and driving 
national competitiveness and economic growth. This agreement helps accelerate a new technology 
to meet energy needs cleanly and reliably, and it unlocks the full potential of AI for everyone. 

• Benefiting the economy: Investing in advanced nuclear technology can provide direct economic 
benefits to communities across the United States since nuclear power has the highest economic 
impact of any power generation source and creates high-paying jobs. 58 In fact, the U.S. Department 
of Energy estimates that reaching 200 GW of advanced nuclear capacity in the U.S. by 2050 will 
require an additional 375,000 workers. 59 

By procuring electricity from multiple reactors—what experts call an “orderbook” of reactors—we’ll help 
accelerate the repeated reactor deployments that are needed to lower costs and bring Kairos Power’s 
technology to market more quickly. This is an important part of our approach to scale the benefits of 
advanced technologies to more people and communities. 

Turning biomass into energy 
Clean energy innovation also involves finding resourceful ways to utilize existing resources. Our partnership 
with PacificLight Energy and Rexus Bioenergy demonstrates this approach. Together, we’re supporting a 
“waste wood-to-energy” plant in Singapore. 

This facility will convert waste wood, such as horticultural waste and wood from the logistics industry, into 
a renewable energy source. The plant is designed with advanced technology and is expected to be more 
efficient than traditional waste-to-energy facilities in Singapore. 

Expected to begin commercial operations in 2026, the plant will operate continuously. It’ll also include a 
pilot-scale carbon capture system, exploring ways to further reduce its environmental impact. This project 
showcases how innovative engineering can transform waste into a valuable energy source. 

Our data center in Singapore lit up at night. 

26 



Flexible future 
Demand response to enable smarter electricity grids 

In the not-so-distant past, data centers were seen as static power users. But today, the equation is shifting, 
and the impact of this shift is more important than many may realize. At Google, we’re reimagining our data 
centers as dynamic players in the broader electricity ecosystem. That means developing smarter ways to 
manage when and how we use power and finding new ways to work with grids. 

By designing data centers that flex—to the grid, to the weather, and to times when cleaner energy is 
available—we can reduce the need for investment in new generation or new infrastructure, alleviate strain 
during peak hours, make better use of clean energy, and support overall grid reliability. 

That shift matters more than ever. As electricity demand grows, especially with the rise of AI and cloud 
computing, grids around the world are facing increasing demands. At the same time, more clean energy is 
coming online—but it’s not always available when and where it’s needed most. Flexibility can help create a 
more cost-effective, reliable, efficient, cleaner grid—and we believe data centers can help deliver it. 

Let’s break that down a bit. 

Data centers that flex 
Imagine a world where computational tasks can be dynamically moved in response to the natural rhythms 
of the sun and wind: as solar power peaks in one region or winds strengthen in another, workloads are 
intelligently routed to harness these cleaner energy sources. Now imagine that this flexibility doesn’t 
compromise the user experience, as many non-urgent compute tasks—like creating new filter features 
on Google Photos, processing YouTube videos, or adding new words to Google Translate—don’t need to 
happen instantaneously. They can be strategically scheduled for off-peak hours or routed to data centers 
running on more readily available clean energy. 

This vision isn’t merely a future aspiration; much of it is current practice at Google. Developing flexible 
data centers means figuring out how to operate them differently—a vital evolution for a world increasingly 
committed to smarter energy use and enhanced resilience. At its heart, this approach is about the 
sophisticated alignment of our computing demands with the optimal resources, in the best locations and 
when it matters most. 

So how do we do this? Our carbon-intelligent computing platform shifts computing tasks across 
locations and times of day, based on local grid carbon intensity. This means we’re going beyond 
focusing on when we use energy to also considering the type of energy we’re using—shifting tasks to times 
and places where cleaner electricity is available. 

We’re also collaborating with utilities and other grid partners to develop our demand response capabilities, 
reducing power consumption during peak periods and ramping back up when the grid can handle it. By 
adjusting when and where computing tasks run—based on coordinated requests from local grid partners— 
we can ease pressure on local grids during high-stress periods, like extreme weather events. The platform 
does all this while still getting everything that needs to get done, done—meaning you can keep streaming 
YouTube videos, uploading photos, finding directions, or whatever else. 

In Belgium, we’re working with our grid partners Centrica Energy and the transmission system operator Elia 
to integrate our demand response capability at our local data center in conjunction with the data center’s 

27 



Our data center in Council Bluffs, Iowa, makes the best out of every inch, so you can use services like Search and YouTube in the most 
efficient way possible. 

battery storage system. As a next step, we’re joining the country’s capacity remuneration mechanism, 
helping stabilize the grid by reducing power consumption at critical times. In Asia Pacific, Taiwan Power 
Company expressed its appreciation for our continued participation in its summer load management 
program, which has helped grid operators manage the power system by reducing peak electricity loads 
during strained summer months. 

These strategies and demand response initiatives are making our computing system smarter, cleaner, and 
more flexible—helping to optimize how we allocate compute tasks across our infrastructure. 

Collaborating for the future 
We’re not doing this alone. Through our partnership, Carrier plans to leverage Google Cloud’s WeatherNext 
AI models as part of its Home Energy Management System (HEMS) to help enhance grid flexibility and 
enable smarter energy management. Once deployed, WeatherNext AI models are expected to help HEMS 
intelligently manage energy flows in real time—charging, discharging, and redirecting energy based on 
grid conditions, energy demands, and weather forecasts—contributing to a more balanced and sustainable 
energy grid. 

We’ve also joined forces with the Electric Power Research Institute (EPRI) through the Data Center Flexibility 
(DCFlex) initiative. This multi-stakeholder effort brings together energy experts, utilities, and hyperscale 
operators to develop new tools, standards, and best practices that help make data center energy use more 
grid friendly. 

Why it all matters 
Data centers are known for their energy footprint—and as demand for digital services grows, so do their 
electricity needs. But in a world where electricity demand is surging, we believe data centers can be part of 
the solution to meeting the world’s needs for reliable, affordable, clean energy. 

That’s good for the grid. It’s good for our business. And it’s a model that’s built for the energy systems of 
the future. Call it a quiet kind of power shift, but one that has the potential to create a more reliable, flexible, 
cost-effective, and resilient energy system. 

28 



Ambitious vision, complex reality 
Our efforts to decarbonize global grids 

The global energy transition isn’t just about generating more clean electricity. It’s also about aligning supply 
with demand in real time—hour by hour, grid by grid. That’s the vision behind 24/7 carbon-free energy, 
where every kilowatt-hour of electricity we use is matched with clean power produced on the same grid 
during the same hour. 

While we’ve made great progress over the years, the path ahead is anything but simple. It requires new 
tools, deeper collaboration, and systemic shifts across markets. But the reason we’re dedicated to this work 
is clear: 24/7 CFE offers a way to drive real-world reductions, accelerate grid decarbonization, mitigate 
electricity price volatility, and make the overall clean energy transition more reliable and enduring. 

Beyond the annual match 
For the last eight years, since 2017, we’ve matched 100% of our global electricity use with renewable 
energy purchases 60—a pursuit that seemed almost impossible when we set out on it back in 2012 (Figure 5). 

This milestone was an important step—but annual matching only tells part of the story. The reality is that 
most grids today still rely on fossil fuels for portions of the day, especially during evenings or times when 
renewable sources aren’t producing electricity. Even if a company buys clean energy in bulk and applies 
it to match its total usage over the course of the year, its real-time energy mix likely includes electricity 
generated from fossil fuels. 

Figure 5. Clean energy purchases compared to total electricity use 

35 

30 

25 

20 

15  Google 
first achieved 

100% renewable 
Google energy match 

10 Google announced pursuit 
signed of 100% renewable 

our first energy match 
PPA 

5 

0 

2010 2011  2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024 

Year 

Legend Total electricity consumption Global renewable energy matching 

29 

Terawatt-hours 



24/7 CFE aims to address this discrepancy. Through this approach, we’re working to match our electricity 
use with clean energy generated locally and in real time—matching electricity consumption with clean 
power generation on the same grid, in the same hour. This requires a portfolio of solutions—clean energy 
generation, energy storage, smarter computing loads, and advanced market instruments like time-based 
energy attribute certificates (T-EACs). 

Real impact, shared outcomes 
We believe that 24/7 CFE isn’t just a wonky metric or our own moonshot—it’s a blueprint for global grid 
decarbonization. By aligning our purchases to fill clean energy gaps on grids, we can help shift demand to 
lower-carbon hours, create new markets for emerging technologies, and send clearer investment signals to 
energy developers. 

That’s why we’re not just doing this for ourselves. We’re working with partners across sectors to scale this 
model, sharing methodologies, collaborating on procurement standards, and supporting policy frameworks 
that make 24/7 CFE more accessible for everyone. 

Navigating real-world constraints 
Still, there are structural barriers that no single company can overcome on its own. Interconnection delays, 
market fragmentation, and regulatory bottlenecks continue to limit how fast clean energy can come 
online—and how easily it can be matched to local demand. Even as we expand our contracting in emerging 
markets and regions with higher carbon intensity, we still face logistical and economic constraints: limited 
local supply, permitting challenges, and other hurdles that can slow technology deployment. 

In 2024, we continued to navigate a complex global energy landscape. We achieved significant progress 
by increasing our global carbon-free energy percentage across our data centers and offices to 66%.  61  
This 2% increase compared to last year is particularly noteworthy given the 27% increase in our electricity 
consumption to support our growing business, including AI. While this global average reflects strong 
progress, our journey varied by region. In Asia Pacific, for instance, our regional average Google CFE was 
12%—well below that of other regions, like 70% in North America and 92% in Latin America. 62 In response, 
we’re advancing new paths for clean energy in Asia Pacific specifically, like solar aggregation and piloting 
investments in new clean energy projects. 

This regional variability is a reminder of what makes 24/7 CFE so powerful, and so complex: it doesn’t hide 
the gaps. It shines a light on them. 

Accelerating new tools like T-EACs 
To overcome these challenges, we’re developing new tools and strategies—like time-based energy attribute 
certificates (T-EACs), sometimes referred to as Granular Certificates. 

T-EACs are an important tool for achieving our own climate moonshots, as well as for making hourly energy 
procurement more accessible to more companies in support of broader efforts to fully decarbonize 
electricity systems worldwide. That’s because T-EACs enable clean energy generation to be purchased, 
traded, and tracked on an hourly basis, offering a more credible and impactful clean energy procurement 
instrument than traditional energy attribute certificates (EACs). 

T-EACs can help enable reliable clean energy procurement in an era of rapid load growth. We retire T-EACs, 
which come bundled with our PPAs, to match a portion of our hourly electricity demand. Many of these 
instruments are now certified by Flexidao and can be traded to allow for hourly matching by others. 

30 



After being the first major company to pilot T-EACs in 2021, we achieved two new milestones in 2024. We were 
the first company to receive bundled T-EACs issued directly by an EAC-issuing body in Europe, and we tested 
the purchase of unbundled T-EACs 63—both milestones that are helping build a market for these instruments. 

We’ve also invested in the data infrastructure to make this possible. In 2024, we supported Electricity Maps’ 
expansion to global coverage of real-time grid-emissions data, adding over 100 countries to its platform. 
And through our partnership with LevelTen Energy and a coalition of energy innovators, we helped launch 
the Granular Certificate Trading Alliance to create a marketplace for hourly energy matching instruments. 

Because market standards are still evolving, we’re working to help shape them. In 2024, we co-authored a set 
of contracting principles with the Eurelectric 24/7 CFE Hub, aimed at helping clean energy buyers and sellers 
move toward greater hourly energy matching. Our published procurement principles for advanced clean 
energy technologies also guide our approach, ensuring that what we buy helps accelerate grid impact. 

Evolving energy markets 
Equally important to our own operational efforts to achieve 24/7 CFE is our work to help create an energy 
system that’s fit for the future—one that can scale to meet the demands of AI, electrification, and economic 
development with minimal environmental impact. 

Beyond focusing on clean energy contracts, we’re working on market transformation—from new electricity 
rates to grid planning. Through partnerships with utilities and system operators, we’re supporting smarter 
infrastructure design and load shaping that makes 24/7 CFE more feasible. We’re even partnering with other 
companies to capitalize on our combined demand for advanced clean energy solutions, such as enhanced 
geothermal, advanced nuclear, clean hydrogen, and long-duration energy storage. 

An interconnection substation at Fervo Energy’ ’s enhanced geothermal plant in Nevada, a firs-t-o-f-i-ts-kind project developed in 
partnership with Google.

31 



While 24/7 CFE is a long-term challenge, the progress we’ve made so far shows what’s possible when 
ambition meets collaboration, data, and transparency (Figure 6). And we’ll keep expanding our toolkit: 
contracting innovative projects, refining how we measure real-world impact, and building the infrastructure 
for others to join us. 

Ultimately, 24/7 CFE isn’t about any one company hitting a perfect score. It’s about rethinking clean energy 
as something you don’t just buy—but something you match, precisely when and where it’s needed. This 
takes decades-long clean energy contracts, new infrastructure, grid-level coordination, and detailed 
systems planning—layered with flexibility, investment, and long-term thinking. 

In many ways, this work is constant. Data centers don’t stop running to wait for clean power. Offices don’t 
turn off the lights while we negotiate energy contracts. But every watt of cleaner electricity we bring online 
makes a difference. 

We’ll keep doing what we’ve done from the start: tackle the parts we can directly control, stay accountable to 
real-world impact, and help build an energy system that can meet the demands of the future while protecting 
the planet. That means smarter energy use, more clean power, and a grid that works better for everyone. 

Figure 6. Carbon-free energy map for grid regions with Google-owned and -operated data 
centers 64 

32 



Energy for our  
supply chain 



Energy for our supply chain 
Contents 

35 Supplier synergy: Shared tools, partnerships, and clean energy agreements 
36 APAC’s brighter future: A solar solution in Taiwan 
37 Conducting change: Focusing on high-impact semiconductor suppliers 
38 Supply chain transformation: Why it’s slow, why it’s messy, and why it  

really matters 

When people think about reducing environmental impacts, they might picture electric vehicles, rooftop 
solar panels—maybe even plastic alternatives. But there’s a part of the climate story that doesn’t get as 
much attention: the supply chain behind your phone, thermostat, or smart speaker, and the data center 
hardware they rely on. And it’s one of the trickiest parts of the puzzle; the further you zoom out—from the 
device in your hand to the global network that made it—the more complex the system becomes. 

For Google, much of that challenge starts in Asia Pacific, where our suppliers manufacture many of 
the core components of our hardware. These facilities often require lots of energy—especially when it 
comes to making semiconductors, the chips that power everything from your phone to our data centers. 
Manufacturing at this scale also demands constant, stable, reliable electricity. And in many parts of the 
world, especially where these factories are located, that often means tapping into regional grids that are 
heavily reliant on fossil fuels. 

Expanding clean energy access across much of Asia Pacific faces significant hurdles, including policy 
barriers, grid infrastructure that struggles to integrate clean energy, and gaps in financing mechanisms— 
although notable developments are accelerating access in specific markets like India and Vietnam. And 
despite its challenges, this transition to clean energy brings meaningful co-benefits to our supply chain—like 
fostering greater resilience and stability. 

Changing how energy is sourced isn’t as simple as walking into a supplier’s factory and flipping a clean 
energy switch. These are independent businesses, navigating their own regulatory environments, 
infrastructure limitations, and financial constraints. Our role is to partner—bringing resources, incentives, 
and technical support to help suppliers make meaningful, measurable progress toward clean energy, which 
in turn can help them manage energy costs and prepare for evolving regulations. 

Rows of machinery on a production floor. 

34 



Supplier synergy 
Shared tools, partnerships, and clean energy agreements 

We’re working to tackle our supply chain emissions with a mix of technical tools, direct supplier 
partnerships, and clean energy agreements and investments. 

One practical resource we developed is an Energy Assessment tool. This is a free tool designed to be 
used without deep technical expertise that helps supplier facility managers identify energy efficiency 
opportunities across their operations. These managers can get a snapshot of where energy is being lost— 
whether it’s outdated chillers, inefficient motors, or poor lighting—and get guidance on which upgrades 
could yield the biggest energy consumption improvements and cost reductions. But efficiency alone isn’t 
enough. That’s where carbon-free energy comes in. 

In 2023, we began rolling out the Google Clean Energy Addendum (CEA)—an agreement asking 
suppliers to commit to achieving a 100% clean electricity match by the end of 2029 for the electricity 
they use to manufacture Google products. 65 We see this as a cornerstone of our strategy—not just a 
recommendation, but a shared agreement to market change. It’s already become a central part of how we 
work with our key suppliers—especially those with the highest energy use. By the end of 2024, many key 
suppliers signed our CEA, and we plan to continue driving clean energy progress within our supply chain 
through our CEA, clean energy investments, and other initiatives. 

We know this takes time, which is why we’re working directly with suppliers to identify practical next steps, 
offer hands-on support, and share tools that make the transition more manageable—from navigating  
clean energy procurement to tracking progress—all of which ultimately strengthen the resilience of our 
supply chain. 

Minco II wind farm in Oklahoma (102 MW for Google). 

35 



APAC’s brighter future 
A solar solution in Taiwan 

Of course, even the most motivated suppliers can’t switch to clean energy if it’s not available. That’s why 
Google isn’t just supporting clean energy procurement—we’re helping create it. 

In 2024, we announced an investment to support the development of a 1 GW pipeline of new solar 
energy in Taiwan, an investment that focuses on a region that plays a prominent role in global technology 
supply chains. We expect to procure solar energy from these projects, and we may offer a portion of this 
clean energy to our semiconductor suppliers and manufacturers in the region so they can advance their 
own sustainability ambitions while helping reduce emissions in our shared supply chain. It’s a model that 
goes beyond carbon accounting to enable broader action—removing barriers so others in our supply chain 
can make better and cleaner choices too. 

This kind of intervention is becoming more important as the global clean energy sector faces bottlenecks. 
Many countries in Asia Pacific face unique challenges when it comes to adding new carbon-free energy, 
including land constraints, low availability of commercially scalable wind and solar resources, and high 
construction costs. By getting directly involved in energy markets, we aim to help bridge some of those 
gaps, grow the supply of available renewable energy sources, and promote emerging technologies that 
enable the decarbonization of regional electricity systems. 

The work builds on more than five years of collaboration to accelerate the clean energy transition through 
market and policy development across Asia Pacific. Our advocacy and engagement efforts were a key 
driver of the 2017 amendment of Taiwan’s Electricity Act, which opened up the market to allow non-utility 
companies to directly purchase renewable energy. This effort led to us becoming the first corporate buyer 
to sign a PPA in the market. 

Looking beyond Taiwan, we continue to drive progress throughout the Asia-Pacific region—marked by 
announcements in Australia, India, Japan, and Singapore. These examples show meaningful strides in our 
ongoing journey, yet they also serve as a reminder that a far greater collective effort is needed—both within 
the dynamic landscape of Asia Pacific and around the world—to truly tackle this challenge. 

Our data center in Changhua County, Taiwan, is a center of community building and innovation. 

36 



Conducting change 
Focusing on high-impact semiconductor suppliers 

Not every part of a supply chain has the same level of impact. Some processes are far more carbon-
intensive than others, and the semiconductor industry is among the most emissions-intensive for Google. 
Making chips requires not only lots of electricity but also the use of extremely potent greenhouse gases. 

We’re actively focusing on this “hotspot”—a specific part of our supply chain where emissions are 
disproportionately high. We’re a founding member of Catalyze, a group working to decarbonize 
semiconductor manufacturing, and we partner with industry-wide efforts like the Sustainable 
Semiconductor Technologies and Systems program and SEMI’s Semiconductor Climate Consortium. We’re 
also a steering committee member of the Clean Energy Buyers Association’s Clean Energy Procurement 
Academy, which delivers tailored trainings to help our suppliers make high-impact clean energy purchases. 
These partnerships are about more than just advocacy: they also help drive shared research and 
development, advance manufacturing processes, and create standards that ripple across the industry. 

Collaborating creates real momentum—especially when the work is shared and sustained across the supply 
chain. When we pull in the same direction, things move faster. 

Ironwood is our most powerful, capable and energy efficient TPU yet, designed to power thinking, inferential AI models at scale. 

37 



Supply chain transformation 
Why it’s slow, why it’s messy, and why it really matters 

Transforming a global supply chain is never quick or easy. It’s a long game filled with logistical hurdles, 
economic trade offs, regional challenges, and infrastructure constraints. Our efforts go beyond our own 
operations—we’re working to influence the broader systems and structures that shape how our industry 
uses energy. 

That’s why progress can often look like a patchwork of small wins—from suppliers upgrading their facilities 
and sharing decarbonization roadmaps to signing our CEA and committing to clean energy procurement. 
Taken together, we believe these moves have great collective impact, and when they happen at scale, they 
can shift market demand, create new norms, and accelerate broader change. These steps also bolster supply 
chain resilience and help companies stay ahead of potential regulatory requirements or reporting needs. 

There’s often a temptation to focus only on what’s most visible—what the consumer sees. But much of the 
progress needs to happen upstream, in the guts of the system. Clean energy transitions are often described 
in terms of breakthroughs—technology, policy, or pricing. But perhaps equally important are the slow, 
painstaking efforts to build trust, share risk, and coordinate action across companies and boundaries. It’s 
not always flashy, but it’s essential. 

We believe that’s the power of supplier engagement. And it’s one of the most powerful tools we have for 
scaling solutions to meet the urgency of the moment, while simultaneously building a more stable, resilient, 
and competitive supply chain for the future. 

A logistics program manager at our data center in Singapore. 

38 



Resource efficiency 



Water stewardship 
Contents 

40 Advancing responsible water use: Our approach to climate-conscious data center cooling 
42 Replenishing water: A local approach to water stewardship 

Water is one of the most essential resources on Earth. And though water risk varies by location and isn’t 
present everywhere, growing concerns in many regions mean managing this precious resource is no longer 
just a responsibility, but a necessity. We’re working to do just that through a strategy centered on advancing 
responsible water use at Google, benefiting watersheds and communities, and supporting water security 
with technology. 

Advancing responsible water use 
Our approach to climate-conscious data center cooling 

Google’s data centers are the engine of our company, powering products like Google Workspace (which 
includes Gmail, Drive, Docs, and more), Google Cloud, Search, and YouTube for billions of people around the 
world. And as we grow to serve more users globally, building new data center infrastructure is essential. 

To operate smoothly, these facilities rely on cooling systems that frequently use water due to its energy 
efficiency. This dependency highlights a critical balance between technological needs and responsible 
environmental stewardship. In 2024, we consumed a total of approximately 8.1 billion gallons (31 billion liters 
or 31 million cubic meters) of water across our data centers (excluding those operated by third parties) 
and offices. To put that consumption into perspective, that’s about what it takes to irrigate 54 golf courses 
annually, on average, in the southwestern United States. 66 Crucially, the majority of this consumption occurred 
in regions where water resources are abundant: in 2024, 72% of our freshwater withdrawals came from 
sources at low risk of water depletion or scarcity. 67 

Enter Google’s climate-conscious cooling strategy, our multidimensional methodology for choosing cooling 
systems for our data center campuses. This approach recognizes that water is the most efficient means of 
cooling in many places and, when used responsibly, water cooling can play an important role in reducing 
emissions. So, at each data center campus, we look at balancing the availability of carbon-free energy and 
responsibly sourced water to minimize the net climate impact both today and in the future. 

Climate-conscious cooling in the United Kingdom 
The area surrounding our new data center location in Waltham Cross in the United Kingdom receives water 
from sources along the Lea and Thames valleys, which are under stress from recent severe drought events. 

40 



Cooling towers at our data center in Mayes County, Oklahoma. 

An overhead view of one of our cooling plants in  A rainwater retention pond outside one of our data centers in 
Hamina, Finland. the Lowcountry, South Carolina. 

This situation is exactly what our data center water risk framework is designed to help us navigate. The 
framework is a data-driven tool we use globally to evaluate the specific risks of water scarcity and depletion 
in the watersheds where we plan to operate, guiding our technology choices before construction begins. We 
don’t take a one-size-fits-all approach; instead, we use data to understand the local environmental context. 

We applied the framework to the specific water sources serving Waltham Cross, and the results did indeed 
present a high risk of water depletion and scarcity. So, to operate responsibly and minimize our impact on 
this vital local freshwater resource, we decided to utilize air cooling technology at this site—an approach that 
doesn’t consume water for cooling during routine operations. 

We’re taking a similar approach in other areas identified as having high water risk through our framework, 
such as our facilities under development in Mesa, Arizona and Canelones, Uruguay. For us, the assessment of 
the water sources for Waltham Cross was more than just a site- or region-specific decision; it’s another proof 
point that our global, data-driven framework aligns with and supports responsible water use tailored to local 
environmental conditions. 

Responsibly using water isn’t only relevant for our data centers—we’re also developing and implementing 
responsible water use practices across our global office portfolio. We’ve intentionally designed these water 
practices to cover all aspects of water use in our offices, including food preparation, cleaning and sanitation, 
campus landscape irrigation, and workspace cooling systems. For example, our new hardware office 
in Taiwan features water infrastructure innovations like a stormwater capture system as well as other 
infrastructure improvements like water-efficient fixtures and the use of non-potable water for toilet flushing. 

As our business continues to grow, so does our water use: our overall water consumption increased by 28% 
from 2023 to 2024. However, making informed, locally attuned decisions—like choosing air cooling in Waltham 
Cross, Mesa, and Canelones—is central to our responsible water use. It’s how we strive to implement climate-
conscious cooling strategies and manage our water footprint carefully, even as demand for our services 
expands around the world. 

41 



Replenishing water 
A local approach to water stewardship 

Water stewardship isn’t just about managing our consumption. It’s also about ensuring that we give back 
more than we take—especially in regions that have a higher risk of water scarcity or depletion. That’s why 
our water replenishment strategy focuses not only on replenishing more water than we consume, but also 
on improving water quality and ecosystem health in the communities where we operate. 

In 2024, our water stewardship projects replenished approximately 4.5 billion gallons of water (17 
billion liters or 17 million cubic meters), roughly 64% of our 2024 freshwater consumption. 68  We added 
38 new water stewardship projects, increasing our total portfolio to 112 projects spanning 68 watersheds in 
2024 (Figure 7). Many of these projects go beyond replenishing water to also support watershed health by 
improving water quality, biodiversity, and community co-benefits. 

Figure 7. Global water stewardship project map as of the end of 2024 

Legend 

Project category Total 

Land conservation & restoration 21 

Water supply reliability 42 

Water, sanitation, & hygiene (WASH) 9 

Aquatic habitat restoration 24 

Water quality 16 

Total projects 112 

42 



Groundwater recharge in California’s Central Valley 
Local water issues are often complex and contextual. That’s why Google’s approach to water stewardship is 
rooted in partnerships with local communities and organizations. We focus on projects that have a tangible 
impact—such as restoring ecosystems, improving irrigation efficiency, and supporting communities’ water 
supply reliability. 

Take the San Joaquin River, which winds through California’s Central Valley, a region that acts as an 
agricultural engine for the nation. Think fruits, vegetables, nuts—a staggering share of the U.S. supply 
originates here, 69 all cultivated through reliance on irrigation. But this vital production faces a challenge 
simmering beneath the surface: groundwater depletion, making the health and restoration of the San 
Joaquin River more critical than ever for sustaining this food production powerhouse. 

Addressing this critical need for water resilience requires innovative approaches and collaboration with local 
actors. Recognizing this, Google stepped in, partnering with the North Fork Mono Tribe, the Sierra National 
Forest, and Trout Unlimited. We worked together to restore eight degraded wet meadows—key areas that 
act like natural sponges when healthy. They soak up melting snowpack and rainfall, storing water near the 
surface and slowly releasing it over time. 

The restoration involved techniques tailored to bring back the meadows’ natural water-holding function, 
which in turn can unlock multiple benefits: reduced downstream flooding, improved wildlife habitats, and 
crucially, increased groundwater recharge. This type of intervention is vital for replenishing the underground 
supplies that the communities and farms of the Central Valley depend on, helping to secure a healthier 
water future for the region. 

Just upstream, we worked on another water 
stewardship effort that brought together 
public and private partners to tackle 
groundwater depletion directly within the 
Central Valley. Using insights from state 
studies, we planned on-the-ground recharge 
projects and conducted feasibility studies on 
four additional San Joaquin River tributary 
watersheds with Sustainable Conservation. 
This work will also improve groundwater 
resilience, helping local farmers adapt to 
changing water availability. 

Through partnerships spanning headwaters 
to floodplains, these San Joaquin River 
projects embody our approach to water 
stewardship: actively replenishing water 
and enhancing ecosystem health in a region 
critical to both California and the nation. 

For more details on all the water stewardship 
projects we’ve supported as of the end 
of 2024, refer to the 2025 Google Water 

A farm in California’’s Central Valley. (Photo credit: Paolo Vescia) 
Stewardship Project Portfolio. 

43 



Waste reduction 
Contents 

44 Reverse supply chain: Giving hardware a second life 
46 Food waste: Resourceful recipes and smarter services 

Accelerating the circular economy through innovation and enhanced resource efficiency is critical to 
managing raw material extraction and minimizing environmental impacts. That’s why we set out to become 
a more circular Google by maximizing the reuse of finite resources across our operations, products, and 
supply chains—while enabling others to do the same. 

Reverse supply chain 
Giving hardware a second life 

When you think about strategies for reducing the environmental impact of data center hardware, the 
obvious approaches may be energy efficiency or clean energy procurement. But there’s a less talked 
about—yet also important—piece of the puzzle: hardware longevity via the reverse supply chain. 

What is a reverse supply chain? 
At its core, a reverse supply chain is the process of moving products back through the supply chain after 
they’ve served their original purpose. For us, that means repurposing hardware components through reuse, 
recycling, or resale—keeping them out of landfills (Figure 8). It’s about extending the life of things that could 
otherwise be discarded and therefore reducing the need to extract raw materials to produce new hardware. 
And it’s one of the most impactful strategies to make our data center operations more circular. 

Figure 8. Data center hardware reverse supply chain 

Reused hardware 

Inventory 

PCBAs 
Deployed Decommissioned Hardware 

CPUs hardware hardware harvesting 

TPUs/ASICs 

Memory 
Excess and 

obsolete 
HDD hardware Recycled hardware 

Thermal 

Mechanical 

Electro-mechanical Resold hardware 

44 



Why does a reverse supply chain matter so much? 
As we continue to scale our data centers to meet the growing demand for our products and services, 
including AI, reducing waste is essential: in 2024, we diverted 84% of our operational waste from 
disposal across our global Google-owned and -operated data centers. A large part of that success 
comes from our Reverse Supply Chain program, which enables us to reclaim components from 
decommissioned hardware and repurpose them, cutting down on material consumption and emissions. 

We’re not just recycling—we’re giving our data center hardware a second life. In 2024, we harvested 
approximately 8.8 million components from our decommissioned hardware for reuse or resale 
through our Reverse Supply Chain program—including over 3 million hard drives that were securely 
wiped and reused or resold. That’s millions of parts kept in circulation instead of being newly made. As an 
example of our efforts in this space, in 2024, 44% of components used for Google-managed server builds, 
maintenance, and upgrades were from reused inventory. 70 Reused components generally mean fewer 
raw materials, less energy, and fewer emissions from manufacturing new components—three things we’re 
working hard to reduce. 

In addition to our reverse supply chain efforts, a portion of this impact was driven by our Fleet Deployment 
Sustainability programs, which strategically target decommissioning of specific data center hardware for 
harvesting. In 2024, our hardware harvesting program helped us reuse more than 293,000 components to 
fulfill new demand. 

Reselling data center hardware components isn’t 
always easy. It requires us to securely wipe data, 
maintain component functionality, and ensure that 
any reused components are reliable. But we believe 
it’s essential for reducing the environmental impact 
of hardware. Since 2015, we’ve resold more than 
51 million hardware components from our data 
centers into the secondary market for reuse by other 
organizations, including more than 6.7 million resold 
components in 2024 alone. These are components 
that can still be used by other organizations, saving 
them from having to source new materials, in 
turn avoiding the corresponding impacts of the 
manufacturing process. 

When reuse or resale aren’t viable options, we 
responsibly recycle our data center hardware. In 
2024, this included securely crushing and deforming 
or shredding on-site (to protect data security) and 
then recycling approximately 1.9 million hard drives. 

So, the next time you’re using a Google product 
powered by our data centers, know that some of the A Googler swaps out a motherboard at our data center in  

The Dalles, Oregon. 
hardware that supports it had a second life. 

45 



Food waste 
Resourceful recipes and smarter services 

Tackling operational waste extends beyond our data center hardware to another critical area: food. The 
journey from farm to fork is fraught with potential food loss and waste—along with the water, energy, and 
other resources that went into producing it. Addressing this complex food waste challenge requires a 
comprehensive strategy focused on both waste reduction and diversion. 

Prevention is paramount. We’re enhancing strategies across the entire food life cycle—from responsible 
sourcing and procurement to optimizing kitchen operations and finding innovative uses for surplus food. 
This focus on reduction minimizes the amount of waste that needs subsequent diversion from landfills. 

Consider our Bay View campus in Mountain View, California, which exemplifies this multipronged approach. 
We’re tackling food waste by creatively incorporating ingredients that might otherwise be discarded. This 
includes using upcycled products and sourcing “imperfect” but perfectly good items—think surplus farm 
tomatoes transformed into pizza sauce, or visually blemished yet still delicious apples. We’ve also put 
guidelines in place to donate surplus food to those in need, and we’re working with local communities to 
improve composting infrastructure. 

Simultaneously, we optimize kitchen workflows through inventory management and demand forecasting. 
Crucially, AI enhances these efforts, providing chefs with data-driven insights to refine menus and reduce 
waste, while generative AI helps synthesize findings and tailor solutions unique to Bay View’s needs, 
preventing waste before it even occurs for the many Googlers dining there daily. 

At Bay View and elsewhere, these integrated efforts— 
combining operational changes with behavioral 
nudges—are yielding results. In 2024, we reduced 
food waste per Googler by approximately 39% 
compared to 2019. 71 For the waste that does occur, 
our focus shifts to responsible diversion. In 2024, we 
diverted 85% of food waste from landfill through 
composting, donations, or other recovery efforts. 

This work isn’t isolated to one campus; these 
principles are applied across our global operations, 
because every bite counts. And surprisingly, the 
difficult part is actually repeating the easy stuff— 
ensuring sustained efforts in every cafe and kitchen 
across our global operations every day. In 2025, we’re 
doubling down on reducing preventable food waste, 
such as overproduction and expired products, and 
focusing on specific regions and offices where we In our kitchen and cafe operations, we’r’e focused on ways to 
have larger gaps to close. stop food waste before it starts. 

46 



Nature on  
our campuses 

Contents 
47 Restoring habitat: Cultivating nature on our campuses 
49 Ripple effects: How our water efforts bloom into biodiversity gains 

Both businesses and humanity depend on nature and the essential services it provides, such as clean air and 
water, healthy soils, flood prevention, nutrient cycling, pollination, and climate stability. But that’s not all— 
nature can also positively impact human health by reducing stress and improving wellbeing. Protecting and 
enhancing nature is also critical for supporting biodiverse ecosystems, for maintaining healthy communities, 
and for building resilience. 

Restoring habitat 
Cultivating nature on our campuses 

When people think of nature, they usually picture somewhere far away: forests, open spaces, a national 
park. But in many of the places we live and work, the closest thing to wilderness might be a strip of grass 
along a sidewalk. Nature and the built world often feel like two separate realms—and for decades, they’ve 
been treated that way. But what if they didn’t have to be? 

At Google, we’re trying to help change that—by rebuilding nature in the very places it’s been paved over: 
office campuses, sidewalks, former industrial land—places where rebuilding biodiversity can help people 
feel more connected, make cities more livable, and give ecosystems a real chance to thrive. The big idea: 
bring nature back to where people already are. 

Pollinator-friendly campuses 
Take our 1265 Borregas office in Sunnyvale, California. 
The building sits in the heart of Silicon Valley, 
surrounded by roads, businesses, and tech campuses. 

But around the building, we planted three acres of 
pollinator-friendly landscape—using native species 
like coast live oak, native milkweed, California 
sagebrush, and California wild rose. The result? It 
won’t just be prettier—it’ll be a better functioning A monarch butterfly rests on a stalk of lupine at a Google 
ecosystem. campus in California. (Photo credit: Rick Miskiv for Google) 

47 



St. John’’s Terminal has acres of native vegetation, redefining what “green space” means for commercial real estate in New York. 

In the San Francisco Bay Area, we’re rebuilding oak woodlands and willow groves damaged by decades 
of development. We’re reintroducing native plant species and creating the right conditions for wildlife to 
return—not just to pass through, but to stay. 

Building and monitoring thriving habitats 
As of the end of 2024, we created or restored approximately 74 acres of habitat and planted roughly 
5,200 native trees on Google’s campuses and the surrounding urban landscape, primarily in the San 
Francisco Bay Area. That includes new tree plantings, drought-tolerant native species, and pollinator gardens. 
It also includes lawn conversions—like turning grass into a monarch butterfly habitat in Mountain View. 

And as we go, we’re keeping track of what’s working—and where we can do more. At our Bay View campus 
in Mountain View in 2024, we documented more than 70 bird species that have returned to the restored 
habitats we’ve created to forage, roost, and raise their young. At our St. John’s Terminal building in New York 
City, working with NYC Bird Alliance, we’ve documented more than 60 bird species between fall 2023 and 
fall 2024—including 11 species that our expert partners say were never before documented on green roofs 
in the city, like Golden-crowned Kinglets and Yellow Warblers. 

Bringing nature closer to our 
employees and communities 
Bringing back biodiversity isn’t just about plants and 
animals—it’s about people too. We want nature to feel 
close, accessible, and part of daily life. That’s why we’ve 
created spaces where employees and the public can 
connect with wildlife, like “Egret Office Hours” hosted by 
the Santa Clara Valley Bird Alliance in the Shorebird Way 
rookery in Mountain View. 

In New York City, we partnered with the NYC Bird Alliance 
to host “Learning about Birds” events for Googlers at St. 
John’s Terminal, and we collaborated with NYC Parks Tree 
Time and the Arbor Day Foundation to plant native trees in 
two neighborhoods, Chelsea and Hudson Square, near our 
New York City campuses. The goal isn’t just entertainment The Shorebird Way rookery reflects a broader 

effort to design and build our offices with local 
or shade—it’s about reconnecting communities to local environments, ecology, and animal habitats in mind. 
ecosystems and making cities more resilient. 

48 



Ripple effects 
How our water efforts bloom into biodiversity gains 

We know the loss of nature isn’t limited to cities, which is why our restoration efforts extend far beyond our 
campuses. In fact, our water replenishment portfolio intentionally includes projects that have co-benefits 
for nature and biodiversity. 

• In California, we’ve partnered with the Bonneville Environmental Foundation and American Rivers to 
help project partners restore wetland meadows in Yosemite National Park that provide habitat for 
species like the northwestern pond turtle. These ecosystems don’t just support wildlife—they help 
regulate water, reduce fire risk, and make the landscape more climate resilient. 

• In Tennessee, we’re supporting the Cumberland River Compact’s efforts to reforest previously mined 
land—bringing back native species and building healthier local ecosystems. 

• In Arizona, we’re supporting the Cocopah Indian Tribe and National Audubon Society to restore 
habitat along the lower Colorado River floodplain. 

• In Israel, we’re supporting the restoration of former fish farms that are being converted back to 
wetland habitat, which will provide a stopover for migratory birds. 

The thread through all of it: bring nature back where it’s been pushed out. Make it count for biodiversity. 
Make it meaningful for people. And make it part of how we design and build—not just something we try to 
protect at the edges. 

It’s about rethinking how we live with nature in the present—and what we want our future to look like. 
Because in a world shaped by concrete, asphalt, and glass, choosing to build for biodiversity is one of the 
most hopeful decisions we can make. 

Oriental storks in a flooded rice paddy. 

49 



Consumer  
hardware devices 

Contents 
50 Recycled content: Giving materials in our devices a second life 
51 Packaging progress: How we solved the challenge of going plastic-free 
52 Building to last: Our approach to product longevity 
53 Partnering for impact: Collaborating on manufacturing, safer chemistry, and product shipping 

At Google, we’re building consumer devices with recycled materials, ditching plastic in our packaging, and 
working to make it easier for users to repair, reuse, and recycle our devices. The more circular we make our 
approach, the less we waste and the more value everyone can get from the materials we already have. 

Recycled content 
Giving materials in our devices a second life 

You might not notice it when you hold a Pixel or Nest product, but recycled materials can be found in many 
different components—from the rare-earth magnets to the aluminum enclosures and plastic parts, even the 
tin in the solder in our Pixel phones and smartwatches. Overall, at least 20% of all material Google used in 
our new products launched and manufactured in 2024 was recycled content. 72 We’ve incorporated recycled 
materials across our devices in a number of ways: 

• The magnets in Pixel Watch 3 and in the haptics engine of Pixel 9 and Pixel 9 Pro phone series are 
made with 100% recycled rare-earth elements. 73 

• Pixel Watch 3 and Pixel 9 and Pixel 9 Pro phones use 100% recycled tin in the solder of all rigid and 
flexible printed circuit boards, including the main logic board. 74 

• The aluminum enclosure of all Pixel phones since Pixel 6 through Pixel 9 series have been made  
with 100% recycled aluminum, reducing the carbon footprint of the aluminum portion of the 
enclosures by at least 35% compared to 100% primary aluminum. 75 

• We’re also using recycled or renewable material in plastic used across our consumer hardware product 
portfolio: 40% of the plastic Google used in products manufactured in 2024 was recycled content. 76 

Choosing recycled content helps reduce the environmental impact of extraction, supports more sustainable 
supply chains, and enables designing products differently from the start. This kind of design thinking helps 
reduce the impact of our consumer hardware—without compromising performance or quality. We’re also 
sharing what we’ve learned, for example in our Consumer Hardware Carbon Reduction Guide. 

50 



Packaging progress 
How we solved the challenge of going plastic-free 

Recycling is one side of the equation. Eliminating plastic in our packaging is the other. 

Product packaging traditionally relies heavily on mixed materials, particularly those incorporating plastic. 
This poses a challenge for recycling and creates a significant waste stream, especially if it isn’t accepted in 
recycling facilities. So packaging felt like the right place to focus. 

By 2020, we had already reached 94% plastic-free packaging. 77 But that last 6%? It hid in places like box 
liners, seals, and adhesives—and it wasn’t easy to swap out. 

So we got creative. We tested stretchier, stronger paper to replace wraps. We built a new molded fiber pulp 
made partly from recycled newspapers. Sometimes materials are recyclable but consumers don’t recognize 
them as such, so we redesigned packaging structures and ditched glossy coatings in favor of uncoated, 
speckled textures that looked—and felt—recyclable for consumers. 

The result: the packaging for new Google products launched and manufactured in 2024 was  
100% plastic free. 78 Packaging isn’t just what holds the product, it’s part of the product experience. And 
rethinking how it’s made can make sustainability feel more tangible from the start. Our Plastic-Free 
Packaging Design Guide shares design, engineering, and operational insights from our new packaging 
design and encourages other companies to share their innovations too. 

Google consumer hardware devices in their product packaging. 

51 



Building to last 
Our approach to product longevity 

One of the best ways to reduce e-waste and drive customer savings? Make devices that last. That’s why 
we’re putting more focus on software support, repairability, and second-life options like refurbishment. 

Pixel 8 and later phones get seven years of software support, including Android operating system upgrades 
and security updates. Google Nest devices receive automatic security updates for at least five years after 
launch. Chromebooks come with 10 years of automatic updates. 

We’re advocating for “Right to Repair” legislation while also empowering everyone with more repair options. 
For example, users can access the same parts and tools to fix Pixel phones themselves as are available at 
official repair centers. We’re pairing this with better documentation, how-to guides, and a self-repair hub for 
DIY users. Our goal is simple: make repair accessible, understandable, and worthwhile for consumers. 

We also launched a Certified Refurbished Pixel program in the United States in 2024—giving returned 
devices a second life and reducing waste along the way. 

We’ve extended the life of devices like the Pixel 8 through accessible repair. 

52 



Partnering for impact 
Collaborating on manufacturing, safer chemistry, and 
product shipping 

We’re also rethinking the upstream and downstream processes—working with suppliers and partners to 
make our manufacturing systems more circular from the inside out. 

In 2024, 82% of final assembly manufacturing sites for our consumer hardware products achieved  
UL 2799 validation for waste diversion 79—with 89% of those sites achieving Zero Waste to Landfill Gold or 
Platinum classification. 

Through our consumer hardware product Restricted Substances Specification and Manufacturer  Restricted  
Substances List, we restrict many hazardous substances and ensure our suppliers have processes in place 
to detect and prevent them from entering our products or the manufacturing process. 

We’re collaborating to improve materials too. In partnership with ChemFORWARD, we commissioned 
chemical hazard assessments for more than 190 individual chemicals from 2019 to 2024, to help inform the 
material choices we make for our consumer hardware products. To further accelerate safer chemistry 
across the industry, in 2024, we co-funded the Safer Chemistry Impact Fund—helping researchers and 
organizations find alternatives to hazardous substances. 

We’re also reducing the emissions tied to how our products move around the world. In 2024, we partnered with 
DHL to use sustainable aviation fuel (SAF) for shipping products across the Americas, Asia, and Europe. And 
we’re exploring ways to reduce emissions even further—from lighter packaging to smarter shipping routes. 

Assembly in progress in a warehouse. 

53 



New AI research 
solutions 



New AI research solutions 
Contents 

56 1 gigaton aspiration: Unlocking climate action at scale 
58 Fuel-efficient routing: Driving smarter while saving more 
59 Green Light: AI for more efficient city streets 
60 Solar API: How we’re democratizing solar power from rooftops to the grid 
62 Contrails: How AI can help mitigate the warming effects of aviation 

We believe technology—specifically AI—has the potential to accelerate the changes we need to protect 
people and the planet, and we’re focusing on some surprising areas where AI is already making a real 
difference today. 

Some of the most exciting innovations are happening in places you might never notice—in the clouds 
formed behind airplanes, the timing of a traffic light at a busy city intersection, the route of your local 
commute, and the untapped solar potential of your neighbor’s rooftop. 

The cutting-edge solutions we’re developing and deploying in these areas represent enormous 
opportunities. And they all share something important: they’re complex problems with numerous variables 
that—while challenging for a human to manage—are perfectly suited for AI to help solve. 

Contrails 

FireSat 

Wildfire boundary mapping Flood forecasting 

A visual showcase of various Google Research projects. 

55 



1 gigaton aspiration 
Unlocking climate action at scale 

You might wonder what optimized traffic lights, smart thermostats, tools for solar developers, and fuel-
efficient driving directions all have in common? Well, these are some of the ways we’re advancing our 
aspiration to help individuals, cities, and other partners collectively reduce 1 gigaton (GT) of their carbon 
equivalent emissions annually by 2030. To put the scale of this ambition into perspective, 1 GT of emissions 
reductions is comparable to the entire annual emissions of Japan. 80 

This aspiration is different from our operational 
ambitions. It’s a way for us to use our unique Figure 9. Emissions reductions enabled by 
technological capabilities and our global reach five Google products in 2024 
to inspire and enable others with information 
that can help mitigate climate change. This 30 

monumental opportunity—while inherently 
difficult and imprecise to measure—represents 
one of the most consequential environmental 
contributions we can make for the planet. 20 

While we still have a long way to go toward our  
1 GT aspiration, we’re motivated by our progress 
to date and the opportunity for real-world 10 

impact at scale: In 2024 alone, just five of our 
products—Nest thermostats, Google Earth 
Pro, Solar API, fuel-efficient routing in Google 
Maps, and Green Light (which represent only 

0 

a subset of our efforts)—enabled individuals, 2024 

cities, and other partners to collectively 
Year 

reduce an estimated 26 million metric tons of 
Legend 

GHG emissions 81 (Figure 9), roughly equivalent to 
the emissions from the annual energy use of over Green Light Nest thermostats 

3.5 million U.S. homes. 82 For context, Google’s 
Solar API Google Earth Pro 

total emissions in 2024 were 11.5 million tCO e. 83 
2 

Fuel-efficient routing 
Read more about the role each of these products 
played in 2024 below: 

• Fuel-efficient routing: In 2024, we
estimate that fuel-efficient routing enabled
more than 2.7 million metric tons of GHG
emissions reductions 84—equivalent to taking
approximately 630,000 gasoline-powered 
cars off the road for a year. 85 Want to dive
deeper into how this product feature is making
a tangible difference for drivers and the
planet? Explore the full story in Fuel-efficient 
routing: Driving smarter while saving more. Fuel-efficient routing 

56 

Million tCO2e 



• Green Light: In 2024, we estimate that Green Light
enabled over 3,000 metric tons of GHG emissions
reductions 86—and we expect even greater impact as
we continue to expand Green Light from 20 cities to
hundreds of cities over the next few years. Continue
reading for more details on this innovative traffic
management tool in Green Light: AI for more efficient 
city streets. Green Light 

• Solar API: In 2024, we estimate that around 6 million
metric tons of lifetime GHG emissions reductions
were enabled by solar panels installed by our partners
using the Solar API in the United States. 87 And using 
the annual accounting basis, we estimate that in 2024,
0.6 million metric tons of GHG emissions reductions
were enabled by solar panels installed by our partners
in the United States alone. 88  This partnership-driven 
approach not only enables emissions reductions, 
but it also helps companies scale their businesses
and create new jobs, and it directly contributes to a
cleaner energy future. Read Solar API: How we’re 
democratizing solar power from rooftops to the grid 
to learn more about exactly how we’re enabling more
people to harness the sun’s energy.

Solar API 
• Google Earth Pro: In 2024, we estimate that Google 

Earth Pro helped enable our partners to reduce 
more than an estimated 15 million metric tons of 
GHG emissions in the United States. 89 Solar and wind 
developers use Google Earth Pro for everything 
from evaluating potential sites to streamlining design 
and construction estimates. The platform’s ability 
to overlay critical datasets like flood plains, habitat 
information, and topography, combined with historical 
imagery, allows developers to identify potential 
constraints and optimize layouts. This precision  
helps them develop projects more efficiently and  
cost-effectively. Google Earth Pro 

• Nest thermostats: In 2024, we estimate that our  
Nest thermostats helped customers save more than 
25 billion kWh of energy, 90 enabling approximately  
8.4 million metric tons of GHG emissions reductions. 91  
For over a decade, our Nest Thermostats have
used machine learning to help people save energy 
and money at home by automatically adjusting 
temperatures based on habits and preferences. In 
fact, we estimate that our Nest thermostats helped
customers cumulatively save more than 162 billion 
kWh of energy from 2011 to 2024, 92 which is more  
than the total annual electricity consumption of

Nest thermostat 
Poland in 2023. 93 

57 



Fuel-efficient routing 
Driving smarter while saving more 

Looking for information about how to reduce your environmental footprint when in transit, from heading to 
work to picking up groceries? What if you learned that you could easily do just that—while also optimizing 
your fuel or energy use and saving money—every time you drive? Thanks to AI-powered fuel-efficient 
routing in Google Maps, you can. 

We’ve taken the guesswork out of how to drive more efficiently by suggesting the route that gets you to 
your destination in roughly the same time. Here’s how it works: our AI models analyze factors like your 
vehicle’s engine type, real-time traffic, and road conditions to pick the most fuel-efficient path. For example, 
a diesel vehicle’s efficiency is generally greatest in highway driving, while hybrid and electric vehicles tend 
to provide progressively greater efficiency in stop-and-go city driving and hilly driving where they benefit 
from regenerative braking. The result? A more fuel-efficient drive, regardless of your vehicle type, without 
sacrificing time or convenience. 

In 2024, we estimate that fuel-efficient routing enabled over 2.7 million metric tons of GHG 
emissions reductions 94—equivalent to taking approximately 630,000 gasoline-powered cars off the 
road for a year. 95 And it’s not just for cars. In places like Southeast Asia, where motorcycles and scooters 
rule the road, we’ve expanded the model to include two-wheelers as well. 

As of January 2025, fuel-efficient routing is available globally, helping people all over the world cut down 
on fuel or energy use, reduce their impact, and help their wallet. It’s a seemingly simple approach that 
underscores the power of technology to facilitate more sustainable choices in everyone’s daily lives. 

Fuel-efficient routing in Google Maps. 

58 



Green Light 
AI for more efficient city streets 

Anyone who’s spent time in a major city knows the feeling: long periods sitting in traffic, bumper to bumper, 
waiting for that light to turn green. But beyond the inconvenience, stop-and-go traffic has an environmental 
toll. Emissions from idling cars, constant acceleration, and braking contribute to air pollution and fuel 
waste—and city intersections are a hotspot for this problem. 

While some amount of stop-and-go traffic is unavoidable, part of it is preventable through the optimization 
of traffic light timing. To improve this timing, cities need to either install costly hardware or run manual 
vehicle counts. Both of these solutions are expensive, and neither provides all the necessary information. 

So what can cities do? The solution: Green Light, Google’s AI-powered traffic optimization tool. 

Green Light by Google 
Green Light uses AI and Google Maps driving trends to optimize traffic light timing, ensuring that cars 
spend less time idling and more time moving. It works by analyzing traffic flow at intersections, using data 
to recommend timing adjustments for red and green lights to reduce fuel-wasting stop-and-go traffic. The 
AI model looks at factors like traffic volume, vehicle speed, and intersection congestion to find the most 
efficient traffic light schedules. 

In cities where Green Light has been implemented, the results have been promising. Our analysis from 
intersections implementing Green Light recommendations indicates the potential to reduce stops at 
intersections by up to 30% and reduce emissions at intersections by an average of over 10%. 96 It’s like giving 
the city a smoother flow, without the need for costly infrastructure overhauls. 

Real-world results 
Recommendations from Green Light have been implemented across many intersections, helping to save 
fuel and lower emissions for more than 47 million car rides monthly. 97  In fact, in 2024, we estimate that 
Green Light enabled over 3,000 metric tons of GHG emissions reductions. 98 

These impressive results certainly warrant a green light for further expansion. So we brought the tool to 
several new U.S. cities in 2024—including Seattle and Boston—and to Santiago, Chile in early 2025. We’re 
now working to scale Green Light from 20 cities to hundreds of cities and tens of thousands of intersections 
over the next few years. 

The impact of Green Light goes beyond just reducing traffic jams or the frustration of waiting at a red light. 
This tool is a way to help make cities smarter, more efficient, and more sustainable. By optimizing traffic 
flow, we’re not only helping reduce emissions—we’re also easing congestion, reducing pollution, benefiting 
resident health and quality of life, and contributing to a more efficient urban environment. 

59 



Solar API 
How we’re democratizing solar power from rooftops to 
the grid 

The promise of clean, abundant energy from the sun is a compelling one. But despite its potential, many 
people still find solar adoption challenging. Between the up-front costs, understanding how much energy 
you could generate, and figuring out where to install panels, it can feel like a daunting challenge. 

We’ve focused on making solar more accessible by using technology to eliminate some of these barriers. 
Whether you’re a homeowner wanting to switch to residential solar, a solar installer looking for data, or a city 
planner aiming to expand solar infrastructure—Google’s tools are helping to make solar energy a reality for 
more people. 

Bringing solar to your roof with Project Sunroof 
We launched Project Sunroof in 2015 to help homeowners assess their solar potential. Using aerial imagery, 
the tool provides personalized solar savings estimates, showing how much sunlight your roof receives and 
how much you could save on energy bills by installing solar panels. With just your address, you can find 
out whether your home is a good candidate for solar, how much energy you could save, and how much it 
would cost. Project Sunroof also provides information about financial incentives—helping users understand 
available rebates and tax credits that can make solar adoption even more affordable. 

Making solar accessible for cities and developers 
At the core of this effort is our Solar API, which provides detailed, 
high-resolution solar potential data for buildings around the 
world. This tool can be used by solar installers, city planners, 
and energy companies to target rooftops with the highest 
potential. Using machine learning, high-resolution imagery, 
and advanced modeling, we’ve mapped the solar potential of 
nearly 540 million buildings across more than 40 countries. 99  

This dataset includes information vital for solar assessment: roof 
size and shape, orientation, shading from nearby objects, and 
estimated sunlight hours throughout the year. For solar installers 
and energy companies, having this information readily available 
can reduce the time and cost of initial assessments, allowing 
them to focus resources on installations. 

In 2024, we pushed this technology even further, using AI to 
estimate solar potential from satellite imagery for 125 million 
previously unmapped buildings across 23 countries, including 
many in the Global South—regions where detailed building 
information was previously unavailable. This expansion marks an 
important milestone in overcoming key barriers to solar adoption Project Sunroof interface showing solar 

capacity in downtown San Francisco, California. 
in emerging markets with limited infrastructure. 

60 



Enabling others to reduce emissions 
As the Solar API has continued to grow with new partners and in new regions, we’ve been developing an 
understanding of the impact it’s having on the world. We estimate that around 6 million metric tons of 
lifetime GHG emissions reductions were enabled by solar panels installed by our partners using the 
Solar API in 2024 in the United States. 100 Using an annual accounting basis, we estimate that in 2024, 0.6 
million metric tons of GHG emissions reductions were enabled by solar panels installed by our partners in 
the United States alone. 101 

In the future, we envision a world where every building with solar potential—whether in an urban center or 
a rural town, in the Global North or the Global South—has access to clean, affordable solar energy. We’re 
working to democratize solar energy, making it accessible to everyone, regardless of where they live, and 
empowering people with the information they need, when they need it, to harness the power of the sun. 

The Solar API offers coverage (illustrated in yellow) for nearly 540 million buildings across more than 40 countries. 

61 



Contrails 
How AI can help mitigate the warming effects of aviation 

What exactly are contrails? 
Contrails, short for condensation trails, are the line-shaped clouds that you sometimes notice behind 
airplanes. They form when water vapor in the air condenses around tiny particles of soot and other 
pollutants emitted by airplane engines (Figure 10). 

While they might seem temporary, contrails can persist for hours and spread into cirrus-like clouds that 
trap heat in Earth’s atmosphere. This heat-trapping effect is particularly potent because it happens high in 
the atmosphere where temperatures are already low. Scientists have determined that contrails account for 
approximately 35% of aviation’s global warming impact 102—a surprisingly large percentage that receives 
relatively little attention in climate discussions. 

Planes don’t always make contrails. Contrails only occur when planes fly through humid regions. If planes 
intentionally avoid flying through these regions, then they can avoid creating warming contrails, often with 
minimal impact on fuel usage. The challenge is knowing where these regions will occur. 

Figure 10. What are contrails? 

62 



A cost-effective and scalable solution without the wait 
Unlike many solutions that require completely rebuilding infrastructure or waiting for new technologies 
to develop, contrail reduction is something that could be implemented almost immediately with existing 
aircrafts. Airlines and their pilots just need to know exactly where and when contrails will form to avoid those 
specific atmospheric conditions. 

That’s why we partnered with Breakthrough Energy and American Airlines to develop AI models that analyze 
atmospheric data to predict contrail formation with remarkable accuracy. The system processes massive 
quantities of weather, satellite, and flight data to identify when and where contrails are likely to form. 

With these predictions, airlines can make slight adjustments to flight paths—sometimes changing altitude by 
just a few thousand feet—to avoid these contrail-forming zones while maintaining safety and with minimal 
additional fuel consumption. 

From testing to takeoff 
Our testing has shown extraordinary promise. In one trial consisting of 70 test flights, flights that 
adjusted their routes using our AI-based contrail predictions showed a 54% reduction in contrail 
kilometers, when compared to control flights that didn’t have access to the AI predictions. 103 In this trial, 
we also found that the flights that were rerouted to avoid creating contrails only used an average of 2% 
additional fuel, compared to control flights. 

What makes this approach particularly attractive is its efficiency. A study found that only a small percentage 
of flights would need adjustments to avoid the majority of potential contrail formation. 104 

Our analysis suggests that the cost of reducing contrails through navigational avoidance could be in 
the range of $5–$25 per tCO2e—making it a cost-effective climate solution that’s available today. 105 For 
comparison, many carbon removal technologies cost hundreds of dollars per ton 106 while sustainable 
aviation fuel costs thousands of dollars per ton. 107 

In 2024, we expanded this work by beginning a collaboration with EUROCONTROL to apply our contrail 
prediction technology in Europe’s airspace—a busy and complex air-traffic environment. This partnership 
represents a key step toward mainstreaming contrail avoidance as a standard practice in aviation. 

The flight path toward clearer skies 
The contrail reduction opportunity points to a broader theme in climate innovation: some of the most 
impactful solutions don’t require waiting for breakthrough technologies or completely rebuilding 
infrastructure. Sometimes they simply require using existing information in new ways. 

As we continue this work, we’re seeing growing interest from airlines and air navigation service providers. 
The aviation industry, which has struggled to find immediate pathways to significant emissions reductions, 
has a near-term opportunity in contrail avoidance that can be implemented while longer-term technologies 
like sustainable aviation fuels and electric aircraft continue to develop. 

For passengers, the changes are virtually invisible—an occasional slight change in altitude that most won’t even 
notice. But these small adjustments could collectively be substantial, reducing aviation’s overall climate impact. 

63 



AI for extreme events 
and disaster response 



AI for extreme events 
and disaster response

Contents
66 Battling the blaze: How AI, satellites, and maps are helping us fight fire faster
68 Future of forecasts: A new AI revolution is reshaping how we predict weather
69 Seven-day lead time: How AI is giving flood-prone communities time to act

As extreme weather events intensify—like we saw in 2024 with devastating floods in Spain and other parts 
of Europe and heatwaves that brought record-breaking temperatures across Asia, with India recording 
its hottest day in May 2024 108—it’s clear that the need for novel research and engineering innovations to 
enhance resilience is only growing.

Building resilience is about the ability of communities, ecosystems, and economies to cope, adapt, and 
thrive despite the challenges posed by a changing planet. This means proactive preparation for future 
impacts, coupled with effective management of current ones. We’re helping the world adapt and transform, 
emerging stronger and better equipped to face what’s ahead.

At Google, we’re using our technological capabilities to tackle this head on. We’re focused on developing 
advanced forecasting and early warning systems that give communities the critical tools they need to 
predict, prepare for, and respond to these growing threats. By combining AI, data, and machine learning, 
we’re working to ensure that when disaster strikes, people have the information they need to act fast.

But disaster response doesn’t start when the storm hits—and it doesn’t end when the skies clear. That’s why 
we’re focused on the full timeline of support: before an event occurs, during the disaster, in the immediate 
aftermath, and in the long-term work of understanding risk and preparing for what’s next. We’re also 
working closely with state and local governments, as well as organizations like the World Meteorological 
Organization, under the banner of the UN’s Early Warnings For All initiative, so that we can ensure the 
information we provide is accurate, timely, and accessible.

We’ve seen firsthand how our platforms—like Search and Maps—become vital resources during disasters, 
so we’re looking for ways to better serve our users during extreme weather events. In the United States, 
for example, we know that users turned to Google Search as a key resource during major disasters like 
hurricanes Helene and Milton in the fall of 2024 and the Los Angeles wildfires in January 2025. 109 We’ve 
also seen that extreme events can act as a stimulus—including for those not directly affected by the event 
itself—to investigate how climate change can affect the frequency and intensity of extreme events.

We’ll continue to research and develop new ways to support users and scale these tools globally—especially 
for the most vulnerable communities, so they can protect what matters most.

65



Battling the blaze 
How AI, satellites, and maps are helping us fight fire faster 

In January 2025, wildfires swept across the hills outside Los Angeles. Working in tandem with satellite data 
and mapping technology, Google Search and Maps provided information to help manage the wildfire, 
such as road closures and nearby hotels that were offering free or discounted accommodations to anyone 
displaced by the wildfires. It was a clear example of how technology is transforming disaster response—and 
building resilience to such events—thanks to AI, satellites, and a whole lot of data. 

FireSat, a system to identify wildfires earlier 
Imagine being able to detect a wildfire as small as the size of a garage anywhere on Earth (Figure 11). 
That’s the promise behind FireSat. Born from an idea at Google Research, the FireSat initiative officially 
launched its first wildfire-detecting satellite in March 2025. This pioneering effort leverages technology to 
gather high-resolution and frequent data, and employs AI to analyze it—providing critical, rapid insights to 
firefighters. The idea became a reality through key partnerships across philanthropy, scientists, industries, 
and the establishment of the Earth Fire Alliance in 2024. 

FireSat satellites were developed by Muon Space in collaboration with Earth Fire Alliance, with leadership 
and support from Google, the Gordon and Betty Moore Foundation, Environmental Defense Fund, and 
others. Funding for the first satellite in the FireSat constellation came in part from Google.org (Google’s 
philanthropic arm), which provided $13 million as part of the AI Collaborative: Wildfires, an initiative 
to harness AI’s potential in reducing the economic, humanitarian, and environmental damages from 
catastrophic wildfires and building long-term resilience to such disasters. 

Figure 11. FireSat is the first satellite constellation to focus on early detection in high resolution 
imagery 

66 



The first satellite launched in early 2025, with plans for more than 50 to follow in the years to come, 
led by the Earth Fire Alliance coalition. Once fully operational, the FireSat program will provide near real-
time data on the location, size, and intensity of all wildfires on Earth every 20 minutes or less. This means 
emergency crews will be able to act quickly—often before a small fire has the chance to escalate. The ability 
to detect fires early in their life cycle could significantly reduce the damage they cause, making firefighting 
efforts more effective and ultimately saving more lives, homes, and communities. 

Wildfire mapping 
Wildfires spread rapidly, change direction unpredictably, and often begin in remote areas where early 
signs could go unnoticed. Once a fire ignites, it can engulf large areas in a matter of hours, devastating 
communities and ecosystems, so the window of time between detection and response is narrow. 

One of our most visible tools is AI-powered wildfire boundary tracking, which uses satellite data to refresh 
fire maps every 15 to 20 minutes, offering a near real-time picture of the fire’s spread. These updates appear 
in Google Search, Google Maps, and even in location-based push notifications. In 2024, our crisis alerts 
provided timely wildfire information to over 26 million users across more than 480 wildfire events 
around the world—including the devastating fires in the Attica region of Greece in August 2024. 

This work not only helps emergency responders assess where the fire is currently, but also assists in 
creating evacuation routes and alerting nearby residents to evacuate or take protective measures. By 
providing timely and accurate information, this technology aids community resilience in the face of these 
challenging events. The updates provided by this technology can be the difference between safety and 
catastrophe, offering essential information to people when they need it most. 

Bridging the gap from detection to prediction 
The best way to address wildfire risk is before a fire even starts. To help, Bellwether—a prediction engine for 
the Earth and everything on it, and a part of X, Alphabet’s moonshot factory—has built an AI-first wildfire risk 
forecasting system to understand the future probability of wildfire in the United States, Canada, and Australia. 

Named one of TIME’s “Best Inventions of 2024,” Bellwether will offer insights that can help governments and 
communities plan ahead based on the probability of wildfires before they happen. Instead of reacting after 
the fire starts, the system will give communities and emergency responders the foresight to take action 
before a disaster strikes. 

Through partnerships with agencies like the U.S. Forest Service, we’re also improving fire-spread prediction 
models. These models use machine learning to simulate how fires might move across landscapes, based on 
a range of factors such as weather, terrain, and past fire data. This means firefighters can arrive at strategic 
locations and begin mitigating damage before the fire becomes too large to contain, potentially saving 
lives and reducing destruction. The ability to predict fire behavior gives communities the chance to protect 
themselves and minimize losses. 

Taken together, these efforts represent a shift from reacting to wildfires to getting ahead of them. The 
future of fire response is faster, smarter, and increasingly powered by AI. 

67 



Future of forecasts 
A new AI revolution is reshaping how we predict weather 

If you checked the weather this morning, there’s a strong chance it was powered in part by AI. And not 
just any AI—but a growing suite of deep-learning models that are pushing the boundaries of what weather 
prediction can do. 

The latest breakthrough? WeatherNext, a family of AI models from Google DeepMind and Google Research 
that produces state-of-the-art weather forecasts. These aren’t just upgrades to your standard forecast— 
they represent a whole new approach. 

How it’s different 
Traditional forecasts rely on physics-based models—essentially solving equations about how air moves 
through the atmosphere. They’re powerful, but slow. Weather systems are also chaotic, involving massive 
amounts of data, and we can’t account for—or measure—every variable. Even small inaccuracies in 
measurement are quickly magnified. 

In contrast, AI models like WeatherNext learn directly from vast amounts of historical weather data, 
generating predictions much faster. 

WeatherNext includes two primary models. 

• WeatherNext Graph provides single, precise predictions up to 10 days in advance.

• WeatherNext Gen generates ensemble forecasts—a range of possible scenarios—up to 15 days
ahead, helping decision-makers plan for uncertainty.

These models aren’t just concepts—they’re already transforming how we forecast the weather, helping us 
make better decisions and improving disaster response, grid reliability, and global food security. We’re also 
sharing our models with scientists and forecasters, to accelerate their work and ultimately benefit billions of 
people around the world. 

More models, more possibilities 
Other innovations are joining the forecast revolution. NeuralGCM, developed in collaboration with the 
European Centre for Medium-Range Weather Forecasts, uses neural networks to simulate the Earth’s 
atmosphere faster than traditional climate models. 110  SEEDS, a generative AI model, can create massive 
collections of weather forecasts at a fraction of the cost compared to the operational U.S. forecast system. 111 

Some of these models—including MetNet-3 and WeatherNext Graph—are starting to power user 
experiences on Google Search and Maps improving forecasting of precipitation, cyclones, flooding, and 
extreme heat. 

This work is more than a technology showcase—it’s building a foundation for more accurate, accessible 
weather information everywhere. And as climate change brings more extreme weather, that foundation for 
resilience will matter more than ever. 

68 



Seven-day lead time 
How AI is giving flood-prone communities time to act 

Floods are one of the most common types of natural disaster, and roughly 19% of the global population 
is directly exposed to substantial risks from severe flood events worldwide. 112 When a flood approaches, 
the difference between chaos and preparedness often comes down to timing: a few extra days can mean 
sandbags in place, supplies distributed, and people evacuated. That’s why Google’s fl ood forecasting 
initiative, launched in 2018, has focused on giving people more time. 

The real-time operational system—visualized on Google Flood Hub—provides alerts via Google Search, 
Google Maps, and Android notifications and also displays flood forecasts to help governments, aid 
organizations, and at-risk communities take timely action. As of the end of 2024, Flood Hub’s  
AI-powered riverine flood forecasting system covered over 100 countries and over 700 million 
people globally 113 (Figure 12). 

In 2024, we improved our flood forecasting system to offer warnings up to seven days in advance with the 
same accuracy as the previous model had at five days. That extra window is possible thanks to a new AI 
model and is crucial for anticipatory action. 

Figure 12. Flood Hub view showing extended coverage 

69 



Flood forecasting 

A visual showcase of Google Flood Hub. 

Making an impact on the ground 
In 2024, we generated more than 1,100 crisis alerts that shared critical flood information, including 
mappings of estimated flooded areas, which were viewed by more than 33 million users. These alerts 
give people the vital information they need to act before a crisis hits. 

Take Brazil, for instance. Aid organizations including World Vision Brazil and its local partners used our 
flood forecasts to predict the regions that would be affected by floods and quickly deliver child protection 
services, distribute direct assistance, and provide essentials—such as drinking water, food baskets, and 
bedding kits—in less than two days. 

And in countries like Nigeria and Bangladesh, Google.org supported nonprofits like GiveDirectly and the 
International Rescue Committee to distribute pre-emptive cash assistance, helping families prepare, 
boosting their resilience, and shortening recovery time. 

New tools for a global problem 
For most of history, accurate flood forecasting at scale wasn’t possible due to the complexity of the 
problem and lack of resources and data. Given that only a small percentage of the world’s rivers are 
equipped with streamflow gauges, this provided an extra barrier to safety for people in developing 
countries as well as in underserved and vulnerable communities. 

To fill the gaps in data, we’ve introduced “virtual gauges”—AI-driven estimates of water levels in regions 
without physical flood sensors. This means we’re able to use AI-based forecasting to improve forecasts in 
regions in Africa and Asia to a similar quality as those currently available in Europe. 

As the effects of climate change become more severe, floods could strike in increasingly unexpected 
places. So we’ll continue using our research capabilities and technology to further increase our coverage as 
well as forecast other types of flood-related events and disasters, including flash floods and urban floods. 

The goal is simple: give people all over the world the information they need—early enough to make it count— 
and build resilience against increasing flood risks. Because when water rises, seven days can mean the 
difference between devastation and the critical chance to save lives. 

70 



Protecting the planet 
with our AI products 



Protecting the planet  
with our AI products 

Contents 
73 Forests in focus: Empowering the fight against deforestation 
74 Surfacing solutions: Safeguarding the world’s vital freshwater and ocean 

resources 

The world’s ecosystems are undergoing significant transformation. We’re observing changes in forest 
coverage, shifts in freshwater systems, and impacts on marine environments—trends that highlight the 
growing pressures on natural resources. While these changes are unfolding at a rapid pace, our ability to 
track and respond to them effectively has often lagged. We’re working to bridge this gap, using cutting-
edge technology to make the invisible visible and empower action at unprecedented scales. 

We’re developing powerful tools that allow us to monitor environmental changes from the vast stretches of 
the Amazon to the remote waters of the Pacific in real time. But our efforts go beyond tracking ecosystem 
data—we’re working to drive real solutions. With AI-powered tools that protect forests and acoustics that 
monitor ocean life, we’re providing the actionable information and insights that governments, organizations, 
and communities need to act swiftly and decisively. Through innovation and collaboration, we’re working to 
protect the planet through our products at scale. 

Google’s AI models identify animal species by analyzing photos from camera traps. 

72 



Forests in focus 
Empowering the fight against deforestation 

We’re building tools and working with partners to make spotting signs of deforestation easier and faster to 
act on—while there’s still time to respond. 

From satellite images to on-the-ground action 
One of the most powerful tools we’ve built is Google Earth Engine. It’s a planetary-scale platform that helps 
people map, analyze, and monitor changes in land use—from tree cover to water to urban growth. In forest 
protection, that means being able to see not just where trees are, but where they’re being lost—and why. 

In partnership with the World Resources Institute (WRI), we’ve mapped deforestation drivers like agriculture, 
fire, and logging down to a one-kilometer scale. That kind of detail can help land managers, companies, 
and governments respond with precision—not just with policies, but with boots-on-the-ground protection 
where it’s needed most. 

We’re a founding partner of the Forest Data Partnership, which aims to stop deforestation caused by 
commodity production. To support this partnership, in 2024 we released new global datasets—like maps of 
rubber-, palm-, and cocoa-growing regions. Now people can see where these deforestation-linked crops 
are expanding and assess the risk to nearby forests. It’s a foundational step for companies trying to develop 
more resilient supply chains and for regions working to shift toward sustainable production. 

Tools that scale around the world 
Earth Engine, with its built-in AI capabilities, powers land-use monitoring from Brazil to Indonesia, from 
the Congo Basin to the American West. It’s how the United Nations Environment Programme–World 
Conservation Monitoring Centre monitors progress toward global biodiversity goals. It’s how MapBiomas 
tracks land change in Brazil. It’s even how countries get paid for protecting forests through the REDD+ 
(Reducing Emissions from Deforestation and Forest Degradation) program. These maps aren’t just pixels— 
they’re data that drives decisions, whether that’s enforcing protections, documenting illegal clearing, or 
planning forest restoration. 

We’re also supporting organizations using AI to track illegal logging from the ground up. With funding from 
Google.org and in-kind contributions from Google employees, The Nature Conservancy in Brazil developed 
the Forest Fingerprints (Digitais da Floresta) project—an initiative that uses AI and biochemical analysis to 
identify and trace the origin of timber extracted from the Amazon. The project aims to reinforce the fight 
against environmental crimes related to the illegal timber trade. The idea is to bring more transparency— 
and more accountability—to forest products, starting in the Amazon. 

Making deforestation harder to hide—and easier to stop 
None of these tools fix deforestation on their own. But they can help put the right information in the right 
hands at the right time. When businesses can trace their supply chains, they can clean them up. And when 
policymakers can monitor real-time forest loss, they can act before it becomes irreversible. Forests don’t 
fall all at once, and the right tools can help stop a chain reaction before it begins. 

73 



Surfacing solutions 
Safeguarding the world’s vital freshwater and  
ocean resources 

The story doesn’t end with forests. The intricate networks of rivers, lakes, wetlands, and oceans are the 
planet’s circulatory system, and they too are under immense strain. Pollution, overuse, and the impacts of a 
changing planet are taking a toll. 

Through partnerships with scientists, governments, and NGOs, we’re building tools that help protect these 
essential systems. Whether it’s monitoring reservoirs in near real time or tracking illegal fishing halfway 
across the globe, we’re working to bring critical insights to light, so action can follow. 

Mapping the world’s freshwater 
Freshwater ecosystems support millions of species and billions of people. But many of them are poorly 
monitored, especially in regions where data is scarce or outdated. 

Given this reality, we teamed up with the United Nations Environment Programme and DHI to build the 
Freshwater Ecosystems Explorer—a free platform that brings together satellite data, AI, and hydrological 
models. The easy-to-use geospatial platform helps policymakers and scientists see how freshwater systems 
are changing across countries, river basins, and watersheds. The Freshwater Ecosystems Explorer helps 
track water levels in reservoirs and spot changes in wetlands—offering a clearer picture of how these 
systems are shifting over time. 

We’ve also supported other tools aimed at making 
water data more actionable: 

• LeadOut Map, a tool launched by 
BlueConduit in 2024, uses AI to help cities 
locate lead pipes for removal in the  
United States. 

• Global Wetland Watch is mapping global 
wetlands with satellite imagery and AI. 

• Global Water Watch offers near-real-time 
updates on reservoir levels. 

And with $2.5 million in funding from Google.org, 
we’re supporting new AI-powered platforms to 
improve water reuse in drought-prone regions like 
Mexico and the Middle East. Because clean water 
isn’t just about what you save—it’s also about what 

The Global Water Watch tool. 
you can safely use again. 

74 



Global Fishing Watch releases AI--powered datasets that map global ocean infrastructure and vessels by type. 

Watching and listening to the ocean 
The ocean’s challenges are as deep and vast as its waters, from overfishing and illegal fleets to warming sea 
surface temperatures. That’s why we co-founded Global Fishing Watch with SkyTruth and Oceana in 2015. 
The open-source platform uses satellite data and AI to publicly map more than one million ocean-going 
vessels and fixed infrastructure in near real time—helping governments spot anomalies and take action. 

In 2024, the platform expanded to include data on marine infrastructure, GHG emissions, and 
biodiversity pressures. Governments are now using the tool to plan marine protection areas, guide 
offshore wind development, and monitor activity from marine vessels. 

But not all data shows up on a map. Some signals are easier to hear than see—which is why we’re also 
working with scientists to monitor ocean life using underwater acoustics. 

AI-powered acoustic tools are analyzing whale calls to track migration. In the Philippines and Indonesia, 
we’re listening to coral reefs to assess their health. These projects offer new windows into fragile 
ecosystems that are otherwise hard to study. And when paired with imagery, they become powerful 
conservation tools. 

The challenges facing freshwater and oceans are real, but they’re no longer out of sight. Satellite images, 
sound data, and AI are helping turn murky signals into clear, actionable tools—and helping communities 
protect the planet. 

75 



Appendix 



Appendix 
Contents 

77 About Google 
77 About this report 
78 Ambitions 
78 Climate moonshots 

86 Water and waste 

89 Governance and risk management 
90 Stakeholder engagement and partnership 
98 Environmental data 

115 Certifications and recognitions 
116 Endnotes 

About Google 
As our founders explained in their first letter to shareholders, Google’s goal is to “develop services that significantly improve the lives of as many people  
as possible.” 

We believe in the potential of technology to have a positive impact on the world. That unconventional spirit has been a driving force throughout our history, 
inspiring us to tackle big problems and invest in moonshots, such as our long-term opportunities in AI. We continue this work under the leadership of 
Alphabet and Google CEO Sundar Pichai. 

Alphabet is a collection of businesses—the largest of which is Google. Google comprises two segments: Google Services and Google Cloud, and all 
non-Google businesses are referred to collectively as Other Bets. Supporting these businesses, we have centralized certain AI-related research and 
development. Google Services’ core products and platforms include ads, Android, Chrome, devices, Gmail, Google Drive, Google Maps, Google Photos, 
Google Play, Search, and YouTube. Our devices include Fitbit, Google Nest, and Google Pixel devices. Our Google Cloud products include Google Cloud 
Platform and Google Workspace. 

Our headquarters are located in Mountain View, California. We own and lease office facilities and data centers around the world, primarily in Asia, Europe, 
and North America. In 2024, Google had offices and data centers on six continents, in over 200 cities, across nearly 60 countries. To learn more, refer to our 
data center locations and our office locations. 

About this report 
Google’s 2025 Environmental Report highlights how our technologies—including cutting-edge AI and emerging research—are driving progress for both 
people and the planet. Throughout this report, we use the term “sustainability” to refer to environmental sustainability. This report features data from our 
2024 fiscal year (January 1 to December 31, 2024), and mentions some notable achievements from 2025 to date. 

Additional resources 
• Explore our 2025 Environmental Report
• Sustainability.google
• Sustainability reports
• Sustainability blog 
• About Google 
• Google’s commitments 
• Alphabet additional information: Environmental 
• Alphabet SASB and TCFD Index 

77 



Ambitions 
Google builds technology for everyone—working to solve complex challenges, advance the field of AI, and help as many people as possible. We approach 
sustainability the same way we approach our business—by seeking to unlock bold and responsible innovations that create benefits for people everywhere. 

To guide our efforts, we set “moonshots”—environmental ambitions that may seem impossible at the time we set them. Progress is often 
non-linear and may take longer than expected, but continuing to pursue these moonshots can lead to significant, systemic change that might 
not otherwise be achieved. They help us prioritize our efforts, direct our investments to the highest-impact outcomes, and catalyze deep innovation 
across the company. Environmental ambitions are particularly unique because they can't be achieved by us in isolation. Instead, they demand broader 
ecosystem-level change, which requires close collaboration with partners and other stakeholders to reach these crucial outcomes for the planet. 

Climate moonshots 
We’re at the halfway point of the decade, and we’ve made meaningful progress. In 2024, we reduced our data center energy emissions by 12% due 
to new clean energy we brought online—successfully decoupling our operational energy growth from its associated carbon emissions. We achieved 
at least 80% carbon-free energy on an hourly basis across nine out of 20 grid regions with Google-owned and -operated data centers. We’ve 
signed the world’s first corporate agreements to purchase advanced geothermal and advanced nuclear energy from small modular reactors (SMRs), used 
AI to accelerate grid interconnections, created new rate structures for large energy users to buy reliable power, shifted some compute tasks to reduce 
stress on the local power grid, and more. 

And while we remain committed to our climate moonshots, it’s become clear that achieving them is now more complex and challenging across every 
level—from local to global. Several external factors, largely outside our direct control, are converging to create significant uncertainty: 

1. Scalable carbon-free energy technology: A key challenge is the slower-than-needed deployment of carbon-free energy technologies at 
scale, and getting there by 2030 will be very difficult. While we continue to invest in promising technologies like advanced geothermal and 
SMRs, their widespread adoption hasn’t yet been achieved because they’re early-stage, relatively costly, and poorly incentivized by current 
regulatory structures. 

2. AI energy demand: The rapid evolution of AI is fundamentally reshaping our business and the technology industry as a whole. This may drive 
non-linear growth in energy demand, which makes our future energy needs and emissions trajectories more difficult to predict. 

3. Policy uncertainty: Shifts in climate- and energy-related policies and regulations introduce significant uncertainty. This policy instability 
poses new challenges to our planning and progress as it’s anticipated to impact clean energy supply and development timing. 

4. Resource-challenged markets, including Asia Pacific: Some regions are still early in their decarbonization journeys and have electricity 
grids that are undersupplied with carbon-free energy. For example, many countries in Asia Pacific face unique challenges when it comes 
to adding new carbon-free energy—including land constraints, low availability of commercially scalable wind and solar resources, and high 
construction costs. 

These external factors could affect the cost, feasibility, and timeline of our progress—and navigating them requires flexibility. To maintain momentum 
toward our climate moonshots, we’ll continue to evaluate a broad range of solutions, balancing cost, quality, and the speed of emissions reductions. 

Over the last several years, we’ve also learned many valuable lessons. We’re entering the second half of the decade with a stronger understanding of what’s 
required to make progress, what’s achievable in different regions, and how best to maximize the impact of our efforts and investments. Looking ahead, 
we’re charting pathways that are highly ambitious in their approach—taking into account the lessons we’ve learned, the specific needs and challenges of 
each region where we operate, and the opportunities we see to drive systemic change. 

78 



Carbon-free energy moonshot 
We aim to run on 24/7 carbon-free energy on every grid where we operate by 2030. 

In 2024, we achieved approximately 66% global average carbon-free energy across our data centers and offices. 114 

One of the most important impacts of our 24/7 carbon-free energy efforts isn’t on our own electricity-related emissions, but on the broader power 
grids in which we operate. Modeling by leading research organizations shows that 24/7 carbon-free energy procurement drives greater impact on grid 
decarbonization than alternative procurement approaches, with comparative benefits achieved starting at roughly 80% hourly matching. 115 Therefore, 
we view exceeding 80% as a significant achievement in driving system-level decarbonization, and we’re proud to have already achieved at least 80% 
CFE across nine out of 20 grid regions with Google-owned and -operated data centers (refer to the Environmental metrics data tables for details). 
What’s most important is forward progress. 

And while we’re making meaningful strides toward this moonshot, progress is uneven across regions. As the table below illustrates, North America, 
Europe, and Latin America are showing improvements, but the Asia-Pacific region largely remains undersupplied with carbon-free energy. 

Year-on-year progress 

Regional average Google CFE across Google data center grid regions Unit 2022 2023 2024 

North America % 69 68 70 

United States % 69 68 70 

Canada & Mexico 116 % 96 96 88 

Europe, Middle East, & Africa % 76 83 83 

Europe % 76 84 84 

Middle East & Africa % 3 4 5 

Latin America % 90 91 92 

Asia Pacific % 11 12 12 

Global CFE across Google data centers % 64 64 66 

Trend Graph 
For our global average across our data centers and offices, we increased 
our Google CFE percentage from 64% in 2022 and 2023 to 66% in 2024 117— 30 

despite significant growth in electricity demand over this period (which was 
driven, in part, by AI). This was a result of increases in Contracted CFE and 
overall increases in global Grid CFE, specifically in North America where our 
energy consumption is highest. 

20 
Overall, we increased our Google CFE in over half of our grid regions that 66% CFE 
contain Google-owned and -operated data centers, and achieved at least 
80% CFE in nine out of 20 of these grid regions in 2024. 64% CFE 

64% CFE 
Details 10 

We set this ambition in 2020. The load-weighted average of carbon-free 
energy percentages across Google’s global portfolio of data centers and 
offices is referred to as “Google CFE.” This metric is inclusive of third-party 
data centers, and it represents the clean energy purchased to meet our 0 

electricity needs at every hour of every day, and within every grid where we 2022 2023 2024 
operate. For more details, refer to 24/7 Carbon-Free Energy: Methodologies Year 
and Metrics. Legend 

Total electricity consumption across our data centers and offices 

Global average CFE percentage 

79 

Terawatt-hours 



Carbon reduction moonshot 
We aim to reduce absolute, combined scope 1, 2 (market-based), and 3 emissions by 50% from a 2019 base 
year by 2030. 

Ambition-based carbon footprint 
In February 2025, the SBTi (Science Based Targets initiative) validated Alphabet’s near-term science-based emissions reduction ambition based on our 
data, company structure, and activities at that time, ensuring our ambition meets the most rigorous standards for emissions reductions and contributes to 
limiting climate change. 118 

In 2025, we adjusted the boundary for our carbon reduction and net-zero ambitions to exclude certain scope 3 emissions activities that are peripheral to 
our core operations or where our ability to influence emissions reductions is limited (Figure 13). Accordingly, we use the term “ambition-based” to describe 
the subset of emissions from our total carbon footprint that are within the boundaries we’ve set for our climate ambitions. The boundary of our ambition-
based emissions, and how we measure and report progress, doesn’t affect the completeness of our total emissions inventory, which is presented in our 
Environmental metrics data table. 

In 2024, our total ambition-based emissions were approximately 11.5 million tCO2e, which represent our scope 1, scope 2 (market-based), and 
scope 3 (ambition-based) emissions. 

Figure 13. Our 2024 ambition-based carbon footprint 

Scope 1: Legend 
73.1K tCO2e 

Scope 2 Scope  tCO2e % 
(market-based): 
3.1M tCO Scope 1 

2e 73,100 1% 

Scope 2 (market-based) 3,059,100 26% 

Scope 3 (Category 1: Purchased goods and services) 739,000* 7% 

Scope 3 (Category 2: Capital goods) and 
5,561,000* 48% 

(Category 11: Use of sold products) 

Total 
Scope 3 (Category 3: Fuel- and energy-related activities) 

ambition-based 714,000 6% 

emissions: Scope 3 (Category 4: Upstream transportation 
11.5M tCO2e 853,000 7% 

and distribution) 

Scope 3 (Category 5: Waste generated in operations) 12,000 0.1% 

Scope 3 (Category 6: Business travel) 399,000 4% 

Scope 3 (Category 7: Employee commuting) 137,000 1% 

Total ambition-based emissions 11,547,200 100%

Scope 3 * These totals reflect our ambition-based boundary and therefore exclude certain scope 3 emissions activities. 

(ambition-based): These exclusions collectively account for 25% of our 2019 scope 3 footprint, well within SBTi’s guidelines to 
exclude no more than 33% of base year scope 3 emissions. 

8.4M tCO2e 

Scope 1 
The primary sources of our scope 1 emissions are natural gas use for building heating, refrigerant leakage, fuel use from backup generators, and 
transportation from company vehicles. In 2024, our scope 1 emissions were approximately 73,100 tCO2e, representing less than 1% of our total 2024 
ambition-based carbon footprint. 

Compared to 2023, we reduced our scope 1 emissions by 8%, primarily due to building efficiencies and warmer weather conditions that resulted in 
decreases in natural gas, changes to generator utilization that resulted in decreases in diesel and other fuel usage, and improvements to refrigerant data 
quality. Our scope 1 emissions reduction efforts to date have focused on electrification, refrigerant mitigation, and renewable fuel use. 

Scope 2 
The primary source of our scope 2 emissions is purchased electricity for our data centers and offices. In 2024, our scope 2 (market-based) emissions were 
approximately 3.1 million tCO2e, representing 26% of our total 2024 ambition-based carbon footprint. 

Compared to 2023, we reduced our scope 2 (market-based) emissions by 11%, primarily due to clean energy procurement. For scope 2 emissions 
accounting, clean energy purchases must be matched following GHG Protocol regional market boundaries. In 2024, we were successful in sourcing more 
clean energy from within the same regions as our data centers, specifically in North America. 

As we have more control over our data centers and offices than many other parts of our value chain, scope 2 emissions are a key focus of our 
decarbonization efforts. Our scope 2 emissions reduction efforts to date include energy management and clean energy procurement. Our path forward 
details our forward-looking strategy for clean electricity for our data centers to further reduce scope 2 emissions. 

80 



Scope 3 (ambition-based) 
Scope 3 emissions are indirect emissions that occur across the supply chain, making them further removed from our direct control and therefore requiring a 
longer runway to make significant progress. In 2024, our total scope 3 (ambition-based) emissions were approximately 8.4 million tCO2e, representing 73% of 
our total 2024 ambition-based carbon footprint. 

Compared to 2023, our total scope 3 (ambition-based) emissions increased by 22%, primarily due to increases in data center capacity delivery (i.e., 
emissions generated from the manufacturing and assembly of technical infrastructure hardware—including for AI—and their logistics, as well as from data 
center construction). 

We expect to increase, relative to 2024, our investment in our technical infrastructure—including servers, network equipment, and data centers—to support 
the growth of our business and our long-term initiatives, in particular in support of AI products and services. We’re focused on decoupling this growth from a 
proportional increase in emissions, and Our path forward outlines two key areas where we’re helping our suppliers to reduce their emissions: clean electricity 
for our supply chain and low-carbon data center construction. 

Avoided emissions 
Figure 14. Avoided emissions 

For over two decades, we’ve 
been implementing initiatives 30 

and technological improvements 
that have helped decarbonize our 66% 
operations and supply chain. lower 

20 

While our total reported emissions 
have increased in recent years,  
these initiatives continue to make  

10 
a meaningful impact—without them, 
our emissions would have  
been higher. 

0 

In 2024, we estimate our ambition- 2019 2020 2021 2022 2023 2024 
Year 

based emissions were 66% lower 
Legend 

than they would have been without Avoided emissions Emissions 
clean energy procurement, machine 

PUE improvements Total reported (ambition-based) emissions Scope 2 (market-based) 
hardware efficiencies, and PUE 

Clean energy procurement Scope 3 (ambition-based) Scope 1 
improvements 119 (Figure 14). 

Machine hardware efficiencies 

Carbon reduction progress 
In 2024, our total ambition-based emissions were 11.5 million tCO2e, representing a 51% increase compared to 2019. 

• Operations: Combined scope 1 and scope 2 (market-based) emissions were 3.1 million tCO2e, representing a 241% increase compared to 2019. 
• Supply chain: Scope 3 (ambition-based) emissions were 8.4 million tCO2e, representing a 25% increase compared to 2019. 

Graph 

7. 5 

Legend 

Our operational emissions 

Total operational emissions 
5 

Scope 2 (market-based) 

Scope 1 

Supply chain emissions 
2.5 Total scope 3 (ambition-based) 

emissions 

Scope 3 (ambition-based) 

0 
2019 2020 2021 2022 2023 2024 

Year 

81 

Million tCO2 e 

Million tCO2 e 



Year-on-year progress 
Unit 2022 2023 2024 

Operations: Scope 1 + scope 2 (market-based) Year-on-year % change 37% increase 36% increase 11% reduction 

Supply chain: Scope 3 (ambition-based) Year-on-year % change 4% increase 7% increase 22% increase 

Total ambition-based emissions Year-on-year % change 12% increase 15% increase 11% increase 

2019 base year 
Legend 

tCO2e 

10 Exclusions from scope 3 (Category 2: Capital goods) and (Category 11: Use of sold products) 292,000 

Exclusions from scope 3 (Category 1: Purchased goods and services) 1,914,000 

Scope 3 (Category 7: Employee commuting) 203,000 
7. 5 

Scope 3 (Category 6: Business travel) 461,000 

Scope 3 (Category 5: Waste generated in operations) 14,000 

Scope 3 (Category 4: Upstream transportation and distribution) 476,000 
5 

Scope 3 (Category 3: Fuel- and energy-related activities [not included in scope 1 or scope 2]) 425,000 

Scope 3 (Category 2: Capital goods) and (Category 11: Use of sold products) 4,292,000 

2.5 Scope 3 (Category 1: Purchased goods and services) 873,000 

Scope 2 (market-based) 835,900 

Scope 1 81,900 
0 

2019 Total 2019 ambition-based emissions 7,661,800 
Year 

Trend 
In 2024, our total ambition-based emissions were 11.5 million tCO2e, representing an 11% year-on-year increase and a 51% increase compared to our 2019 
base year—primarily driven by increases in supply chain emissions. 

The year-on-year increase was slightly offset in that we reduced our scope 1 and scope 2 (market-based) emissions by 8% and 11%, respectively— 
demonstrating that our operational decarbonization efforts are bearing fruit. This achievement is particularly significant given the 27% increase in our 
electricity consumption compared to 2023. 

Details 
Science Based Targets initiative (SBTi) validation: 
In February 2025, the SBTi validated Alphabet’s near-term science-based emissions reduction ambition based on our data, company structure, and activities at 
that time. 120 

Scope: 
All Alphabet scope 1, 2 (market-based), and 3 emissions with the exception of food program purchases, certain purchased goods and services associated 
with Alphabet’s day-to-day operations, 121 and Other Bets capital goods. 122  Starting this year, in line with SBTi’s guidelines, we’ve excluded these scope 3 
activities given they are peripheral to our core operations or our ability to influence emissions reductions is limited. These exclusions are reflected for all 
reported years of our ambition-based emissions data. These exclusions collectively account for 25% of our 2019 scope 3 footprint, which is well within 
SBTi’s guidelines to exclude no more than 33% of base year scope 3 emissions. 123  To learn more about the methodology behind our GHG accounting and 
carbon reduction ambition, refer to the Methodology section. 

Base year:  
When setting our carbon reduction ambition in 2021, the most recent emissions inventory available was from 2020. However, since operations were 
significantly impacted by the COVID-19 pandemic that year, we determined it wasn’t representative of a typical year. Instead, we selected 2019—the most 
recent year with representative data—as the base year. 

82 

Million tCO2e 



Our path forward 
In 2021, we set out an ambition to reach net-zero emissions across all of our operations and value chain by 2030. To meet this ambition, we aim to reduce 
over time our absolute, combined scope 1, 2 (market-based), and 3 emissions by 50% from a 2019 base year, and we plan to invest in a range of carbon 
removal solutions to neutralize our remaining emissions. 124  This year, we’re sharing more details about our approach to this moonshot. 125 

We outline how we’re working toward net-zero emissions over the next five years. Our path forward is guided by science, grounded in robust measurement 
and reporting, and designed to deliver real-world results. It outlines our expected carbon reductions in the coming years, which are based on a multi-year 
process we’ve followed to identify and prioritize carbon reduction initiatives, 126 resulting in three key areas that help drive reductions across our operations 
and supply chain. 

A note on the expectations in this section: 
We’re at an extraordinary inflection point, not just for our company specifically, but for the technology industry as a whole—driven by the rapid growth of 
AI. This evolving landscape introduces significant uncertainties that may impact our future trajectories and the precision of our forecasting, including: 

• Infrastructure, energy, and non-linear growth: The combination of AI’s potential for non-linear growth driven by its unprecedented pace of 
development and the uncertain scale of clean energy and infrastructure needed to meet this growth makes it harder to predict our future 
emissions and could impact our ability to reduce them. 

• Evolving government policies: The policy landscape is constantly evolving, creating uncertainty around future regulations, tax considerations, 
and other government programs that could impact our business and emissions trajectories. 

• New opportunities and risks: The development of AI could create both new business opportunities and unforeseen risks that may alter our plans. 

While based on current estimates, the expectations in this section should be considered in light of these factors. 

Emissions trajectories 
We made meaningful progress in 2024, particularly across our operational emissions (i.e., scope 1 and scope 2): 

• Scope 1: Our scope 1 emissions decreased by 8% year-on-year in 2024, following a 13% year-on-year reduction in 2023. 
• Scope 2: Our scope 2 (market-based) emissions decreased by 11% year-on-year in 2024. 

However, the emissions from our supply chain (i.e., scope 3)—which are further removed from our direct control—are still increasing: 

• Scope 3: Our ambition-based scope 3 emissions increased by 22% year-on-year in 2024. 

Overall, total emissions have grown in recent years alongside the growth of our business and growing product adoption by users around the world (Figure 15). 
The majority of these emissions are indirect, coming from our supply chain. We’re actively working to bend our emissions curve toward our net-zero ambition. 

Figure 15. Our path forward 127 

Illustrative emissions 

12  

9 

6 

3 

0 
2019  2020  2021  2022  2023  2024  2030  

Year 

Legend Reported ambition-based emissions Illustrative ambition-based emissions Net emissions 

Illustrative business-as-usual emissions 

83 

Million tCO2e  



Key reduction areas 
Building on the lessons and achievements from our first two decades of climate action, we developed a company-wide approach to guide our progress. 
Our net-zero approach includes carbon reduction initiatives across scopes 1, 2, and 3. We’re prioritizing three key areas of emissions reductions, which we 
estimate will collectively contribute to the majority 128 of our projected 2030 emissions reductions: clean electricity for our data centers, clean electricity for 
our supply chain, and low-carbon data center construction (Figure 16). 

Figure 16. Expected carbon reductions from key reduction areas and additional carbon reduction initiatives in 2030 

Illustrative business- Clean electricity Clean electricity Low-carbon data Additional carbon Remaining 
as-usual emissions for our data centers for our supply chain center construction reduction initiatives emissions 

Key reduction areas 
Legend 

Illustrative business-as-usual emissions Expected carbon reductions Carbon removals

Clean electricity for our data centers 
We’re prioritizing the decarbonization of our operational electricity consumption because it represents the largest reduction opportunity and is an area 
where we have more direct control—specifically over the energy supply for our data centers and offices—compared to our broader value chain. 

In 2024, our scope 2 (market-based) emissions were approximately 3.1 million tCO2e, about 95% of which resulted from the electricity needed to power our 
data centers and offices. 

Our approach to this key reduction area begins with increasing the energy efficiency of our data centers to help minimize our electricity demand. In 
2024, the average annual PUE for our global fleet of data centers was 1.09, compared with the industry average of 1.56, meaning that Google data centers 
used 84% less overhead energy than the industry average. 129  We’ll continue to build on this progress by driving additional energy efficiency and flexibility 
measures in our data centers—with a focus on our machine learning fleet. 

After efficiency, our next focus is on scaling our clean energy procurement across all regions: In 2024, we signed contracts to purchase over 8 GW of 
additional clean energy generation 130—more than in any prior year. We’re also using Google’s engineering expertise and purchasing demand to accelerate 
the commercialization of advanced CFE technologies and scale their climate impact, and advocating for energy policies that can unlock access to cost-
effective and reliable clean energy. And while we’re prioritizing clean energy procurement, we’re also purchasing T-EACs when local clean energy options 
aren’t available. 

Clean electricity for our supply chain 
Electricity-related emissions from activities outside our direct operations come from both supplier and non-supplier sources. 131  We use life cycle 
assessments (LCAs) to determine emissions hotspots, enabling us to focus our efforts on the commodities and suppliers where we can drive the largest 
carbon reduction. 

In 2024, our total scope 3 (ambition-based) emissions were approximately 8.4 million tCO2e, representing 73% of our total 2024 ambition-based carbon 
footprint. Approximately 60% of these emissions came from electricity use across our value chain, so our largest opportunity for reducing scope 3 
emissions is in enabling our value chain’s adoption of clean electricity. 

Our approach to this key reduction area is to engage our suppliers to commit to directly procuring clean electricity—or matching their energy use with 
clean energy—for our most carbon-intensive components. The Google Clean Energy Addendum (CEA) asks suppliers to commit to achieving a 100% clean 
electricity match by the end of 2029 for the electricity they use to manufacture Google products. 132 By the end of 2024, many key suppliers signed our 
CEA, and we plan to continue driving clean energy progress within our supply chain through our CEA, clean energy investments, and other initiatives. 

While our primary focus will remain on engaging our suppliers to reduce their emissions through clean energy procurement, we’ll also continue to explore 
purchasing EACs for select scope 3 categories in the near term—while continuing to strongly advocate for policy and market intervention efforts that 
expand supplier access to clean energy. 

84 

Expected 2030
ambition-based emissions 



Low-carbon data center construction 
Our data center construction projects are generally multi-year projects with multiple phases. Emissions primarily come from the embodied carbon of 
construction materials, such as steel and concrete, as well as from vehicles and generators used during construction. 

In 2024, emissions from data center construction increased 54% year-on-year, reaching approximately 1.6 million tCO2e and representing 19% of our total 
2024 ambition-based scope 3 emissions. Our data center construction emissions—which are already meaningful and expected to increase in the near term 
as we build more data centers to meet demand—therefore represent a key area for decarbonization. 

Our approach to this key reduction area begins with carbon-aware data center design. We design our data centers with standardization and optimization as 
core principles, focusing on efficiency and modular scalability to meet our computing needs. The standardized nature of Google’s data center designs allow 
us to reduce the materials required for construction. Our data center design teams have already optimized several core elements of Google’s standard 
data center design—which collectively have the potential to reduce the embodied carbon emissions intensity of a data center building by around 9%. 133 

The use of low-carbon construction materials is another important part of our work in this area. We plan to scale the use of low-carbon concrete across 
our data center construction projects, as well as expand the use of low-carbon steel—which has the potential to reduce embodied carbon emissions from 
data center construction by up to 40%. 134  The electrification of on-site construction activities, supported by clean electricity procurement for data center 
construction, is another way we’re addressing data center construction emissions. Additionally, we’re maximizing the utilization of our data center capacity, 
ensuring fully utilized infrastructure and greater space efficiency. 

Managing remaining emissions 
While our primary focus is on decarbonizing our operations and value chain, we’re also committed to neutralizing our remaining emissions by 2030 through 
a portfolio of carbon credits that serve as high-impact climate solutions, with an eye toward maximizing positive impact on the atmosphere. We’re focusing 
on accelerating a range of projects and forging strategic partnerships that will help us achieve our net-zero ambition. 

In 2024, we significantly expanded our carbon removal portfolio, signing 16 new offtake deals representing over $100 million for a total of approximately 
728,300 tCO2e of removal credits. This brings our cumulative total portfolio to approximately 782,400 tCO2e—a 14-fold increase from our 2023 removal 
credits portfolio. For more details, refer to the Environmental metrics data tables section. 

A core component of this strategy is to play a meaningful role in advancing the development and deployment of a range of carbon removal solutions, which 
are vital for broader climate change mitigation efforts. 

We prioritize two fundamental criteria when considering the climate impact of these efforts: scale and certainty. For scale, we consider whether the 
solution can become big and affordable enough to make a difference for the planet. Ideally, the most effective solutions will be able to scale up to at least 
half a gigaton per year of CO2e reductions and become affordable and widely available in the foreseeable future. For certainty, we strive to ensure that 
projects deliver their claimed climate impact by rigorously assessing factors like additionality, leakage, permanence, and verifiability. 

85 



Water and waste 
Beyond climate, we’ve also set ambitions across other operational areas like water and waste. Many of the challenges and uncertainties described above 
also relate to these ambitions, particularly for water replenishment and data center Zero Waste to Landfill, which are both connected to our data center 
capacity delivery. 

Water replenishment 
We aim to replenish 120% of the freshwater volume we consume, on average, across our offices and data 
centers by 2030. 

In 2024, our water stewardship projects replenished approximately 4.5 billion gallons of water (17 billion liters or 17 million cubic meters), or 
roughly 64% of our freshwater consumption. 135 

Graph 

7,500  

5,000  

64% 

2,500  

18% 

6% 
0 

2022 2023 2024 

Year 
Legend 

Estimated water replenished Total freshwater consumption for offices and Capacity of all contracted water replenishment 
Google-owned and -operated data centers projects once fully implemented 

Trend Details 
Our water stewardship projects replenished approximately 4.5 billion We set this ambition in 2021, and it covers water that’s replenished as 
gallons of water (17 billion liters or 17 million cubic meters) in 2024 a percentage of the amount of freshwater we consume each year at 
alone, increasing replenishment of our freshwater consumption from our offices and data centers (i.e., excluding seawater and reclaimed 
18% in 2023 to 64% in 2024. 136  This was the result of both the continued wastewater). We count replenishment benefits from projects that are 
success of our existing projects and the implementation of new projects active within the watersheds that our operations rely on and that have 
that have further expanded our replenishment portfolio. confirmed volumetric benefits from the reporting year. 

86 

Million gallons 



Data center Zero Waste to Landfill 
We aim to achieve Zero Waste to Landfill for our global data center operations. 

In 2024, 35% of Google-owned and -operated data center campuses achieved Zero Waste to Landfill. 

Trend Graph 
35% of Google-owned and -operated data center campuses 40 

met our Zero Waste to Landfill ambition, up from 33% in 2023. 137  
While two additional data center campuses achieved this 
milestone in 2024, four data center campuses that came into the 
scope for our ambition did not achieve greater than 90% landfill 30 

diversion, impacting our overall progress toward this ambition. 

Details 20 

We set this ambition in 2016. With regard to annual operational 
waste for all Google-owned and -operated data center 35% 
campuses globally, we consider “Zero Waste to Landfill” for 33% 
our data center operations to mean that more than 90% of 10 23%
waste is diverted from landfill and incineration, in line with 
industry standards. Our waste diversion methodology considers 
thermally processed waste (i.e., incineration), with or without 

0
energy recovery, as waste disposal. 

2022 2023 2024 

Year 
Legend Data center campuses yet to achieve our Zero Waste to Landfill ambition

Data center campuses that have achieved our Zero Waste to Landfill 
ambition

Food waste 
We aim to divert all food waste from landfill by 2025. 

In 2024, we diverted 85% of food waste from landfill. 

Trend Graph 
Our food waste diversion rate increased from 82% in 2023 to 100

85% in 2024 due, in part, to our focus on improving waste bin 
sorting guidance and signage. Challenges remain amid limited 
composting infrastructure in certain regions—including Asia 85% 82% 85% 
Pacific—which continues to impact our ability to divert food 75 
waste from our kitchen and cafe operations. 

Details 
We set this ambition in 2022, and it covers annual food waste 50

that’s diverted from landfills and incinerators in kitchens 
and cafes at Google’s offices globally. We consider sending 
“zero food waste to landfill” as 99% diversion via composting, 
anaerobic digestion, donations, or other on-site processing 

25 
methods—which goes further than the 90% industry standard 
for Zero Waste to Landfill. 

0 

2022  2023  2024  

Year 
Legend Percentage of food waste diverted from landfill 

87 

Percentage Data center campuses 



Recycled plastic 
We aim to use recycled or renewable material in at least 50% of plastic used across our consumer hardware 
product portfolio by 2025. 

40% of the plastic Google used in products manufactured in 2024 was recycled content. 138 

Trend Graph 
The percentage of plastic used in our manufactured consumer 

40 
hardware products that was recycled content increased from 41% 40% 
34% 139 in 2023 to 40% 140 in 2024, due to changes in our product 
mix, primarily driven by a decrease in the manufacturing of 36% 

34% 
Google products with low recycled content in 2024. 30 

Details 20 

We set this ambition in 2020, and it includes the minimum 
percentage of recycled or renewable plastic content calculated 
as a percentage of total plastic (by weight) in Google’s 10 
consumer hardware portfolio for products manufactured in a 
given year. The following may be excluded from the calculation 
of percentage: printed circuit boards, labels, cables, connectors, 
electronic components and modules, optical components, 0

electrostatic discharge components, electromagnetic 2021 2022 2023 2024 
interference components, films, coatings, and adhesives. 

Year 
Renewable content consists of plastic made from bio-based 
material. This ambition doesn’t include third-party products Legend Percentage of recycled or renewable material in plastic 
such as the Nest x Yale Lock. used across our consumer hardware product portfolio 

Plastic-free packaging 
We aimed to make product packaging 100% plastic-free by 2025. 

We reached our ambition early: Packaging for new Google products launched and manufactured in 2024 was 100% plastic-free. 141 

Trend Graph 
The increase from at least 99% plastic-free packaging in 2023 Ambition achieved 
to 100% in 2024 was primarily due to packaging innovations, ahead of schedule 

including implementing fiber-based solutions in our packaging 
material catalog. 142 100

97% 96% 99% 100%

Details 75

We set this ambition in 2020, and it is based on the total weight 
of new Google Pixel, Nest, and Fitbit retail packaging globally 
(excluding adhesive materials and required plastic stickers) 50 

for products launched and manufactured in a given year, as 
shipped by Google. 

25 

0 

2021 2022 2023 2024 

Year 

Legend Percentage of product packaging that was plastic-free for 
new Google products launched and manufactured each year 

88 

Percentage 
Percentage 



Governance and risk management 

Sustainability governance 
Alphabet’s Audit and Compliance Committee has the primary responsibility for the oversight of a number of risks facing our businesses. It reviews and 
discusses with management any major risk exposures, including sustainability risks, and the steps that Alphabet takes to detect, monitor, and actively 
manage such exposures. Our Sustainability Focus Area, an internal management team led by our Chief Technologist, Learning and Sustainability, provides 
centralized management oversight of sustainability and climate-related issues. The Sustainability Focus Area includes the Chief Sustainability Officer 
and executives from across the company with diverse skills, from teams such as operations, products, finance, marketing, legal, communications, and 
policy, among others. Through the Sustainability Focus Area, sustainability and climate ambitions are built into our company-wide goals, plans of action, 
management policies, performance objectives, and how we monitor progress. 

Net-zero governance 
Our net-zero ambition is governed by a framework to ensure accountability at all levels. We’ve launched a company-wide net-zero governance model 
that includes cross-functional planning processes, a company-wide carbon reduction and net-zero approach, and central resourcing. A critical part of 
the framework is our net-zero working group, a monthly forum of cross-functional leaders who convene and drive the execution and operationalization 
of our carbon reduction and net-zero ambitions, primarily through advancing progress on key carbon reduction initiatives. In this forum, a central team 
coordinating the cross-company efforts provides updates that help the working group align on priority areas, foster effective collaboration, and make 
informed decisions. We also share quarterly updates and hold bi-annual engagement sessions across our senior leadership (which can include our VPs, 
SVPs, CFO, and CEO), providing a direct line of communication between the leadership team and the teams responsible for executing our net-zero 
strategy. This engagement enables senior leaders to provide guidance, remove roadblocks, and ensure that resources are allocated effectively to support 
our net-zero initiatives. 

Risk management 
Our Enterprise Risk Management (ERM) team works with subject matter experts across the enterprise to identify, assess, and report risks related to the 
company’s operations, financial performance, and reputation. As with financial, operational, and strategic risks, Google assesses environmental risks as 
part of the company’s overall risk management framework. 

Risks and opportunities identified support public disclosures and inform Google’s environmental sustainability strategy. Our Chief Sustainability Officer and 
sustainability teams work to address risks by identifying opportunities to reduce the company’s environmental impact from its operations and value chain, 
and by improving climate resilience. 

Climate-related risks 
Climate-related risks and opportunities can span multiple time horizons and may have varying levels of uncertainty regarding how climate trends, policy, 
and socioeconomic factors might evolve in the future. We’ve used qualitative and quantitative risk assessments to identify climate-related risks and 
opportunities and understand their associated impact. We’ve aligned our climate risk assessment process closely with the recommendations of the 
Task Force on Climate-Related Financial Disclosures (TCFD), and we’ve leveraged the TCFD categories of risks and opportunities and conducted climate 
scenario analyses. We use our ERM rating scales (i.e., impact, frequency, likelihood, control effectiveness) to identify and prioritize areas of focus. We’ve 
analyzed climate-related risks and opportunities across three time horizons—short term (through 2030), medium term (through 2040), and long term 
(through 2050)—for financial, operational, legal, and strategic risks. Climate risks were modeled under high- and low-emissions scenarios for both physical 
and transition risks using scenarios developed by the Intergovernmental Panel on Climate Change (IPCC) and the Network for Greening the Financial 
System (NGFS). We considered acute and chronic physical risks (e.g., heat stress, water stress, and extreme weather events), as well as risks associated 
with transitioning to a low-carbon economy (e.g., energy costs, future regulations, and technology). We also assessed climate-related opportunities (e.g., 
developing low-carbon products and services, improving energy efficiency, and advancing energy technologies). For more details, refer to our CDP Climate 
Change Response. 

Water-related risks 
To identify and assess water-related risks in our direct operations, Google annually undertakes a water risk assessment of our data centers and offices to 
identify potential water-related risks and opportunities for water stewardship action and risk mitigation. Indicators from available risk assessment tools, 
including the WRI’s Aqueduct Water Risk Atlas 3.0 and the World Wildlife Fund (WWF) Water Risk Filter 6.0, are blended with other metrics to evaluate risks 
related to scarcity, flooding, water quality, sanitation and hygiene, reputation, and regulatory stressors. 

We also apply our data center water risk framework to measure and evaluate site-level water risks and the potential watershed impact to inform our 
decision-making process for new site selection, cooling system design, and ongoing operations. We apply this framework to every new data center site 
(including new sites before acquisition and future developments on existing campuses) and aim to repeat these assessments across our existing Google-
owned and -operated data center portfolio every three to five years to evaluate water risks that may require mitigation. We also use this framework to 
inform our water replenishment efforts, by prioritizing replenishment in locations with higher risk. 

To identify and assess water-related risks in our supply chain, we’ve conducted a supply chain water use analysis and a supplier risk assessment using WRI’s 
Aqueduct Water Risk Atlas, WWF’s Water Risk Filter, and WULCA AWARE. The key risks identified included baseline water stress, flood risk, access to safe 
drinking water, and the level of sanitation and hygiene services. 

89 



Stakeholder engagement and partnership 

We recognize that achieving our own sustainability ambitions and addressing the urgency of climate change and sustainability requires engagement, 
collaboration, and partnership across a diverse set of stakeholders—both within our operations and supply chain, as well as beyond. That’s why we actively 
engage with a wide range of stakeholders, including employees, suppliers, policymakers, NGOs, customers, researchers and academics, and more. These 
engagements and partnerships are essential for: 

• Overcoming barriers to unlock new opportunities: We work together to overcome obstacles and accelerate advancements in 
sustainability. Only through collaboration can we develop and implement solutions on a global scale. 

• Shared learning: Our engagement work also enables us to better understand our stakeholders’ perspectives, elaborate on our environmental 
strategy, and advance key ambitions. This creates a vital two-way dialogue that informs our approach to the work. 

• Driving systemic change: These partnerships are crucial for advancing carbon-free energy technology investment, shaping effective 
policies, and scaling up climate solutions around the world. 

The following content summarizes how we engage with these stakeholder groups. 

Employees 
Sustainability is embedded within Google’s culture. We foster this culture by actively engaging employees through internal groups and learning platforms, 
while also supporting sustainable commuting and reducing the environmental impact of our employees’ business travel. 

Community groups and learning 
Employees can join global and local internal community groups focused on sustainability. These groups engage in a variety of activities focused on 
organizing local sustainability activities and raising awareness about environmental topics for interested Googlers. For example, one sustainability-related 
internal community group has roughly 3,500 members globally. This community group hosts weekly climate talks featuring internal and external speakers 
and biannual events highlighting sustainability-related 20% opportunities. Google has a program called “20% Time” whereby Google employees are 
allowed to use 20% of their work time to explore innovative ideas beyond their current roles, enabling engineers with technical skill sets to contribute to 
addressing climate and sustainability challenges. 

Employees can also learn about sustainability through online sustainability courses, internal newsletters, campaigns, and websites. 

Employee commuting and business travel 
Our transportation team supports sustainable commuting options to help Googlers get to work—like offering shuttles and encouraging carpooling, 
public transit, biking, and walking. We strive to provide electric vehicle charging stations for 10% of the total parking spaces at our San Francisco Bay Area 
headquarters, and we continue to work toward this design standard for new development projects. As of 2024, we’ve installed more than 6,000 electric 
vehicle charging ports at our offices in the United States and Canada. Google also offers commuter shuttles to many of its campuses to reduce individual 
vehicle commuting. On average, in 2024, electric vehicles comprised 24% of our commuter “GCab” fleet in India. 

We’re also working to reduce the impact of our employees’ business travel by exploring ways to make air travel less carbon-intensive and supporting 
the production of SAF at scale. In 2023, Google joined the Avelia Sustainable Aviation Fuel program, which offers SAF credits to corporate customers. 
Additionally, in 2024, Google joined the United Airlines Ventures Sustainable Flight Fund, a first-of-its-kind effort to provide catalytic investment to drive 
SAF production. And as a member of the Sustainable Aviation Buyers Alliance, we’re also collaborating with other companies to drive SAF adoption. 

Suppliers 
Through our Supplier Responsibility Program, we’re working to build an energy-efficient, low-carbon, circular supply chain. We focus on the areas where we 
can make an immediate and lasting impact, such as helping our suppliers improve their environmental performance. 

Google’s Supplier Code of Conduct includes requirements that enable us to ensure that those we partner with are responsible environmental stewards. 
Along with having suppliers evaluate their operations, we perform our own ongoing due diligence and audits with select suppliers to verify compliance and 
understand our supply chain’s current and potential risks. 

We investigate any issues identified during an audit, and when we find that a supplier isn’t conforming to our expectations, we expect the supplier to 
provide a corrective action plan that outlines the root cause of the finding, how and when they will resolve the issue, and what steps will be taken to 
prevent recurrence. We determine whether the plan is acceptable based on our Supplier Code of Conduct requirements. Lastly, we monitor and verify all 
corrective actions are completed in the agreed-upon time frame, with a process for escalation if necessary to the Supplier Responsibility Steering Team, 
which comprises our Chief Compliance Officer and leaders from our data center, devices, and extended workforce teams. 

90 



In 2024, we audited a subset of our suppliers to verify compliance for various environmental criteria (Figure 17): 

Figure 17. 2024 audit conformance data for environmental criteria 
The lighter bars show the percentage of unique audited supplier facilities that had no findings for the listed criteria after their audit. The darker bars 
show the percentage that had no findings after the corrective action plan process was completed. 

Environment 

Environmental permits and reporting 97.5% 99.2% 

Hazardous substances 93.4% 96.7% 

Solid waste 96.7% 99.2% 

Air emissions 90.1% 94.2% 

Water management 98.4% 98.4% 

Energy consumption and greenhouse gases 86.8% 92.6% 

Environment Management Systems 

Risk assessment (and risk management) 93.4% 95.9% 

Environmental control processes 86.0% 93.4% 

Communications 88.4% 91.7% 

Performance review and continuous improvement 90.1% 94.2% 

Legend Percentage in conformance before CAP Percentage in conformance after CAP 

Reporting environmental data 
We work directly with some of our suppliers to collect data. We also encourage suppliers to participate in CDP’s corporate questionnaire by asking them 
to disclose climate- and water-related data via the CDP supply chain platform. In 2024, we invited 227 suppliers to participate, and 96% responded. Of the 
suppliers that we invited to respond in 2024, 76% reported having GHG emissions reduction targets. 

To support these efforts, we work with our suppliers to improve their environmental data collection and accounting, including for their scope 1, 2, and 3 
emissions. For example, we provide training on CDP reporting, as well as on setting carbon reduction and renewable electricity targets. In 2024, we hosted 
a summit for our consumer hardware device suppliers where we discussed Google’s ambitions. 

Restricted substances 
Through our consumer hardware product Restricted Substances Specification and Manufacturer Restricted Substances List, we restrict many 
hazardous substances with hazard-based requirements and ensure our suppliers have processes in place to detect and prevent them from entering the 
manufacturing process. We also maintain a Responsible Chemical Management program, which includes assessments, guidance, and training resources to 
help suppliers better mitigate occupational and environmental risks related to the chemicals they use. 

Customers 
We’re committed to helping our customers achieve their sustainability ambitions, and we offer a variety of tools and resources to support them. We 
recognize that collaboration and information sharing are crucial for accelerating progress toward a more sustainable future, and we’re dedicated to 
providing our customers with the support they need to make a positive impact. 

Google Cloud 
Google Cloud offers organizations Cloud and AI products and solutions to drive impact for their business and sustainability. We help organizations harness 
AI for improved sustainability measurement to build resilience, AI-powered insights to use energy and resources more efficiently in operations and supply 
chains to reduce costs, and AI tools to unlock new growth opportunities and markets while accelerating sustainability impact and reducing the carbon 
footprint of Cloud. 

• Measure: We help organizations use AI-powered insights to monitor their progress toward sustainability targets in order to build business 
resilience. For example, our Cloud partner Watershed’s software platform is used by companies to manage climate and ESG data, produce 
audit-ready metrics for reporting, and drive real decarbonization. 

91 



• Optimize: We help organizations work more efficiently by using AI to streamline energy and resource usage across their operations 
and supply chains. For example, Google Cloud, in partnership with NGIS (and their solution TraceMark), is helping brands gain a deeper 
understanding of sustainable sourcing practices across supplier networks. By combining the power of our cloud computing, AI, and 
geospatial analytics, we’re helping companies get real-time, global, reliable information into operations at a local supplier level. 

• Grow: We help organizations adapt their business by using AI to uncover new growth opportunities in the low-carbon transition. For example, 
we launched SpatiaFi with our Cloud partner Climate Engine—an Earth Finance Company—to help the banking sector harness the power of 
geospatial analytics to support climate finance. 

• Build: We help developers take action to reduce the carbon footprint and cost of their applications in their use of Cloud. For example, we’ve 
created a Carbon Sense suite so customers can accurately measure, report, and reduce their cloud carbon emissions (through Carbon 
Footprint) with recommendations for carbon reduction actions (through Region Picker, Carbon-free energy disclosure, and Active Assist). 
The Carbon Sense suite has experienced significant adoption, with customers monitoring over 65% of total Google Cloud emissions as of the 
end of 2024. Enhancements to the suite included the addition of scope 2 market-based emissions data, complementing the existing location-
based data, which underscores Google’s aim of providing transparent and comprehensive emissions reporting for our customers. 

Customer carbon footprints 
In addition to equipping Cloud customers, we also provide tools to empower Google Workspace and Google Ads customers to measure, understand, and 
manage the environmental impact of using our products: 

• Google Workspace: Our Google Workspace carbon footprint report provides data on total and monthly carbon emissions based on the use 
of various Google Workspace applications. 

• Google Ads: To help advertising customers measure their emissions from using Google advertising products, we now offer Carbon Footprint 
for Google Ads. This provides comprehensive carbon emissions reporting data aligned with the Greenhouse Gas Protocol and developed in 
accordance with the Global Media Sustainability Framework. The reports provide detailed breakouts of scope 1, scope 2 (both market- and 
location-based), and scope 3 emissions—allocated at the account level. 

Researchers and academics 
We recognize the vital role that research plays in addressing complex environmental challenges, so we partner with researchers and academics in our 
collective pursuit of knowledge, innovation, and thought leadership on topics ranging from energy, decarbonization, AI, and more. 

In 2024 and early 2025, we published our own studies or collaborated with academics and other partners on the following research: 

Topic Research 

Adaptation • “A Data-Centric Perspective on the Information Needed for Hydrological Uncertainty Predictions,” Hydrology and Earth Systems 
Sciences, September 2024. 

and resilience 
• “An Artificial Neural Network to Estimate the Foliar and Ground Cover Input Variables of the Rangeland Hydrology and Erosion 

Model,” Journal of Hydrology, March 2024. 

• “Generative Emulation of Weather Forecast Ensembles with Diffusion Models,” Science Advances, March 2024. 

• “Global Prediction of Extreme Floods in Ungauged Watersheds,” Nature, March 2024. 

• “Neural General Circulation Models for Weather and Climate,” Nature, July 2024. 

• “Neural General Circulation Models Optimized to Predict Satellite-Based Precipitation Observations,” arXiv, December 2024. 

• “Reproducing Flash Flood Warnings with Machine Learning,” European Geosciences Union General Assembly 2024, April 2024. 

AI and climate • “Assessing Large Language Models on Climate Information,” arXiv, May 2024. 

• “Life-Cycle Emissions of AI Hardware: A Cradle-to-Grave Approach and Generational Trends,” arXiv, February 2025. 

Clean energy • “24/7 Carbon-Free Electricity Matching Accelerates Adoption of Advanced Clean Energy Technologies,” Joule, February 2025. 

• “Granular Scope 2 Accounting: Achievable Pathways to More Accurate Emissions Reporting,” Boston Consulting Group, 
September 2024. 

Manufacturing • “Overview of F-GHG and Nitrous Oxide Semiconductor Abatement Technologies,” Semiconductor Climate Consortium, 
February 2025. 

92 



Topic Research 

Mitigation • “CANOS: A Fast and Scalable Neural AC-OPF Solver Robust To N-1 Perturbations,” arXiv, March 2024. 

• “OPFData: Large-Scale Datasets for AC Optimal Power Flow with Topological Perturbations,” arXiv, June 2024. 

• “Do Earthquakes “Know” How Big They Will Be? A Neural-Net Aided Study,” arXiv, August 2024. 

• “Feasibility Test of Per-Flight Contrail Avoidance in Commercial Aviation,” Communications Engineering, December 2024. 

• “Google’s Quiet Nuclear Quest: For a Decade, Google Has Advanced Fusion R&D and Other Frontiers,” IEEE Spectrum, 
December 2024. 

• “Probabilistic Weather Forecasting with Machine Learning,” Nature, December 2024. 

• “Satellite Sunroof: High-res Digital Surface Models and Roof Segmentation for Global Solar Mapping,” arXiv, August 2024. 

• “Scalable Learning of Segment-Level Traffic Congestion Functions,” arXiv, September 2024. 

• “On the Relationship of Speed Limit and CO2 Emissions in Urban Traffic,” SSRN, March 2024. 

Nature • “Patterns in Bird and Pollinator Occupancy and Richness in a Mosaic of Urban Office Parks Across Scales and Seasons,”  
Ecology and Evolution, March 2024. 

• “To Crop or Not to Crop: Comparing Whole-Image and Cropped Classification on a Large Dataset of Camera Trap Images,”  
The Institution of Engineering and Technology, November 2024. 

Policymakers 
Public policy and advocacy 
Policy measures and corporate commitments will continue to play an important role in driving emissions reductions in the next decade. 

We’ve shared sustainability policy positions on the following topics: 

• Carbon-free energy: A Policy Roadmap for 24/7 Carbon-Free Energy 
• Climate action with AI: Accelerating Climate Action with AI 
• Device repairability: Google & Repairability 

The following table includes a detailed list of our sustainability policy engagements in 2024: 

Global and cross-cutting initiatives 

Advanced clean electricity technologies: In 2023, Google published a paper outlining how corporate clean energy buyers can accelerate clean energy 
technologies by supporting favorable policies, signing long-term purchase agreements, and providing early-stage project funding. In 2024, we published an 
updated version of this paper to include our detailed procurement criteria for carbon-free energy technologies. 

United Nations Framework Convention on Climate Change (UNFCCC) 29th Conference of the Parties (COP-29): Google participated in COP-29, in 
Baku, Azerbaijan, in over 150 engagements with officials and sustainability industry leaders, partners, and priority stakeholders. 

United Nations General Assembly (UNGA): Google participated in 2024 UNGA meetings in New York City, participating in events and discussions with over 
200 officials and industry leaders. At UNGA, CEO Sundar Pichai delivered a keynote address that laid out Google’s vision for closing the digital divide and how 
AI can accelerate progress on the UN Sustainable Development Goals. 

Policy to deploy digital solutions for climate: In partnership with Deloitte, Google launched the Digital Sprinters: The Road to Sustainability report, which 
explores how digital solutions like AI can help reduce global emissions and aid in climate adaptation, outling steps governments can take to accelerate this work. 

United States 

Engagement on U.S. federal sustainability, climate, and energy policy 

Executive branch engagement: Google had multiple engagements across the White House; Departments of State, Defense, Energy, and Transportation; 
and the U.S. Environmental Protection Agency to discuss the role of digital technology and AI in accelerating climate mitigation and adaptation. 

Federal Energy Regulatory Commission (FERC) colocation engagement: In November 2024, Google testified before FERC on colocation and, in 
December 2024, submitted post-conference comments articulating our colocation position on the record. Google views colocation as a potentially helpful 
tool to address load growth, when done in close partnership and collaboration with utilities and grid planners. Google’s position was used to inform positions 
developed by our trade associations. 

93 



Western energy market expansion: Google was an active participant in the West-Wide Governance Pathways Initiative, organized by a group of state 
regulators. The initiative proposes the creation of a regional organization overseen by an independent governing board that could deliver an electricity 
market comprising all states in the Western Interconnection—including California. Google filed public comments related to stakeholder engagement and the 
group’s step 2 proposal. 

Engagement with coalitions and sustainability initiatives 

Electricity customer coalitions: In 2024, the Electricity Customer Alliance (ECA) testified on behalf of Google and other member companies before the U.S. 
House Energy and Commerce Committee on the issue of AI-driven growth of electricity demand. Additionally, ECA formally submitted comments advocating 
for the implementation of grid-enhancing technologies at FERC and collaborated with other organizations—including Clean Energy Buyers Association (CEBA), 
Data Center Coalition (DCC), and Electricity Consumers Resource Council (ELCON)—to advocate for colocation approach consistent with Google’s position. 

U.S. state engagement 

Clean Transition Tariff (utility rate): Google announced a new, first-of-its kind clean energy partnership with NV Energy called a “Clean Transition Tariff” 
(CTT) that enables Google and other energy users to meet growing power demand cleanly and reliably. The CTT brings utilities and customers together into a 
long-term energy agreement that can facilitate investments into new projects that deliver clean firm energy to the grid. 

Utility regulation: Google participated in many regulatory proceedings and dockets across the United States, collaborating with coalition partners to 
promote the cost-effective adoption of clean energy resources. 

Regulatory frameworks for decarbonization: Google led discussions with the National Association of Regulatory Utility Commissioners on how Google’s 
24/7 CFE ambition can be a supportive framework to drive cost-effective grid decarbonization. 

Europe 

Engagement on European sustainability, climate, and energy policy 

Energy Efficiency Directive: Google engaged with EU policymakers through DIGITALEUROPE to inform the development of a new EU-wide scheme for 
rating data center sustainability under an upcoming delegated act. 

EU Agency for the Cooperation of Energy Regulators (ACER) PPA templates: We participated in ACER’s expert group on PPAs and shared views on the 
role of voluntary standardized PPA templates in Europe. 

European electricity market redesign: In partnership with the RE-Source Platform, we successfully advocated for a stronger role for corporate clean 
energy buyers in the EU’s energy transition, with the adoption of several measures in the final legislation that enhance the role of PPAs. 

Granular Guarantees of Origin: Google signed and helped organize a letter from leading companies, NGOs, and industry associations to EU policymakers 
calling for the faster introduction of Granular Guarantees of Origin (GOs) throughout Europe. Granular GOs help companies track clean energy more 
accurately, enabling the matching of energy production to consumption on an hourly basis. 

Wind power action plan: We worked with other clean energy buyers and developers within RE-Source on input to the European Commission’s consultation 
on design elements of renewable energy auctions’ to ensure a level playing field between contracts for difference and corporate PPAs. 

Engagement with coalitions and sustainability initiatives 

RE-Source Platform: In 2024, Google continued supporting and working with RE-Source to advocate for a stronger role for corporate clean energy buyers 
within European energy markets. We informed RE-Source’s input to the European Commission’s consultation on design elements of renewable energy 
auctions to advocate for policy changes that help unlock the ability of large customers to purchase renewable energy. 

European Green Digital Coalition: We helped develop a science-based methodology and guidelines to assess the reduction and avoidance of GHG 
emissions by information and communication technologies solutions across sectors, which launched in April 2024. 

Partnership with European Aviation Safety Agency (EASA): Google collaborated with EASA on the technical development of a ReFuelEU ecolabel, a uniform 
methodology for calculating flight emissions data. This will increase transparency and empower informed choices by travelers within the aviation sector. 

European 24/7 Hub: We worked with the European 24/7 Hub, a collaboration with Eurelectric, to create a platform where energy buyers, suppliers, and 
policymakers can meet to learn more about 24/7 CFE and receive technical training and implementation guidance. 

24/7 Carbon-Free Coalition: Google was one of six companies to join the pilot launch of the Climate Group’s 24/7 Carbon-Free Coalition, launched at New 
York Climate Week in 2024. The Coalition seeks to encourage and support companies to move toward local and hourly matching of their electricity demand 
with carbon-free electricity. 

Corporate Leaders Group (CGL) Europe: Google became members of CLG Europe to advance policies that support Europe’s decarbonization objectives. 

94 



Asia Pacific 

Energy policy in Asia Pacific: Google participated in engagements with energy policymakers and regulators across Asia Pacific via regionally-focused 
coalitions and initiatives—like the Asia Clean Energy Coalition (ACEC), the SEMI Energy Collaborative (SEMI EC), and the Clean Energy Demand Initiative 
(CEDI)—to promote cost-effective access to clean energy resources. Google also participated in events with energy policymakers—such as Renewable 
Energy Markets Asia and Singapore International Energy Week—to advocate for policies that accelerate the decarbonization of grids in Asia Pacific and 
showcase our 24/7 CFE efforts. 

24/7 CFE in Asia Pacific: Google supported and contributed to a paper by Bloomberg New Energy Finance and the Global Renewables Alliance on how 24/7 
CFE procurement can advance Asia Pacific’s energy transition. 

Expanding clean energy procurement in Asia Pacific: We supported a paper by the Clean Energy Buyers Association (CEBA) and the Asia Clean Energy 
Coalition (ACEC) on how high-impact utility green tariffs can allow utilities and companies to partner to decarbonize grids in the Asia-Pacific region. 

Supply chain decarbonization: We supported Singapore’s National Climate Change Secretariat, part of the country’s Prime Minister’s Office, with the Climate 
Leaders’ Assembly held during New York Climate Week in 2024. In particular, we convened a roundtable on “APAC’s role in decarbonizing supply chains.” 

Trade associations and third-party groups 
We belong to many sustainability-focused third-party groups through which we engage on sustainability policy issues around the world. Refer to Figure 18 
for an overview of our participation in these groups. 

Figure 18. Select list of Google’s participation in sustainability-focused trade associations, memberships, and groups 

• Advanced Energy Buyers Group • Corporate Leaders Group Europe • Princeton ZERO Lab 
• Advanced Energy United • Data Center Coalition • RE100 
• Advanced Power Alliance • DIGITALEUROPE • Renewable Northwest 

• American Clean Power Association • Electric Power Research Institute • RE-Source Platform 

• American Council on Renewable • Energy Alabama • SEMI Energy Collaborative 
Energy • Energy Systems Integration Group • Singapore Carbon Market Alliance 

• Americans for a Clean Energy Grid • EnergyTag • Singapore Sustainable Finance 
• Asia Clean Energy Coalition • Eurelectric Association 
• Beyond Alliance • GeSI • SolarPower Europe 
• Business Environment Leadership • Hydrogen Europe • Southeast Asia Partnership for 

Council of the Center for Climate and Adaptation through Water 
Energy Solutions • Japan Climate Leaders Partnership 

• smartEn 
• Carolinas Clean Energy Business • Keystone Energy Board 

• Southwest Energy Efficiency Project 
Association • Long Duration Energy Storage 

• Trellis Network 
• Clean Air Task Force Council 

• U.S. EPA Green Power Partnership 
• Clean Energy Buyers Association • Marktoffensive Erneuerbare Energien 

• Utah Clean Energy 
• Clean Energy Demand Initiative • North Carolina Sustainable Energy 

Association • We Are Still In 
• Clean Grid Alliance 

• Nuclear Innovation Alliance • WindEurope 
• Corporate Eco Forum 

95 



International and nonprofit organizations 
Google engages in many international partnerships and with many nonprofit organizations to accelerate progress toward shared sustainability ambitions. 
Some of our key partnerships include: 

Organization Details 
24/7 Carbon-Free Energy Compact In 2021, Google helped launch the 24/7 Carbon-Free Energy Compact in partnership with Sustainable Energy for All and UN-Energy to help grow the 

movement to enable zero-carbon electricity. 

Ad Net Zero Google is a founding supporter of and active participant in Ad Net Zero—a global initiative to help the advertising industry tackle the climate crisis. 

Bonneville Environmental  Google has partnered closely with BEF since 2019 on the implementation of our water strategy, including identifying and facilitating impactful water 
Foundation (BEF) replenishment and watershed health projects globally, with a variety of local organizations and partners. 

Building Transparency We work with Building Transparency to advance the development of tools to measure, model, and track the embodied carbon of building materials. 

Business for Social Responsibility (BSR) Google has been a BSR member for many years and is one of a few select Spark Members. We participate in a number of BSR collaboration initiatives, and 
one of our senior leaders sits on its board. 

C40 Cities C40 and Google launched the 24/7 Carbon-Free Energy for Cities program to empower cities around the world to run entirely on clean energy. C40 is a 
strategic partner of Google’s Environmental Insights Explorer (EIE). 

Climate Group 24/7 In 2024, Google supported the pilot launch of the Climate Group’s 24/7 Carbon-Free Coalition at New York Climate Week, a new initiative designed to 
Carbon-Free Coalition encourage energy consumers to move toward 24/7 CFE. 

Coalition to End Wildlife Trafficking In 2018, Google and other companies launched the Coalition to End Wildlife Trafficking Online, collectively creating a wildlife policy framework for online 
Online trade and an industry-wide approach to reduce online wildlife trafficking. 

CDP At Google, we’ve been reporting our carbon footprint to CDP since 2009. We’ve also collaborated with CDP on various initiatives in the past, such as hosting 
its annual conference, hosting a hackathon, and launching CDP scores in Google Finance. 

Clean Energy Buyers Association (CEBA) Google was actively involved in the creation of CEBA in 2018. A Google representative continues to serve as the board chair of this organization. 

Climate Neutral Data Centre Google helped establish the CNDCP, a coalition of European data center operators who commit to a set of voluntary sustainability targets to set them on a 
Pact (CNDCP) path toward climate neutrality. 

Ellen MacArthur Foundation (EMF) Google joined the Ellen MacArthur Foundation’s Network in 2015 and, as a Network Partner, has jointly co-authored thought leadership white papers and 
case studies covering safer chemistry, building deconstruction and reuse, electronics, and the role of AI in the circular economy. 

Environmental Defense Fund (EDF) Since 2012, Google has partnered with EDF to map air quality using Street View cars in the United States, Europe, and Southeast Asia—as well as to detect 
methane leaks in U.S. cities. We’ve launched a partnership with EDF’s MethaneSAT to help power its satellite data analysis, quantify leaks from oil and gas 
infrastructure around the globe, and put methane insights into the hands of scientists and decision-makers. 

EnergyTag Google is an active member of the EnergyTag Advisory Committee, working to enable markets, publish standards, and encourage policies critical for the 
adoption of Granular Certificates and hourly matching. 

European 24/7 Hub Google supported the launch of the European 24/7 Hub with Eurelectric, which provides education on the “what, why, and how” of 24/7 CFE for buyers and 
suppliers in Europe. Google is an active member of the Hub. 

European Green Digital Coalition (EGDC) Google is an active member of the EGDC—a group of technology companies committed to supporting the green and digital transformation of the European 
Union and harnessing the emission-reducing potential of digital solutions for all other sectors. 

Exponential Roadmap Initiative (ERI) In 2021, Google joined ERI and the UN Race to Zero Campaign, the largest ever alliance committed to halving emissions by 2030 and achieving net-zero 
emissions by no later than 2050. 

Frontier In 2022, Google co-founded Frontier, an advance market commitment that will accelerate the development of carbon removal technologies by guaranteeing 
future demand. As one of the founding members of this public benefit LLC, we aim to use Frontier as a catalyst for the most effective technologies in long-
duration carbon removal. 

Global Covenant of Mayors for Google’s Environmental Insights Explorer was developed in partnership with GCoM through a shared vision to support city climate action with useful and 
Climate & Energy (GCoM) accessible data and insights. GCoM is a strategic partner, sharing EIE data with its alliance of cities and local governments to accelerate climate action. 

Global Renewables Alliance (GRA) Google is a supporter of GRA’s campaign to triple renewable energy globally by 2030 and has supported efforts to encourage high-impact corporate clean 
energy purchasing as a key strategy to accelerate progress toward this ambition. 

ICLEI Africa, ICLEI Europe, ICLEI USA Google is a partner of the regional secretariats of ICLEI—Local Governments for Sustainability—in Africa, Europe, and the United States. Through these 
partnerships, ICLEI regional teams support sustainable development projects in cities, using data and insights from EIE. 

International Energy Agency (IEA) We’ve partnered with the IEA on multiple energy-related projects, including research on advancing decarbonization through clean electricity procurement. 
We also surfaced information through Search about the European energy crisis, providing energy-saving tips and electric vehicle and home heating 
information. In 2024, Google partnered with the IEA and others on a two-year “Energy and AI” initiative to explore the challenges of meeting electricity 
demand for AI, as well as the opportunities for using AI to decarbonize the energy sector. 

iMasons Climate Accord Google is a founding member and an active participant in the Governing Body of the iMasons Climate Accord, a coalition united on carbon reduction in 
digital infrastructure. 

Linux Foundation Energy Since 2022, we’ve partnered with LF Energy to develop standards that accelerate secure and scalable data portability for the energy transition. In 2024, we 
focused on industry engagement through webinars and conferences to gather feedback from key stakeholder groups. 

ReFED Since 2018, Google has been working with ReFED—a nonprofit with a mission to catalyze the food system toward evidence-based action to stop wasting 
food—supporting its technical teams and exploring ways to convene businesses. 

Responsible Business Alliance (RBA) In 2024, we supported the Responsible Business Alliance in developing its Waste Minimization Toolkit, which includes a Waste Tracking Record Tool and an 
online learning module to train supply chain facility personnel on waste stream tracking, reporting, and management. 

Symbiosis In 2024, Google co-founded Symbiosis, a new coalition of corporate buyers committed to following the latest science to scale high-quality, nature-based 
carbon removal. 

The Nature Conservancy (TNC) Google has supported TNC on watershed projects in Chile and the United States, and separately, Google.org has provided support to TNC for nature-
related projects, including the restoration of giant kelp forest ecosystems across south-eastern Australia. 

United Nations Food and Agriculture Since 2015, Google and the UN FAO have partnered on forest monitoring, natural resources, livelihoods, and the environment. 
Organization (UN FAO) 

United Nations Environment In collaboration with UNEP and the European Commission Joint Research Centre, Google launched the Freshwater Ecosystems Explorer. This platform 
Programme (UNEP) enables all countries to freely measure and monitor freshwater resources (toward Sustainable Development Goal 6.6.1) as well as learn when and where 

surface water is changing. In 2023, Google.org supported the UNEP International Methane Emissions Observatory in developing a new AI-based automated 
methane emission detection, alerting, and notification system. 

World Business Council for A member of the WBCSD since 2019, Google actively participates in initiatives related to improving well-being for both people and the planet—including 
Sustainable Development (WBCSD) shifting diets, accelerating climate change standards and policy progress, and supporting regenerative agriculture. 

World Economic Forum (WEF) Google partners with WEF on various initiatives, including: the First Movers Coalition, the Chief Sustainability Leaders Community, Tech for Climate 
Adaptation, the Alliance for Clean Air, and the AI Governance Alliance with a focus on the AI and Energy workstream. 

World Resources Institute (WRI) Google has supported WRI since 2007. Some key WRI projects include developing a near real-time land cover dataset (Dynamic World), launching 
deforestation monitoring and alerts (Global Forest Watch), ending commodity-driven deforestation and accelerating restoration (Forest Data Partnership), 
measuring and mitigating extreme heat (supported by Google.org), and educating stakeholders on 24/7 CFE. 

96 



Startups 

Google for Startups Accelerators 
Our sustainability-focused accelerator programs work to identify, support, and scale startups that are building technologies to combat climate change 
and advance sustainability efforts. Google for Startups Accelerators are 10-week programs designed to bring the best of Google’s products, people, 
and technology to Seed to Series A technology startups. In addition to mentorship and technical project support, programming also focuses on product 
design, customer acquisition, and leadership development for participating founders. Since launching the Google for Startups Accelerator: Climate Change 
program in 2021, we’ve hosted seven climate accelerators across five continents, which have collectively supported 83 startups, as of the end of 2024. 

In 2024, we announced another cohort for the Google for Startups Accelerator: Climate Change in Europe. The cohort comprises 15 startups with solutions 
that use Cloud technologies—including AI, geospatial data analysis, and advanced analytics—to develop groundbreaking approaches to environmental 
challenges. We also launched our first-ever Google.org Accelerator: Generative AI, focused on supporting organizations harnessing the power of 
generative AI for a wide range of solutions. One participant, Materiom, is using Vertex AI and Gemini to accelerate the development of sustainable plastic 
alternatives, while another participant, Climate Policy Radar, is using AI to provide insights about climate law and policy decisions. 

Looking ahead in 2025, a new cohort of startups will be able to participate in the Climate Change Accelerator in Europe, and we’ll also launch two new 
accelerator programs. Google for Startups Accelerator: AI for Energy will focus on supporting startups enabling grid flexibility and optimization for clean 
energy deployment and grid resilience, and Google for Startups Accelerator: AI for Nature will assist startups in accelerating their environmental impact by 
using Google’s advanced AI technology for nature protection, conservation, and restoration efforts. 

Startups for Sustainable Development 
Through our Startups for Sustainable Development program, we’re working with impact-driven startups using technology to address one or more of the 
UN’s 17 Sustainable Development Goals, from eradicating poverty and hunger to improving healthcare and advancing climate action. Startups receive long-
term support to scale their impact, including mentoring from expert advisors, connections to funding partners, and access to cutting-edge research and 
technology. In 2024, we began pairing Googlers with startups to add AI solutions to their most impactful projects. Through this engagement, startups were 
able to use machine learning and other models for various applications, including identifying and monitoring tree species to support reforestation efforts, 
predicting utilization rates for electric vehicle chargers, and monitoring marine life. As of the end of 2024, the program has supported more than 600 
startups in over 75 countries, working with a network of over 200 partner organizations. 

Supported organizations 
Google.org—Google’s philanthropy—applies our innovation, research, and resources to promote progress and expand opportunity for everyone. Google. 
org’s efforts are focused across three pillars: knowledge, skills, and learning; scientific advancement; and resilient communities. We empower nonprofits, 
civic entities, and academic organizations with a unique blend of funding, in-kind donations, and technical expertise from Google employees—accelerating 
scientific advancement and catalyzing societal impact. 

Catalyzing early-stage innovation 
We accelerate scientific discovery through support for the global research community. Through the Google Academic Research Awards we funded 
research to create machine learning benchmarks for climate problems. Google.org is also supporting a coalition of global experts using satellite imagery 
and AI to improve agricultural decision making, including advancements in landscape monitoring, soil analysis, crop health assessment, and weather 
integration. Google.org has supported AVPN’s APAC Sustainability Seed Fund since 2022, providing $10 million in funding directly and via capacity building 
programs to support local organizations focused on underserved communities in the region. In 2024, we highlighted AVPN’s 18 funding recipients that are 
using AI and cloud technologies to build sustainability solutions. Through Google.org’s support for the ICLEI Action Fund—a grant program supporting data-
driven solutions for environmental and climate action across Europe—projects have received funding for innovative solutions in cities, tackling issues like 
energy poverty, renewable energy adoption, and sustainable mobility. 

Creating scaled impact for sustainability 
A key focus of Google.org is supporting efforts to accelerate climate action through enabling scientific discovery and the application of technological 
innovation. We do this by supporting organizations that use technology and data, especially AI and machine learning, to support the creation of free, 
open-sourced tools and datasets for the global community. As of the end of 2024, we’ve provided more than $75 million to social impact organizations 
for projects that use AI to build a more sustainable world, primarily through the Google.org Impact Challenge on Climate Innovation, AI for the Global 
Goals, and the Google.org Accelerator: Generative AI, as well as through other funding initiatives and opportunities. We’re also supporting AI for scientific 
breakthroughs through the Google.org AI and Science Fund, which will provide $20 million in funding to support academic and nonprofit organizations 
around the world using AI to address complex problems at the intersections of different disciplines of science. 

Collaborating with others 
Google.org actively champions increased corporate philanthropy for innovation, and we’ll continue encouraging other private actors to join these efforts. 
Our open-call programs demonstrate strong interest from the social impact and social enterprise sectors to use AI to help transition the world to a 
sustainable future. Corporate philanthropy has the opportunity to play an important role in catalyzing innovation and impact by providing resources for bold 
experimentation. That’s why we’ve joined the WEF’s Giving to Amplify Earth Action initiative and have joined other corporate philanthropies and foundations 
to help launch the Corporate Philanthropy Challenge for People and Planet. 

97 



Environmental data 

Methodology 
The reporting period for our environmental data covers our fiscal year January 1, 2024, through December 31, 2024. Most of our environmental data covers 
Alphabet Inc. and its subsidiaries. All reported data is global and annual unless otherwise specified. The below methodologies apply to our GHG emissions, 
as well as certain other carbon, energy, water, and waste metrics, for all years presented in our Environmental metrics data tables. 

Greenhouse gas emissions 
GHG emissions reporting standards 
GHG emissions are calculated according to the Greenhouse Gas Protocol standards and guidance developed by the World Resources Institute (WRI) and 
The World Business Council for Sustainable Development (WBCSD), including A Corporate Accounting and Reporting Standard (Revised Edition) and the 
WRI/WBCSD GHG Protocol Scope 2 Guidance (an amendment to the GHG Protocol Corporate Standard)(collectively, the “Corporate Standard”), as well 
as the Technical Guidance for Calculating Scope 3 Emissions (“Scope 3 Technical Guidance”), and the Corporate Value Chain (Scope 3) Accounting and 
Reporting Standard (“Scope 3 Standard”)(collectively, “the Greenhouse Gas Protocol”). 

Our inventory 
We use the operational control approach to define our organizational boundary, which means that we account for all emissions from operations over which 
we have control. The Greenhouse Gas Protocol defines operational control as having the authority to introduce and implement operational policies over an 
asset, and we report all emissions for Alphabet Inc. and its subsidiaries’ data centers, offices, and other assets under our operational control. 

Our inventory includes all of the seven GHGs addressed by the Kyoto Protocol, where relevant: carbon dioxide (CO2), methane (CH4), nitrous oxide (N2O), 
hydrofluorocarbons (HFCs), perfluorocarbons (PFCs), sulfur hexafluoride (SF6), and nitrogen trifluoride (NF3). However, perfluorocarbons (PFCs), sulfur 
hexafluoride (SF6), and nitrogen trifluoride (NF3) aren’t emitted as a result of our operations and are therefore appropriately excluded from our “GHG 
emissions by type” data table. We report emissions both in the unit of metric tons per gas (e.g., tCO2, tCH4, etc.) and in the standardized unit of metric tons 
of carbon dioxide equivalent (tCO2e), with the exception of biogenic emissions which are reported as tCO2 only. 

We source the global warming potentials (GWP) for each GHG from the Intergovernmental Panel on Climate Change (IPCC) Fourth Assessment Report 
(AR4), IPCC Fifth Assessment Report (AR5), and IPCC Sixth Assessment Report (AR6), and we use the most up-to-date emission factors available when 
calculating our emissions, based on our reporting timelines and requirements. 

We round all reported emissions values to the nearest hundred, except for scope 3 emissions (which we round to the nearest thousand) and emissions per 
gas (which we round to the nearest hundred unless the total is less than 50 tons, in which case we report to the nearest one). 

Scope 1 emissions 
Scope 1 emissions are direct emissions from sources such as company vehicles or generators at our offices and data centers. They represent direct 
emissions from Google-owned and -operated data centers, offices, and other assets, including fuel use from back-up generators, fuel consumption from 
our operated vehicles and aircraft, methane and nitrous oxide from biogenic fuel sources, natural gas usage, and refrigerant leakage. Where actual data 
isn’t available, for example from a utility bill, we estimate natural gas consumption using the square footage of our data centers, offices, and other assets 
and internally developed natural gas intensity factors by office type, based on data from the reporting period. Where actual refrigerant leakage data isn’t 
available, we estimate refrigerant leakage by using an average of GWP values from known refrigerants within our portfolio and leakage rates at our data 
centers, offices, and other assets. 

The emission factors used to calculate scope 1 emissions include the 2024 WRI/WBCSD GHG Protocol Emission Factors from Cross Sector Tools, the 2025 
U.S. Environmental Protection Agency (EPA) Emission Factors for Greenhouse Gas Inventories, the 2024 Climate Registry Default Emission Factors, and the 
2024 Department for Environment, Food and Rural Affairs (DEFRA) UK Government GHG Conversion Factors. 

Scope 2 emissions 
Scope 2 emissions are indirect emissions from purchased electricity; natural gas use and refrigerant leakage in our leased offices; and purchased steam, 
hot water, and chilled water from district energy systems. We report scope 2 emissions using both location-based and market-based methods. The 
location-based method reflects the average carbon intensity of the electric grids where our operations are located and thus where our electricity 
consumption occurs. The market-based method incorporates our procurement choices, primarily our renewable energy purchases via contractual 
instruments, such as power purchase agreements (PPAs). 

We use actual data (such as third-party invoices, monthly utility bills, or meter readings) to calculate scope 2 emissions. Where actual data isn’t available, we 
estimate electricity consumption, natural gas consumption, and activity from district energy systems using the square footage of our data centers, offices, 
and other assets and internally developed intensity factors by office type, based on data from the reporting period. 

The emission factors used to calculate scope 2 (location-based) emissions include the 2024 WRI/WBCSD GHG Protocol Emission Factors from Cross Sector 
Tools, the 2025 EPA Emission Factors for Greenhouse Gas Inventories, the 2024 DEFRA UK Government GHG Conversion Factors, the 2024 International 
Energy Agency (IEA) Emission Factors, the 2025 EPA eGRID Emission Factors, and the 2024 Climate Registry Default Emission Factors. 

The emission factors used to calculate scope 2 (market-based) emissions are the same as scope 2 (location-based) with the addition of emission factors 
specific to energy attribute certificates (EACs), as well as residual mix emission factors where available. Residual grid mix removes the proportion of 
renewable energy contracted to other parties—that have the rights to claim those clean electricity attributes through EACs—from the grid electricity mix, 

98 



and therefore avoids double-counting. Comprehensive residual mix emission factors are currently only available for Europe (the 2023 Association of Issuing 
Bodies’ European Residual Mixes). Outside of Europe, residual emission factors aren’t available from third-party sources to account for voluntary purchases, 
and this may result in double counting between electricity consumers. 

Scope 3 emissions 
Scope 3 emissions are indirect emissions from other sources in our value chain. We calculate our scope 3 emissions using methodologies from the Scope 3 
Technical Guidance for the following categories identified as relevant: 

• Category 1: Purchased goods and services 
• Category 2: Capital goods 
• Category 3: Fuel- and energy-related activities (not included in scope 1 or scope 2) 
• Category 4: Upstream transportation and distribution 

• Category 5: Waste generated in operations 

• Category 6: Business travel 
• Category 7: Employee commuting 
• Category 11: Use of sold products 

We’ve determined that the remaining scope 3 categories were either not relevant or not applicable based on the Scope 3 Standard’s relevance criteria, 
which is described further in our 2025 (FY2024) Independent Accountants’ Review Report. The emissions associated with categories deemed not relevant 
are not significant to scope 3 emissions individually or in the aggregate. 

For each relevant scope 3 category, we report emissions according to their minimum boundaries listed by the Scope 3 Standard. For certain categories, 
we’ve also included activities which the Scope 3 Standard deems optional. None of the scope 3 categories have associated biogenic carbon dioxide 
emissions. 

In 2024, we stopped reporting a scope 3 (Other categories) metric—a previously aggregated total that included certain emissions from category 2 (Capital 
goods), category 11 (Use of sold products), and category 12 (End-of-life treatment of sold products). Instead, we now present all emissions from category 2 
(Capital goods) and category 11 (Use of sold products) as an aggregated total for business confidentiality purposes. The emissions from category 11 (Use of 
sold products) are not a material component of total scope 3 emissions. We’ve determined that category 12 (End-of-life treatment of sold products) is not 
relevant based on the relevance criteria in the Scope 3 Standard, and is therefore no longer included in our inventory boundary. 

For each relevant scope 3 category, we provide the following details, as applicable: the minimum and optional activities included, calculation methods, 
activity data, emission factors, percentage of category emissions from value chain partners, allocations, and any significant estimates or assumptions. 

“Category 1: Purchased goods and services” includes upstream emissions generated from manufacturing consumer devices and spare parts, our food 
program, and additional goods and services purchased for our operations. We use a combination of the average-data method and spend-based method, 
as defined by the Scope 3 Technical Guidance. To calculate supply chain emissions generated from manufacturing consumer devices and spare parts, we 
perform third-party-verified Life Cycle Assessments (LCAs) in accordance with International Organization for Standardization (ISO) 14040 and ISO 14044. 
To calculate emissions generated from our food program, we use LCA emission factors from WRI’s Cool Food Pledge Calculator and annual procurement 
volumes from our San Francisco Bay Area offices. Where procurement volume data isn’t available for the remaining offices, we estimate remaining 
emissions by scaling the San Francisco Bay Area emissions based on global building admittance data. Where emission factors from WRI aren’t available, we 
estimate remaining emissions using spend data and the EPA’s U.S. Environmentally-Extended Input-Output (“USEEIO”) Supply Chain GHG Emission Factors 
(2024 v1.3), which are then adjusted for inflation using the U.S. Bureau of Labor Statistics’ Consumer Price Index Inflation Calculator (“USEEIO supply chain 
emission factors”). To calculate emissions generated from the remaining goods and services purchased for our operations, we estimate supplier emissions 
using spend data and USEEIO supply chain emission factors. Approximately 2% of the data we use to calculate category 1 emissions are obtained from value 
chain partners. 

“Category 2: Capital goods” includes upstream emissions generated from final goods that are used in the manufacturing and assembly of servers and 
networking equipment used in our technical infrastructure, materials and fuels used in the construction of data centers and offices, and additional capital 
goods purchased for Alphabet’s operations. We use a combination of the average-data, and spend-based methods, as defined by the Scope 3 Technical 
Guidance, as well as LCAs that are in accordance with ISO 14040, ISO 14044, and ISO 14067. To calculate emissions generated from the manufacturing 
and assembly of servers and networking equipment used in our technical infrastructure, we transitioned in 2024 to primarily using LCAs as we continue 
to increase the accuracy of our estimates. This improved approach uses configurable LCA models (third-party reviewed) for high-impact components 
(which account for the majority of our total technical infrastructure hardware emissions). This allows us to tailor calculations to our specific mix of data 
center hardware and incorporate supplier-specific process-level data. For technical infrastructure components where LCA data is unavailable, we apply 
our previous spend-based method. For these remaining components, we collect supplier emissions data from our contract manufacturers as well as 
component and fabless suppliers through the CDP Supply Chain Program. Alphabet’s share of these suppliers’ emissions is determined via economic 
allocation (i.e., based on revenue and spend). Where available and valid, we use scope 2 market-based method emissions from these suppliers. Where 
supplier-specific emissions data isn’t available through CDP, we estimate supplier emissions using spend data, USEEIO supply chain emission factors 
or proxy supplier emissions data. To calculate emissions generated from materials used in data center and office construction, we use data on annual 
construction area and lifecycle emission factors derived from LCAs conducted on our data centers and offices, as well as invoice-based material 
information. We input building mass by material data—either collected or estimated based on actual data when unknown—into LCA software (Tally, One 
Click LCA, and SimaPro—which reference emission factors from ecoinvent and Sphera) and the Embodied Carbon in Construction Calculator (EC3) 
webtool. For offices, the LCA results undergo third-party review (e.g., by the U.S. Green Building Council for Leadership in Energy and Environmental Design 
[LEED] certification). To calculate emissions generated from additional capital goods purchased for our operations, we estimate supplier emissions using 
spend data and USEEIO supply chain emission factors. Approximately 15% of the data we use to calculate category 2 emissions are obtained from value 
chain partners. 

99 



“Category 3: Fuel- and energy-related activities (not included in scope 1 or scope 2)” includes upstream emissions from purchased fuels 
(e.g., natural gas, diesel, and gasoline) and purchased energy (i.e., electricity, steam, heating, and cooling), as well as emissions from transmission and 
distribution losses from purchased energy. We use the average-data method, as defined by the Scope 3 Technical Guidance. We calculate upstream 
emissions from purchased fuel, steam, heating, and cooling, in addition to emissions from transmission and distribution losses from steam, heating, and 
cooling using 2024 DEFRA UK Government GHG Conversion Factors. We calculate emissions from upstream electricity by country using the 2024 IEA 
Emission Factors. We calculate emissions from electricity transmission and distribution losses using grid loss values and emission factors derived from the 
2024 IEA Emission Factors and, for the United States, the 2025 EPA eGRID Emission Factors. For upstream electricity, we calculate emissions using scope 2 
market-based data (i.e., by using the remaining electricity not addressed by renewable energy). For electricity transmission and distribution losses, we use 
the market-based method to account for EACs that we’ve purchased to cover a portion of grid losses. 

“Category 4: Upstream transportation and distribution” includes emissions generated primarily from the transportation and warehousing of our 
consumer products and data center equipment. We also include the optional activities of upstream emissions of transportation. For transportation 
emissions, we use a combination of the fuel-based and distance-based methods, as defined by the Scope 3 Technical Guidance. For transportation 
emissions, we collect well-to-wheel (WTW) emissions data, calculated based on fuel use or weight-distance data, and routing associated with a shipment 
from logistics providers. Logistics providers determine Alphabet’s share of a shipment’s transportation emissions via physical allocation (i.e., based on how 
much of the total shipment’s weight is from Alphabet’s goods). Where actual logistics provider emissions data isn’t available, we calculate WTW emissions 
using weight and distance data by shipment collected from our logistics providers, using emission factors from the 2024 Global Logistics Emissions 
Council (GLEC) Framework v3.1 or EPA SmartWay carrier performance data. Where logistics provider weight and distance data isn’t available, we estimate 
emissions based on reported data from other transportation providers and the weight shipped. For warehousing emissions, we use the site-specific 
method, as defined by the Scope 3 Technical Guidance. To calculate consumer product and data center equipment warehousing emissions, we collect 
energy data (from both) and refrigerant leakage data (data center equipment warehousing only) directly from the warehouses and calculate emissions 
using lifecycle electricity and fuel emission factors from the Sphera Professional database 2024. Alphabet’s share of a third party’s warehouse energy and 
refrigerant leakage activity is determined via physical allocation (e.g., based on how much of the total warehouse area is used for Alphabet’s goods). Nearly 
100% of the data we use to calculate category 4 emissions are obtained from value chain partners. 

“Category 5: Waste generated in operations” includes emissions from solid waste generated at our offices, Google owned- and operated data centers, 
and Google-owned warehouses. The waste is either composted, recycled, landfilled, or incinerated (with or without energy recovery). We calculate this 
category’s emissions to also include the optional activity of waste transportation, which is embedded in the emission factors we use. We use a combination 
of the waste-type-specific method and the average-data method, as defined by the Scope 3 Technical Guidance. The waste generation data comes from 
a combination of data from invoices and on-site measurements. Where actual waste data isn’t available for a specific facility, we estimate waste tonnage 
using waste container size and pickup frequency, actual waste data from similar facilities, or historical waste data from the same facility. We use waste 
type- and disposal type-specific emission factors from the 2025 EPA Emission Factors for Greenhouse Gas Inventories. We exclude the emissions from 
wastewater treatment from this category. 

“Category 6: Business travel” includes emissions from business-related air, rail, bus, personal vehicle (when the employee’s car is used for business 
purposes), taxi, rideshare, shuttle, and rental car travel—including emissions from relocation travel. We also include the optional activity of upstream 
emissions from business travel. We use a combination of the distance-, fuel-, and spend-based calculation methods, as defined by the Scope 3 Technical 
Guidance. We collect all travel data through either our online booking system or a third-party travel agency. To calculate emissions from the majority of our 
air travel, we use the Travel Impact Model, an emissions estimation model developed by Google that’s built from public and licensable external datasets. 
We calculate total plane WTW emissions and allocate an amount to the employee passenger based on the plane’s percentage of occupied seats (i.e., the 
passenger load factor) and the mass of cargo being carried. For all other modes of transport—including rail, taxi, rideshare, non-U.S. personal vehicles, 
non-U.S. shuttle travel, and a minority of air travel modes—we use the WTW emission factors from the 2024 DEFRA UK Government GHG Conversion 
Factors. We calculate emissions from car rental, U.S. personal vehicle, and U.S. shuttle travel using well-to-tank (WTT) emission factors from the 2024 DEFRA 
UK Government GHG Conversion Factors and tank-to-wheel (TTW) emission factors from the 2025 EPA Emission Factors for Greenhouse Gas Inventories. 
Approximately 6% of the data we use to calculate Category 6 emissions are obtained from value chain partners. 

“Category 7: Employee commuting” includes emissions from the transport of our full-time employees between their homes and their worksites by 
passenger car (i.e., carpool, dropoff, taxi, rideshare, or single-occupied vehicle), rail, bus, motorcycle, and gas-powered scooter. We also include the 
optional activity of upstream emissions of employee commuting. We use the distance-based method, as defined by the Scope 3 Technical Guidance. We 
survey our employees to determine typical commuting patterns and apply these patterns to our global employee population. We use a mode-specific 
commuting distance obtained from the American Public Transportation Association’s 2023 Fact Book and the U.S. Department of Transportation’s 2022 
National Household Travel Survey. We calculate employee commuting emissions using mode-specific WTT emission factors from the 2024 DEFRA UK 
Government GHG Conversion Factors and TTW emission factors from the 2025 EPA Emission Factors for Greenhouse Gas Inventories. We use passenger 
distance-based emission factors for shared vehicles (i.e., carpool, taxi, rideshare, rail, bus) in order to allocate the total vehicle emissions to the employee 
passenger. In 2024, we removed home energy emissions generated by our full-time employees working remotely (i.e., teleworking) from our inventory 
boundary because this emissions activity is optional under the Scope 3 Standard and because it would’ve required separate tracking and reporting from 
our SBTi-validated carbon reduction ambition. 

“Category 11: Use of sold products” includes direct use-phase emissions generated by Google’s flagship consumer devices 143 sold in the reporting 
period that directly consume electricity during use. 144  These emissions also include the optional activity of upstream electricity emissions of these 
devices by using LCA emission factors. We perform LCAs that are in accordance with ISO 14040 and ISO 14044 and are third-party reviewed. We 
publish summaries of the LCA results in Product Environmental Reports on Google’s Sustainability Reports webpage. We use laboratory power draw 
measurements, data on use patterns, common industry assumptions on product lifetimes, and LCA electricity emission factors from the 2024 Sphera LCA 
for Experts database. 

Biogenic emissions 
In accordance with the Greenhouse Gas Protocol, we report biogenic emissions separately from other scope 1 emissions. Our biogenic carbon dioxide 
emissions are generated from our operated vehicles and generators that consume biofuels. We calculate biogenic emissions using emission factors from 
the 2025 EPA Emission Factors for Greenhouse Gas Inventories. 

100 



Other carbon and energy metrics 
Ambition-based emissions 
For our ambition-based emissions, we include all Alphabet scope 1 and scope 2 (marked-based) emissions. We exclude certain scope 3 activities 145 that 
are peripheral to our core operations or where our ability to influence emissions reductions is limited. These exclusions include food program purchases, 
certain purchased goods and services associated with Alphabet’s day-to-day operations, 146 and Other Bets 147 capital goods. For more details, refer to our 
Ambition-based emissions reconciliation presented in our Environmental metrics data table. 

Carbon intensity 
We calculate our carbon intensity metrics as defined by the Global Reporting Initiative (GRI) Disclosure 305-4. Carbon intensity metrics are based on 
global combined scope 1 and scope 2 (market-based) emissions. We round reported carbon intensity per unit of revenue and per full-time equivalent 
(FTE) employee values to the nearest hundredth, and reported carbon intensity per megawatt-hour (MWh) of energy consumed values to the nearest ten 
thousandth. 

Carbon removal credits 
In 2024, we did not apply any carbon removal credits to our emissions inventory. We plan to begin applying these credits in 2030. When we do, we’ll provide 
detailed information about our methodology. In the meantime, we’ve reported our total procurement to date for transparency. 

Energy and electricity 
We calculate total energy consumption as defined by GRI Disclosure 302-1e-f. Total energy consumption includes all fuel and natural gas consumption; 
purchased electricity, steam, heating, cooling; and all electricity generated on-site from carbon-free energy technologies. We round reported energy 
consumption metrics to the nearest hundred. 

We calculate total electricity consumption as defined by GRI Disclosure 302-1c(i) and 302-1f. Total electricity consumption includes both purchased and 
self-generated electricity. Where actual natural gas or electricity consumption for facilities isn’t available, we estimate consumption using building square 
footage and internally developed intensity factors based on data from the reporting period. Total electricity consumption differs slightly from purchased 
electricity, which is electricity sourced from an electrical grid and purchased from a local electric utility company. 

We calculate electricity procured from renewable sources (%) on an annual basis by dividing the megawatt-hours of renewable electricity procured 
(i.e., through contractual instruments, on-site renewable electricity generation, and renewable electricity in the electric grids where our facilities are 
located) by the total megawatt-hours of electricity consumed by our global operations. The numerator includes all renewable electricity procured, 
regardless of the market in which we consumed the renewable electricity. To achieve our 100% renewable energy match, we first consider both our on-site 
renewable electricity generation and the renewable electricity already in the electric grids where our facilities are located (using the residual mix where 
data is available). We then procure renewable electricity through contractual instruments. We have a few facilities located in geographies where we’re 
not currently able to source large volumes of renewable electricity, so we make up for this by procuring surplus renewable electricity in regions where it’s 
abundant. For example, by procuring larger amounts of wind energy in places like Europe, we compensate for our lack of renewable energy purchases in 
the Asia-Pacific region. Refer to “Achieving Our 100% Renewable Energy Purchasing Goal and Going Beyond” for additional details on our custom criteria 
and methodology. 

Carbon-free energy 
Google’s Carbon-free energy (CFE) metric is the percentage of Google’s electricity consumption on a given regional grid that is matched hourly with CFE. 
We calculate this metric at an hourly granularity, using both CFE under contract by Google (Contracted CFE) as well as CFE from the electricity grid (Grid 
CFE). Grid CFE is defined as the percentage of energy on the grid that’s supplied by carbon-free energy sources (e.g., wind or solar) at that particular 
hour. Grid CFE is applied to Google’s electricity consumption for any hour where Google’s Contracted CFE is less than the electricity consumption. Grid 
CFE values are calculated by a third party, Electricity Maps. 

Regional average Google CFE across Google data center grid regions refers to the percentage of carbon-free energy sources consumed by 
Google’s data centers within a given global region per the previously-defined methodology. 

• The eastern North America regional CFE percentage includes the following grid regions: Duke Energy Carolinas (DUKE), Independent 
Electricity System Operator (IESO), Hydro-Québec, Pennsylvania-New Jersey-Maryland Interconnection (PJM), South Carolina Regional Grid 
(SC), Southern Company (SOCO), and Tennessee Valley Authority (TVA). 

• The central North America regional CFE percentage includes the following grid regions: Electric Reliability Council of Texas (ERCOT), 
Midcontinent Independent System Operator (MISO), Southwest Power Pool (SPP), and Sistema Eléctrico Nacional (SEN). 

• The western North America regional CFE percentage includes the following grid regions: Salt River Project (SRP), Bonneville Power 
Administration (BPA), California Independent System Operator (CAISO), NV Energy (NVE), and PacifiCorp East (PACE). 

We calculate Contracted CFE as a percentage of our electricity consumption that’s matched with CFE on an hourly basis from clean energy projects 
contracted by Google, and without consideration of the CFE already on the grids where we operate. If Google’s total Contracted CFE exceeds our 
electricity consumption in a given hour and region, the contracted CFE consumed by Google is capped at the total electricity consumption; this means 
the CFE percentage in this hour would be 100% and that “consumed” Contracted CFE can never exceed 100%. The “excess CFE” from the projects under 
contract that generate MWhs of clean electricity above what Google consumes in a particular hour is not counted toward our Google CFE percentage, 
however it still contributes to decarbonization of the broader grid. 

We calculate Consumed Grid CFE as a percentage of our electricity consumption in a given market that’s matched with CFE from the grid after the 
application of Contracted CFE. For hours when Contracted CFE is equal to or exceeds our electricity consumption, Consumed Grid CFE is equal to zero. 
If our Contracted CFE is less than our electricity consumption in an hour, then the Consumed Grid CFE is calculated by applying the hourly Grid CFE 
percentage to the remaining electricity consumption, and then dividing that product by the total electricity consumption in that hour. 

For more details on how we calculate carbon-free energy percentages, refer to 24/7 Carbon-Free Energy: Methodologies and Metrics. Our approach to 
CFE measurement may evolve as we continue to enhance our methodology and data availability improves. For example, we don’t currently use residual grid 

101 



mix when calculating grid contributions to Google CFE because hourly residual grid mix data doesn’t yet exist. We’re supporting the development of time-
based tracking methods, which are essential for making this calculation possible in the future. 

Power Usage Effectiveness 
PUE is a standard industry ratio that compares the amount of non-computing overhead energy (used for things like cooling and power distribution) to the 
amount of energy used to power IT equipment. A PUE of 2.0 means that for every watt of IT power, an additional watt is consumed to cool and distribute 
power to the IT equipment. A PUE closer to 1.0 means nearly all the energy is used for computing. 

We take a comprehensive approach to measuring our data center PUE: 

• Include all data centers: We consider our entire global fleet, not just the newest or most efficient facilities. 
• Continuous measurement: We measure PUE throughout the year, not just during cooler seasons. 
• Comprehensive data: We include all sources of overhead energy in our calculations. 

We begin reporting PUE for each data center once it reaches stable operations. This fleet-wide data, along with quarterly and trailing 12-month PUE, is 
publicly disclosed on our Data Centers: Efficiency site on a quarterly basis. 

Water metrics 
Global operational water 
Relevant operations for water metrics include our owned and fully leased data centers and owned and leased offices and other assets. Our reported water 
metrics exclude seawater. We report water metrics in million gallons, and we round global operational water metrics to the nearest million and water use 
by data center location to the nearest hundred thousand gallons. If water use by data center location is less than fifty thousand gallons, we round to the 
nearest ten thousand gallons. 

We calculate water consumption by subtracting water discharge from water withdrawal. 

Water withdrawal is based on actual metered or invoiced data when it’s available. At offices where actual metered or invoiced data isn’t available, we 
estimate water withdrawal using facility square footage and internally developed water withdrawal intensity factors by office type based on data from the 
reporting period. At data centers where actual data isn’t available, we estimate water withdrawal using engineering principles. 

Water discharge is based on actual metered or invoiced data when it’s available. Where actual domestic wastewater discharge data isn’t available, we 
apply an industry-standard 90% discharge flow factor to a facility’s domestic water withdrawal to estimate domestic water discharge and a 0% discharge 
flow factor to a facility’s irrigation water withdrawal to estimate irrigation water discharge. We apply this water discharge estimation methodology at 
all offices and at data centers where metered water discharge data isn’t available. At data centers where actual data isn’t available, we estimate water 
discharge using engineering principles. 

Water replenishment 
Our water replenishment metrics are based on the volumetric water benefits from water stewardship projects in our water replenishment portfolio. We 
engage our independent third-party volumetric benefit quantification partner LimnoTech, which applies industry standard methodologies and assumptions 
to calculate two metrics following the Volumetric Water Benefit Accounting (VWBA) methodology. We calculate water replenished by estimating the 
total volumetric water benefits of our current water replenishment portfolio during the year. We calculate contracted water replenishment capacity 
by estimating the annual expected volumetric water benefits of our water replenishment project portfolio throughout each project’s implementation and 
respective duration. 

Once projects are funded and completed, volumetric water benefits are first accounted for in the year the project begins delivering them and in 
subsequent years—provided there’s reasonable evidence that the project is maintained and continues to function as intended, which is confirmed via an 
annual review. If a project has multiple funders, the volumetric water benefit is adjusted to reflect our proportional financial contribution compared to the 
total project cost. The specific calculations applied to each project depend on the project’s objectives, activities implemented, and available information. 

Water scarcity 
To define water scarcity levels, Google assesses operational water risks for data centers and offices. For data centers, we assess water scarcity and 
depletion by applying our Data Center Water Risk Framework, and assign a low, medium, or high water scarcity level. For our office operations, we assess 
water scarcity using the WRI Aqueduct Water Risk Atlas and the WWF Water Risk Filter, and where appropriate we adjust the assigned level of water scarcity 
based on local context. 

Waste metrics 
We report all waste metrics for Alphabet Inc. and its subsidiaries’ data centers (that are owned and operated), offices, and other assets under our 
operational control. 

We calculate waste generated by quantifying solid waste generated that’s either composted, recycled, landfilled, or incinerated (with or without energy 
recovery). The waste generation data comes from a combination of data from invoices and on-site measurements. Where actual waste data isn’t available 
for a specific facility, we estimate waste tonnage using waste container size and pickup frequency, actual waste data from similar facilities, or historical 
waste data from the same facility. We round reported waste generation metrics to the nearest hundred. 

We calculate waste diversion by quantifying the percentage of total waste generated that is diverted from disposal (defined as diversion of waste from 
landfills or incinerators, with or without energy recovery). Our approach to data center waste accounting tracks operational waste and integrates data 
sources and assumptions to account for parts and materials that enter our reverse supply chain—inclusive of decommissioned data center hardware, 
racking infrastructure, and packaging waste. We also classify waste that’s thermally processed (i.e., incinerated) when it leaves our data centers as 

102 



disposed, rather than diverted—even when energy is recovered. For office waste, we actively assess contamination rates and exclude contaminated waste 
from our diversion rate calculations—which is unlike the typical approach, which assumes zero contamination in recycling and compost bins. We round 
reported waste diversion metrics to the nearest one percent. 

Recalculation of previous environmental metrics 
To maintain consistency over time so that meaningful metric comparisons can be made, it may be necessary to recalculate our historical metrics, including 
base year emissions, to the extent a change is significant. 

Our internal recalculation policy, which follows guidance from the Greenhouse Gas Protocol, informs how we apply updates made in the current reporting 
period to metrics from prior reporting periods—including our 2019 base year for our emissions reduction ambition. Updates may include structural 
changes, changes in calculation methodologies, improvements in data accuracy, changes in the categories or activities included in the scope 3 inventory, 
and the correction of errors. We continually review emissions calculation methodologies and are committed to implementing best practices. 

In line with our recalculation policy, in 2024 we recalculated the following previously-reported metrics, due to the following primary drivers: 

• We recalculated 2019–2023 scope 3 emissions metrics—including all reported scope 3 categories, “scope 3 (total),” and “total emissions: 
scope 1, 2 (market-based), and 3”—due to the following: 
• For emissions associated with manufacturing equipment used in our technical infrastructure, we transitioned from a spend-based to 

a primarily LCA-based calculation methodology, and we improved the spend data accuracy for our remaining spend-based emissions 
calculations associated with manufacturing equipment used in our technical infrastructure. 

• For emissions associated with data center construction, we updated the LCA we use, sourced more accurate construction area data, and 
began calculating emissions from additional construction activities. 

• For emissions associated with additional capital goods purchased for Alphabet’s operations for which we use a spend-based approach, 
we improved our approach to mapping USEEIO supply chain emission factors to spend items, and we incorporated capital goods spend 
related to construction and hardware not otherwise captured by our LCA-based emissions calculations associated with capital goods 
purchased for Alphabet’s operations. 

• We recalculated 2020 energy consumption metrics—including purchased steam, purchased cooling, and total energy consumption—due to 
the correction of a calculation error. 

• We recalculated our 2020 “Total electricity consumption” metric to source more accurate energy data. 
• We recalculated our 2021 “CFE across Google data centers (hourly)” metric to include CFE data from third-party data center consumption. 

CFE data from third-party data centers was already included in our previously reported 2022 and 2023 metrics. 
• We recalculated 2019–2023 waste metrics—including data center waste diversion rate, total waste generated, and total waste diversion rate— 

due to data improvements for data center recycled e-waste and packaging and refinement of the metric boundary to exclude low quality data 
from warehouses and third-party data centers. 

Definition of key terms 
• Business-as-usual (BAU) emissions represent our projected emissions without new carbon reduction efforts. Our BAU emissions forecast 

shows how much carbon we need to reduce to reach our 2030 ambitions given our company growth projections. As a result, it serves as the 
baseline by which we calculate the impact of our carbon reduction initiatives. 

• Carbon-free energy (CFE) technologies include types of electricity generation that don’t directly emit carbon dioxide, including solar, 
wind, geothermal, hydropower, and nuclear. In addition, when deployed with the appropriate guardrails, low-carbon technologies including 
sustainable biomass and carbon capture and storage can contribute to a CFE portfolio. Energy storage systems can contribute as well. For 
more details, refer to The Corporate Role in Accelerating Advanced Clean Electricity Technologies. 

• Energy Attribute Certificates (EACs) are tradable instruments issued to a unit of generation (generally, one MWh) which are used to 
aggregate and track energy attributes. Depending on the system that issues them and the market where they are used, corporate buyers may 
purchase them bundled with or unbundled from the underlying generation to secure the property rights to energy attributes. EACs are often 
interchangeably referred to as Renewable Energy Certificates (RECs). 

• We define freshwater as naturally occurring water from surface or groundwater sources that isn’t salty, and is suitable for consumption if 
clean or processed. Freshwater excludes seawater and reclaimed wastewater. 

• A grid region (or regional grid) corresponds to the area over which a single entity manages the operation of the electric power system and 
ensures that demand and supply are finely balanced. In the United States, this generally means the Independent System Operator (ISO) or 
Regional Transmission Organizations (RTOs) in regions that have these regional market structures. If no such structure exists, then Google 
defines the grid region as the electricity-balancing authority where our data centers are located. Outside of the United States, the grid region 
most often refers to the geographic boundary of a country, because most grid system operators operate at the national level. Certain regions 
that span multiple countries are well interconnected and could be considered as one grid. However, our grid mix calculations already include 
import and export considerations and therefore take into account power flows from neighboring grids. In the future, we may update our 
definition as we work with grid operators to better understand how transmission constraints or congestion impact CFE measurement within 
and across grid regions. 

• Time-based energy attribute certificates (T-EACs)—commonly referred to as “Granular Certificates” (GCs)—are a type of Energy 
Attribute Certificate (EAC) that track and verify clean energy production on an hourly basis, and may be used to buy and sell energy attributes 
on an hourly basis. Traditional EACs typically certify energy production monthly or annually. 

103 



Data measurement and uncertainty 
All reported values represent the best data available at the time of publication. Where actual data isn’t available, we may use estimates. We base our 
estimates and methodologies on historical experience, available information, and on various other assumptions that we believe to be reasonable. 

All environmental data found in this report is subject to measurement uncertainties resulting from limitations inherent in the nature, methods, and 
standards used for determining such data. The methodologies and standards for tracking, calculating, and reporting environmental matters—including 
emissions, emissions reductions, offsets, and related issues—continue to evolve. The selection of different but acceptable measurement techniques can 
result in materially different measurements. The precision of different measurement techniques may also vary. 

Forward-looking information 
References to information in this report should not be construed as a characterization regarding the materiality of such information to our financial results 
or our operations. While certain matters discussed in this report may be significant, any significance should not be read as necessarily rising to the level of 
materiality used for the purposes of complying with applicable securities laws and regulations in the United States or any other jurisdiction. The information 
in this report may contain projections, future estimates, plans, expectations, ambitions, and other forward-looking statements. Forward-looking statements 
are based on current expectations and assumptions and may also be based on estimates and assumptions under developing standards that may change in 
the future. Such statements are subject to certain risks and uncertainties, which could cause our actual results to differ materially from those reflected in 
the forward-looking statements. Our ability to achieve any ambition, target, or objective outlined in this report—whether through our products, projects, 
or funding efforts—is subject to numerous risks, many of which are outside of our control, such as the adoption of certain behaviors and activities by third 
parties, including our customers and partners. Performance data are not a guarantee of future performance nor intended to be a demonstration of linear 
progress against aspirations, targets, or objectives. There can be no guarantee that our products, projects, or funding efforts will have the effects we 
anticipate or intend. Any changes in methodology may result in material changes to our calculations and may result in the current and previous periods, 
including our base year, to be adjusted. This report represents our current policy and intent and is not intended to create legal rights or obligations. Except 
as required by law, we undertake no obligation to correct, revise, or update any information included in this report. Neither future distribution of this 
material nor the continued availability of this material in archive form on our website should be deemed to constitute an update or re-affirmation of these 
figures or statements as of any future date. Any future update will be provided only through a public disclosure indicating that fact. 

104 



Environmental metrics data tables 
Greenhouse gas emissions 

Greenhouse gas emissions inventory Unit 2019 2020 2021 2022 2023 2024 

Scope 1 tCO2e 81,900 55,800 64,100 91,200 79,400 73,100 

Scope 2 

Scope 2 (location-based) tCO2e 5,116,900 5,865,100 6,576,200 8,045,400 9,252,900 11,283,200 

Scope 2 (market-based) tCO2e 835,900 911,600 1,823,500 2,492,100 3,423,400 3,059,100 

Total operational (scope 1 +  
tCO e 917,800 967,400 1,887,600 2,583,300 3,502,800 3,132,200 

market-based scope 2) emissions 2

Scope 3 

Scope 3 (Category 1: Purchased goods and services) tCO2e 2,787,000 2,404,000 2,886,000 3,504,000 3,951,000 3,601,000 

Scope 3 (Category 2: Capital goods) and  
tCO 4,584,000 4,176,000 4,462,000 3,886,000 4,583,000 6,337,000 

(Category 11: Use of sold products) 148 2e 

Scope 3 (Category 3: Fuel- and energy-related activities  
tCO e 425,000 512,000 753,000 1,004,000 1,295,000 714,000 

[not included in scope 1 or scope 2]) 2

Scope 3 (Category 4: Upstream transportation and distribution) tCO2e 476,000 440,000 460,000 533,000 570,000 853,000 

Scope 3 (Category 5: Waste generated in operations) tCO2e 14,000 7,000 7,000 7,000 8,000 12,000 

Scope 3 (Category 6: Business travel) tCO2e 461,000 179,000 36,000 268,000 291,000 399,000 

Scope 3 (Category 7: Employee commuting) tCO2e 203,000 52,000 29,000 115,000 96,000 137,000 

Scope 3 (total) tCO2e 8,950,000 7,770,000 8,633,000 9,317,000 10,794,000 12,053,000 

Total emissions: Scope 1, 2 (market-based), and 3 (total) tCO2e 9,867,800 8,737,400 10,520,600 11,900,300 14,296,800 15,185,200 

Biogenic emissions tCO2e 21,900 5,400 3,800 17,900 18,700 17,200 

Note: In 2024, we recalculated certain previously reported GHG emissions metrics in accordance with our internal recalculation policy for improved accuracy. For more details, refer to the 
Recalculation of previous environmental metrics section. 

Ambition-based emissions reconciliation Unit 2019 2020 2021 2022 2023 2024 

Total emissions: Scope 1, 2 (market-based), and 3 (total) tCO2e 9,867,800 8,737,400 10,520,600 11,900,300 14,296,800 15,185,200 

Scope 3 exclusions, per SBTi ambition 149 

Category 1: Purchased goods and services exclusions tCO2e 1,914,000 1,722,000 2,036,000 2,388,000 3,171,000 2,862,000 

Category 2: Capital goods exclusions tCO2e 292,000 333,000 418,000 518,000 750,000 776,000 

Total excluded scope 3 emissions tCO2e 2,206,000 2,055,000 2,454,000 2,906,000 3,921,000 3,638,000 

Total ambition-based emissions tCO2e 7,661,800 6,682,400 8,066,600 8,994,300 10,375,800 11,547,200 

Legend Subject to third-party limited assurance procedures. For more details, refer to our 2025 (FY2024) Independent Accountants’ Review Report. 

105 



Carbon intensity Unit 2020 2021 2022 2023 2024 

Carbon intensity per unit of revenue tCO2e/million USD ($) 5.30 7.33 9.13 11.40 8.95 

Carbon intensity per full-time employee (FTE) equivalent tCO2e/FTE 7.62 13.00 14.76 19.02 17.33 

Carbon intensity per megawatt-hour of energy consumed tCO2e/MWh 0.0624 0.1012 0.1155 0.1352 0.0957 

2024 2024 

GHG Scope 2 Scope 2 GHG Scope 2 Scope 2 
emissions Unit Scope 1 (market- (location- emissions Unit Scope 1 (market- (location-
by type based) based) by region based) based) 

CO2 tCO2e 50,700 3,027,400 11,207,600 North 
tCO2e 53,600 1,161,200 8,293,200 

America 
CH4 tCO2e 100 4,200 22,300 

Europe, 
N2O tCO2e 200 8,500 34,300 

Middle 
tCO

19,000 19,000 East, & 2e 8,800 82,700 1,033,800 
HFCs tCO2e 22,100 

Africa 
Total tCO2e 73,100 3,059,100 11,283,200 

Latin 
tCO2e 1,900 13,900 147,100 

CO 027,400 11,207,600 America 
2 tCO2 50,700 3,

CH 1,300 1,809,100 
4 tCH4 5 100 800 Asia Pacific tCO2e 8,800 1,80

N2O tN2O 1 32 100 Global 
tCO2e 73,100 3,059,100 11,283,200 

HFCs tHFCs 14 13 13 total 

Carbon removal credits 150 

Estimated Expected 
Project  Year deal  Market 

Project type Company contracted timeframe  Credit type 
location was signed commitment 

credits (tCO2e) for delivery 

Varaha 100,000 India 2024 2026–2030 Removal Bilateral 

Charm Industrial 100,000 United States 2024 2026–2030 Removal Bilateral 

CO280 61,226 United States 2024 2028–2030 Removal Frontier 
Biomass carbon removal  

Stockholm Exergi 41,636 Sweden 2024 2028–2030 Removal Frontier 
and storage (BiCRS) 

Charm Industrial 22,635 United States 2023 2025–2030 Removal Frontier 

Vaulted Deep 18,786 United States 2024 2024–2027 Removal Frontier 

NULIFE 78 Canada 2024 2025 Removal Frontier 

Holocene 100,000 United States 2024 Early 2030’s Removal Bilateral 
Direct air capture (DAC) 

280 Earth 13,301 United States 2024 2026–2030 Removal Frontier 

Terradot 200,000 Brazil 2024 2029–2030 Removal Bilateral 

Lithos Carbon 31,514 United States 2023 2025–2029 Removal Frontier 

Terradot 17,324 Brazil 2024 2025–2029 Removal Frontier 

Enhanced rock weathering (ERW) CREW 12,851 United States 2024 2025–2030 Removal Frontier 

Alt Carbon 185 India 2024 2028 Removal Frontier 

Flux 114 Kenya 2024 2026 Removal Frontier 

Silica 127 Mexico 2024 2030 Removal Frontier 

Mombak 50,000 Brazil 2024 2029–2030 Removal Bilateral 
Restoring natural carbon sinks 

CarbonRun 12,695 Canada 2024 2025–2029 Removal Frontier 

Total 782,472 

Legend Subject to third-party limited assurance procedures. For more details, refer to our 2025 (FY2024) Independent Accountants’ Review Report. 

106 



Energy 

Energy consumption by source type Unit 2020 2021 2022 2023 2024 

Fuel MWh 181,800 205,200 374,800 301,200 289,700 

Purchased electricity 151 MWh 15,125,700 18,238,400 21,685,300 25,252,600 32,106,200 

Purchased heat 152 MWh 124,900 119,300 219,100 278,500 237,500 

Purchased steam MWh 22,100 22,600 23,500 14,500 17,100 

Purchased cooling MWh 38,400 45,600 54,800 53,000 56,800 

On-site renewable electricity MWh 7,200 8,800 9,600 10,700 20,500 

Total energy consumption MWh 15,500,100 18,639,900 22,367,100 25,910,500 32,727,800 

2024 

Energy consumption by source type Unit Renewable sources Non-renewable sources Total 

Fuel MWh 63,200 226,500 289,700 

Purchased electricity 153 MWh 23,995,800 8,110,400 32,106,200 

Purchased heat 154 MWh 0 237,500 237,500 

Purchased steam MWh 0 17,100 17,100 

Purchased cooling MWh 0 56,800 56,800 

On-site renewable electricity MWh 20,500 0 20,500 

Total energy consumption MWh 24,079,500 8,648,300 32,727,800 

Electricity consumption Unit 2020 2021 2022 2023 2024 

Data centers MWh 14,426,600 17,659,000 20,806,200 24,294,900 30,825,600 

Office and other facilities MWh 740,200 628,100 970,000 1,012,100 1,354,300 

Total electricity consumption 155 MWh 15,166,800 18,287,100 21,776,200 25,307,000 32,179,900 

Renewable energy consumption Unit 2020 2021 2022 2023 2024 

Renewable electricity procured  
MWh 12,069,200 14,109,400 16,693,600 19,089,200 24,504,500 

(PPAs and other renewable energy agreements) 

Renewable electricity procured (on-site) MWh 7,200 8,800 9,600 10,700 20,500 

Renewable electricity (grid) MWh 3,062,100 4,168,900 5,073,000 6,207,100 7,654,900 

Total electricity procured from renewable 
MWh 15,138,500 18,287,100 21,776,200 25,307,000 32,179,900 

sources 

Global renewable energy 
Unit 2020 2021 2022 2023 2024 2024 

match 

Electricity procured from Electricity and 
% 100 100 100 100 100 Total renewable 

renewable sources renewable Total  
Unit electricity 

electricity allocated electricity 156 
allocated 157  

by region 
Global average carbon-

Unit 2020 2021 2022 2023 2024 
free energy (CFE) North America MWh 23,233,300 18,747,600 

CFE across Google data Europe, Middle East, 
% 67 65 64 64 66 MWh 4,951,900 4,822,000 

centers (hourly) & Africa 

CFE across Google Latin America MWh 500,400 411,900 
% - - 54 56 60 

offices (hourly) 
Asia Pacific MWh 3,494,300 14,300 

CFE across Google data 
centers and offices % - - 64 64 66 Global total MWh 32,179,900 23,995,800 

(hourly) 

Note: In 2024, we recalculated certain previously reported energy consumption and global average carbon-free energy metrics in accordance with our internal recalculation policy for improved 
accuracy. For more details, refer to the Recalculation of previous environmental metrics section. 

Legend Subject to third-party limited assurance procedures. For more details, refer to our 2025 (FY2024) Independent Accountants’ Review Report. 

107 



Regional average Google CFE across Google data center grid regions Unit 2022 2023 2024 

North America % 69 68 70 

United States % 69 68 70 

Canada & Mexico 158 % 96 96 88 

Europe, Middle East, & Africa % 76 83 83 

Europe % 76 84 84 

Middle East & Africa % 3 4 5 

Latin America % 90 91 92 

Asia Pacific % 11 12 12 

Global CFE across Google data centers % 64 64 66 

Data center grid region CFE 159  2024 

Consumed 
Country Regional grid Unit Google CFE Contracted CFE Grid CFE 

Grid CFE 

Europe, Middle East, & Africa 

Belgium Elia % 84 32 52 78 

Denmark Energinet % 91 35 56 88 

Finland Fingrid % 98 73 25 94 

Germany Germany % 68 8 60 66 

Ireland EirGrid % 47 5 42 44 

Netherlands Tennet % 83 70 13 56 

Asia Pacific 

Japan TEPCO Power Grid (TEPCO) % 17 0 17 17 

Singapore Energy Market Authority of Singapore % 4 0 4 4 

Taiwan Taiwan Power Company % 17 1 16 16 

Latin America 

Chile Sistema Interconectado Central % 92 79 13 67

North America 

United States Bonneville Power Administration (BPA) % 87 0 87 87 

United States Duke Energy Carolinas (DUKE) % 65 18 47 58 

United States Electric Reliability Council of Texas (ERCOT) % 94 91 3 44 

United States Midcontinent Independent System Operator (MISO) % 87 82 5 36 

United States NV Energy (NVE) % 64 55 9 30 

Pennsylvania-New Jersey-Maryland 
United States % 62 36 26 41 

Interconnection (PJM) 

United States South Carolina Regional Grid (SC) % 31 9 22 25 

United States Southern Company (SOCO) % 42 13 29 34 

United States Southwest Power Pool (SPP) % 88 83 5 48 

United States Tennessee Valley Authority (TVA) % 63 26 37 50 

108 



Data center energy efficiency (PUE) 160 

Country Location Unit 2020 2021 2022 2023 2024 

Belgium St. Ghislain PUE 1.08 1.08 1.09 1.09 1.08 

Chile Quilicura PUE 1.08 1.09 1.09 1.09 1.09 

Denmark Fredericia PUE - - 1.12 1.10 1.07 

Finland Hamina PUE 1.09 1.09 1.09 1.09 1.10 

Ireland Dublin PUE 1.09 1.09 1.09 1.08 1.08 

Netherlands Eemshaven PUE 1.09 1.08 1.07 1.08 1.08 

Singapore 1st facility PUE 1.14 1.13 1.13 1.13 1.13 

Singapore 2nd facility PUE - - 1.21 1.19 1.15 

Taiwan Changhua County PUE 1.13 1.12 1.12 1.12 1.13 

United States Berkeley County, South Carolina PUE 1.11 1.10 1.10 1.10 1.10 

United States Columbus, Ohio PUE - - - - 1.06 

United States Council Bluffs, Iowa (1st facility) PUE 1.11 1.12 1.12 1.11 1.11 

United States Council Bluffs, Iowa (2nd facility) PUE 1.09 1.09 1.08 1.08 1.07 

United States The Dalles, Oregon (1st facility) PUE 1.10 1.11 1.10 1.10 1.10 

United States The Dalles, Oregon (2nd facility) PUE 1.07 1.06 1.07 1.07 1.06 

United States Douglas County, Georgia PUE 1.10 1.09 1.09 1.09 1.09 

United States Henderson, Nevada PUE - - 1.11 1.08 1.09 

United States Jackson County, Alabama PUE - 1.13 1.12 1.10 1.10 

United States Lenoir, North Carolina PUE 1.09 1.09 1.09 1.09 1.13 

United States Loudoun County, Virginia (1st facility) PUE - 1.10 1.09 1.08 1.09 

United States Loudoun County, Virginia (2nd facility) PUE - 1.13 1.09 1.08 1.08 

United States Mayes County, Oklahoma PUE 1.12 1.10 1.10 1.10 1.11 

United States Midlothian, Texas PUE - - 1.16 1.13 1.10 

United States Montgomery County, Tennessee PUE - 1.10 1.11 1.10 1.10 

United States New Albany, Ohio PUE - - 1.14 1.10 1.07 

United States Papillion, Nebraska PUE - - 1.13 1.09 1.09 

United States Storey County, Nevada PUE - - - 1.19 1.16 

Average annual fleet-wide PUE across  
PUE 1.10 1.10 1.10 1.10 1.09 

Google-owned and -operated data center campuses 

Waste 

Waste generation Unit 2020 2021 2022 2023 2024 

Waste diverted Metric tons 18,000 34,500 27,800 35,100 39,100 

Waste disposed Metric tons 3,700 6,800 6,000 5,900 7,400 
Data centers 

Subtotal waste generated Metric tons 21,700 41,300 33,800 41,000 46,500 

Waste diversion rate % 83 83 82 85 84 

Waste diverted Metric tons 6,900 1,200 4,900 8,600 10,100 

Waste disposed Metric tons 2,900 700 1,600 2,600 1,900 
Offices 161 

Subtotal waste generated Metric tons 9,800 1,900 6,500 11,200 12,000 

Waste diversion rate % 71 64 75 77 84 

Waste diverted Metric tons 24,900 35,700 32,700 43,700 49,200 

Waste disposed Metric tons 6,600 7,500 7,600 8,500 9,300 
Total 

Total waste generated Metric tons 31,500 43,200 40,300 52,200 58,500 

Total waste diversion rate % 79 83 81 84 84 

Note: In 2024, we recalculated certain previously reported waste metrics in accordance with our internal recalculation policy for improved accuracy. For more details, refer to the Recalculation of 
previous environmental metrics section. 

Data center hardware circularity Unit 2020 2021 2022 2023 2024 

Reused inventory used for Google-managed server builds, maintenance, and upgrades 162 % 10 13 21 29 44 

Components resold into the secondary market Million components 8.2 4.9 5.0 7.0 6.7 

109 



Water 

Global 2024 
operational Unit 2020 2021 2022 2023 2024 
water use Water use by 

Water Water  Water 
data centers Unit 

withdrawal discharge consumption 
Million and offices 

Water withdrawal 5,689 6,297 7,600 8,653 11,011 
gallons Million 

Data centers 9,866 2,079 7,787 
gallons 

Million 
Water discharge 1,940 1,735 2,035 2,301 2,876 

gallons Offices and Million 
1,145 797 348 

other facilities gallons 

Water Million 
3,749 4,562 5,565 6,352 8,135 Million 

consumption gallons Total 11,011 2,876 8,135 
gallons 

Freshwater withdrawal from sources  
 163 Unit 2024 Freshwater replenishment Unit 2022 2023 2024 

at risk of water depletion or scarcity
Freshwater consumption Million gallons 4,770 5,601 7,210 

Low risk of water depletion or scarcity % 72 
Water replenished Million gallons 271 1,036 4,590 

Medium risk of water depletion or scarcity % 14 
Water replenished % 6 18 64 

High risk of water depletion or scarcity % 14 
Contracted water 

Million gallons 1,317 2,815 8,268 
replenishment capacity 

Water use by data center location 2024 Golf course 
equivalents 

Location Unit Withdrawal 164 Discharge Consumption (estimated) 165

Ashburn, VA Million gallons 59.5 3.5 56.0 <1 

Berkeley County, SC Million gallons 853.8 77.3 776.5 5.2 

Bristow, VA Million gallons 105.7 21.3 84.4 <1 

Council Bluffs, IA Million gallons 1,410.3 400.1 1,010.2 6.7 

The Dalles, OR Million gallons 461.1 99.7 361.4 2.4 
Douglas County, GA Million gallons 444.1 77.2 366.9 2.4 

Potable water 7.4    
Reclaimed wastewater 436.7 

Dublin, Ireland 166 Million gallons 0.9 0.8 0.1 <1 
Eemshaven, Netherlands Million gallons 416.9 86.9 330.0 2.2 

Potable water 2.9    
Non-potable water 167  414.0 

Frankfurt, Germany Million gallons 2.3 1.8 0.5 <1 

Fredericia, Denmark Million gallons 48.4 10.6 37.8 <1 

Hamina, Finland Million gallons 3.0 2.7 0.3 <1 

Hanau, Germany Million gallons 1.2 0.6 0.6 <1 

Henderson, NV Million gallons 359.9 152.5 207.4 1.4 

Inzai, Japan Million gallons 26.0 7.8 18.2 <1 

Jackson County, AL Million gallons 201.6 18.8 182.8 1.2 

Lancaster, OH Million gallons 207.4 106.3 101.1 <1 

Leesburg, VA Million gallons 246.7 55.1 191.6 1.3 

Lenoir, NC Million gallons 351.7 23.9 327.8 2.2 

Lockbourne, OH Million gallons 177.3 34.0 143.3 <1 

Mayes County, OK Million gallons 1,108.3 275.1 833.2 5.6 

Middenmeer, Netherlands Million gallons 9.3 2.8 6.5 <1 

Midlothian, TX Million gallons 221.0 38.7 182.3 1.2 

Montgomery County, TN Million gallons 387.9 66.1 321.8 2.1 

Montreal, Canada 168 Million gallons 0.6 0.5 0.1 <1 

New Albany, OH Million gallons 405.3 52.6 352.7 2.4 

Legend Subject to third-party limited assurance procedures. For more details, refer to our 2025 (FY2024) Independent Accountants’ Review Report. 

110 



Water use by data center location 2024 Golf course 
equivalents 

Location Unit Withdrawal 169 Discharge Consumption (estimated) 170 

Omaha, NE Million gallons 44.3 12.2 32.1 <1 

Papillion, NE Million gallons 532.3 115.4 416.9 2.8 

Pflugerville, TX 171 Million gallons 0.1 0.1 0.01 <1 

Phoenix, AZ 172 Million gallons 0.2 0.2 0.03 <1 

Quilicura, Chile Million gallons 219.0 97.2 121.8 <1 

San Bernardo, Chile 173 Million gallons 0.3 0.3 0.03 <1 
St. Ghislain, Belgium Million gallons 511.7 118.4 393.3 2.6 

Potable water 13.7    
Non-potable water 174 498.0 

Sterling, VA Million gallons 201.2 43.0 158.2 1.1 

Storey County, NV 175 Million gallons 14.9 13.4 1.5 <1 

Sydney, Australia 176 Million gallons 1.0 0.9 0.1 <1 

Wilmer, TX 177 Million gallons 1.9 1.7 0.2 <1 
Other data center locations Million gallons 828.9 60.0 768.9 5.1 

Potable water 10.7    
Non-potable water 377.9     
Reclaimed wastewater 440.3 

Data centers total Million gallons 9,866 2,079 7,787 51 
Potable water 7,699    
Non-potable water 1,289    
Reclaimed wastewater 877  

Legend Subject to third-party limited assurance procedures. For more details, refer to our 2025 (FY2024) Independent Accountants’ Review Report. 

111 



Assurance 
We obtain limited third-party assurance from an independent auditor for certain environmental metrics, including select GHG emissions, 
energy, and water metrics as indicated in our Environmental metrics data tables. Ernst & Young LLP reviewed these metrics within the 
Schedules of Select Environmental Metrics for the fiscal year ended December 31, 2024. For more details, refer to our 2025 (FY2024) 
Independent Accountants’ Review Report below. 

Due to rounding, recalculation, and footing, some of the reported values in our Environmental metrics data tables for prior years no longer 
directly match the associated Independent Accountants’ Review Reports or data tables from those years. 

Independent Accountants’ Review Report Furthermore, Scope 3 emissions are calculated based on a significant number of estimations and 
management assumptions due to the inherent nature of the Greenhouse Gas Protocol Corporate 
Value Chain (Scope 3) Accounting and Reporting Standard as well as the Technical Guidance 

To the Board of Directors and Management of Alphabet Inc. for Calculating Scope 3 Emissions criteria. 

The information included in the Company’s annual Environmental Report and submission to the 
We have reviewed Alphabet Inc.’s Schedules of Select Environmental Metrics for the year CDP, formerly known as the Carbon Disclosure Project, other than the Subject Matter, has not 
ended December 31, 2024 (the “Subject Matter”) included in Appendix A in accordance with the been subjected to the procedures applied in our review and, accordingly, we express no 
criteria also set forth in Appendix A (the “Criteria”). Alphabet Inc.’s management is responsible conclusion on it. 
for the Subject Matter in accordance with the Criteria. Our responsibility is to express a 
conclusion on the Subject Matter based on our review. Based on our review, we are not aware of any material modifications that should be made to the 

accompanying Schedules of Select Environmental Metrics for the year ended December 31, 
Our review was conducted in accordance with attestation standards established by the 2024 included within Appendix A in order for them to be in accordance with the Criteria. 
American Institute of Certified Public Accountants (AICPA) AT-C section 105, Concepts 
Common to All Attestation Engagements, and AT-C section 210, Review Engagements. Those 
standards require that we plan and perform our review to obtain limited assurance about 
whether any material modifications should be made to the Subject Matter in order for it to be in 
accordance with the Criteria. The procedures performed in a review vary in nature and timing 
from and are substantially less in extent than, an examination, the objective of which is to obtain San Jose, California 
reasonable assurance about whether the Subject Matter is in accordance with the Criteria, in all June 16, 2025 
material respects, in order to express an opinion. Accordingly, we do not express such an 
opinion. Because of the limited nature of the engagement, the level of assurance obtained in a 
review is substantially lower than the assurance that would have been obtained had an 
examination been performed. As such, a review does not provide assurance that we became 
aware of all significant matters that would be disclosed in an examination. We believe that the 
review evidence obtained is sufficient and appropriate to provide a reasonable basis for our 
conclusion. 

We are required to be independent of Alphabet Inc. and to meet our other ethical 
responsibilities, in accordance with the relevant ethical requirements related to our review 
engagement. Additionally, we have complied with the other ethical requirements set forth in the 
Code of Professional Conduct and applied the Statements on Quality Control Standards 
established by the AICPA. 

The procedures we performed were based on our professional judgment. Our review consisted 
principally of applying analytical procedures, making inquiries of persons responsible for the 
subject matter, obtaining an understanding of the data management systems and processes 
used to generate, aggregate and report the Subject Matter and performing such other 
procedures as we considered necessary in the circumstances. 

As described in Appendix A, the Subject Matter is subject to measurement uncertainties 
resulting from limitations inherent in the nature and the methods used for determining such data. 
The selection of different but acceptable measurement techniques can result in materially 
different measurements. The precision of different measurement techniques may also vary. 

Appendix A: Schedules of Select Environmental Metrics 
Alphabet Inc.1 Schedule of Select Environmental Metrics 

For the Year Ended December 31, 20242 

Alphabet Inc.1 Schedule of Select Environmental Metrics 
For the Year Ended December 31, 20242 

Metric 3, 4 Reported 
Value 5 Unit Criteria 

ENERGY 
Metric 3, 4 Reported 

Value 5 Unit Criteria 
Energy Consumption 

GREENHOUSE GAS (GHG) EMISSIONS 

Emissions Inventory 
Metric tons of carbon 

Scope 1 73,100 dioxide equivalent Total energy consumption10 32,727,800 MWh11 As defined by GRI Disclosure 302-1: Energy consumption within the 
(tCO organization a, b, c, e, f, g12, 13 

2e) 
Biogenic emissions 17,200 Metric tons of carbon 

dioxide (tCO2) 

Scope 2 location-based 11,283,200 

Scope 2 market-based 3,059,100 Alphabet calculates electricity procured from renewable sources (%) 
on an annual basis by dividing the MWhs of electricity procured 

Total operational (scope 1 + Electricity procured from from renewable sources (i.e., through contractual instruments, on-
market-based scope 2) emissions 3,132,200 renewable sources 100 % site renewable electricity generation, and renewable electricity in 

the electric grids where facilities are located) by the total MWhs of 
Scope 3 (Category 1: Purchased World Resources Institute (WRI)/World Business Council for 
goods and services) 6 3,601,000 Sustainable Development’s (WBCSD): electricity consumption of Alphabet’s global operations. 

Scope 3 (Category 2: Capital 1. The GHG Protocol: A Corporate Accounting and Reporting 
goods) and (Category 11: Use of 6,337,000 Standard as amended by the GHG Protocol Scope 2 WATER 
sold products) 6 Guidance (Corporate Standard) Global Operational Water Use 
Scope 3 (Category 3: Fuel- and 2. Corporate Value Chain (Scope 3) Accounting and Reporting 
energy-related activities [not 714,000 Standard (Scope 3 Standard) Water withdrawal 11,011 Total water withdrawal, excluding seawater, for any use by 

tCO2e Alphabet.12 
included in scope 1 or scope 2]) 6 3. Technical Guidance for Calculating Scope 3 Emissions 

(Scope 3 Technical Guidance) 
Scope 3 (Category 4: Upstream 
transportation and distribution) 6 853,000 Water discharge 2,876 Total water discharge, excluding seawater, for which Alphabet has 

Million gallons no further use.12 
Collectively, these are referred to as the GHG Protocol. 

Total water consumption, excluding seawater, that has been 
Scope 3 (Category 5: Waste 
generated in operations) 6 12,000 Water consumption 8,135 withdrawn and incorporated into Alphabet’s operations, including 

through evaporation, and is therefore not released back to surface 
water, groundwater, or a third party.12 

Scope 3 (Category 6: Business 
travel) 6 399,000 

Boundaries and general methodology 
Scope 3 (Category 7: Employee 
commuting) 6 137,000 The metrics in the following schedules are reported in alignment with the criteria outlined in the Schedule of Select Environmental Metrics 

above. The reporting boundary for the GHG emissions, energy, and water metrics included in the Schedule of Select Environmental 
Metrics is Alphabet, globally. Alphabet utilizes the operational control approach, as defined by the GHG Protocol, to establish the relevant 

Scope 3 (total) 12,053,000 operations for the emissions, energy, and water metrics at Alphabet’s owned and leased data centers, offices, and other assets (Global 
Facilities). Where possible, based on Alphabet’s reporting timeline and requirements, Alphabet uses the most up-to-date emission factors 

Carbon Intensity available at the time of their emissions inventory calculation and calculates emissions by multiplying relevant activity data by the applicable 
Carbon intensity per unit of emission factors, and global warming potentials (GWPs) (if applicable). Many of the emission factor sources provide emission factors in 
revenue 7 8.95 tCO2e / million USD 

($) GRI Disclosure 305-4: GHG emissions intensity CO2e and therefore GWPs are not required. In cases where Alphabet calculates CO2e from emission factors for individual GHGs, the 
Carbon intensity per full-time GWPs for each GHG are sourced from the Intergovernmental Panel on Climate Change (IPCC) Fourth Assessment Report (AR4), IPCC 
equivalent employee (FTE) 7, 8 17.33 tCO2e / FTE These metrics are calculated using Scope 1 and Scope 2 market- Fifth Assessment Report (AR5), and IPCC Sixth Assessment Report (AR6). 

based GHG emissions. The GHGs included in these metrics are 
Carbon intensity per MWh of 
energy consumed  9 0.0957 tCO2e / MWh CO2, CH4, N2O, and HFCs. Scope 1 

“Scope 1” represents direct emissions from natural gas, back-up generator fuel use, and fugitive emissions of hydrofluorocarbons (HFCs) 
from refrigerant leaks at owned Global Facilities, fuel consumption from Alphabet's operated vehicles and aircraft, and methane (CH4) 
and nitrous oxide (N2O) from biogenic sources. Where actual data isn’t available, for example from a utility bill, Alphabet estimates natural 

1 References to Alphabet Inc. includes its subsidiaries (collectively, Alphabet). gas consumption using square footage of the data centers, offices, and other assets and internally developed natural gas intensity factors 
2 All metrics are reported for the period January 1, 2024 through December 31, 2024. by office type, based on data from the reporting period. Where actual refrigerant leakage data isn’t available, Alphabet estimates 
3 The ambitions and progress against related ambitions are not included in this presentation of the Subject Matter. refrigerant leakage by taking an average of GWP values from known refrigerants within the portfolio and a 20% leakage rate at data 
4 Non-financial information is subject to measurement uncertainties resulting from limitations inherent in the nature and the methods used for centers, offices, and other assets. The emission factors used to calculate scope 1 GHG emissions include the 2024 WRI/WBCSD GHG 

determining such data. The selection of different but acceptable standards and frameworks provide acceptable measurement techniques, which may Protocol Emission Factors from Cross Sector Tools, the 2025 U.S. Environmental Protection Agency (EPA) Emission Factors for 
result in materially different measurements. The precision of different measurement techniques may also vary. 

5 All reported values are rounded to the nearest hundred unless otherwise noted. 10 Total energy consumption includes all fuel and natural gas consumption; purchased electricity, steam, heating, cooling; and all electricity generated 
6 All reported scope 3 GHG emissions values are rounded to the nearest thousand. on-site from renewable sources. 
7 Reported carbon intensity per unit of revenue and per FTE employee values are rounded to the nearest hundredth. 11 Metric is reported in MWh, using a conversion factor of 3600 MJ/MWh. 
8 FTEs are based on the annual average FTEs. 12 Significant contextual information necessary to understand how the data has been compiled has been disclosed. 
9 Reported carbon intensity per MWh of energy consumed value is rounded to the nearest ten thousandth. 13 Other criteria included in GRI Disclosure 302-1 (e.g., 302-1d: electricity, heating, cooling, and steam consumed sold) are excluded. 

112 



Greenhouse Gas Inventories, the 2024 Climate Registry Default Emission Factors, and the 2024 Department for Environment, Food and Alphabet’s Schedule of GHG Emissions by Type 
Rural Affairs (DEFRA) UK Government GHG Conversion Factors. For the Year Ended December 31, 2024 

(tCO2e) 
Biogenic emissions 
“Biogenic emissions” GHG emissions by type Scope 1 Scope 2 (market-based) Scope 2 (location-based) 

represent direct CO2 emissions from Alphabet ’s operated vehicles and generators that consume biogenic fuels. 
In accordance with the Corporate Standard, biogenic CO2  emissions are reported separately from other scope 1 GHG emissions. The CO2 50,700 3,027,400 11,207,600 
emission factors used to calculate biogenic emissions come from the 2025 EPA Emission Factors for Greenhouse Gas Inventories. 

Scope 2 location-based and Scope 2 market-based CH4 100 4,200 22,300 

“Scope 2 location-based” and “Scope 2 market-based” represent indirect emissions from natural gas, fugitive emissions from 
refrigerant leaks at leased Global Facilities, purchased steam, hot water, and chilled water from district energy systems, and purchased N2O 200 8,500 34,300 
electricity consumption at Global Facilities. All purchased electricity includes purchased electricity for owned and operated global data 
centers and purchased electricity related to the operation of Alphabet’s information technology assets at leased data centers and other 
locations. Alphabet reports scope 2 emissions using both location-based and market-based methods. The location-based method reflects HFCs 22,100 19,000 19,000 
the average carbon intensity of the electric grids where Alphabet’s operations are located and thus where the electricity consumption 
occurs. The market-based method incorporates Alphabet’s procurement choices, primarily renewable energy purchases via contractual 
instruments, such as power purchase agreements (PPAs). Alphabet uses actual data (such as third-party invoices, monthly utility bills, Total 73,100 3,059,100 11,283,200 
or meter readings) to calculate scope 2 emissions. Where actual data isn’t available, Alphabet estimates electricity consumption, natural 
gas consumption, and activity from district energy systems using square footage of our data centers, offices, and other assets and 
internally developed intensity factors by office type, based on data from the reporting period. The emission factors used to calculate scope 
2 (location-based) emissions include the 2024 WRI/WBCSD GHG Protocol Emission Factors from Cross Sector Tools, the 2025 EPA 
Emission Factors for Greenhouse Gas Inventories, the 2024 DEFRA UK Government GHG Conversion Factors, the 2024 International 
Energy Agency (IEA) Emission Factors, the 2025 EPA eGRID Emission Factors, and the 2024 Climate Registry Default Emission Factors. Alphabet’s Schedule of GHG Emissions by Type 
The emission factors used to calculate scope 2 (market-based) emissions are the same as scope 2 (location-based) with the addition of For the Year Ended December 31, 2024 
emission factors specific to energy attribute certificates (EACs), as well as residual mix emission factors where available. Residual grid (metric tons per gas type) 
mix removes the proportion of renewable energy contracted to other parties—that have the rights to claim those clean electricity attributes 
through EACs—from the grid electricity mix, and therefore avoids double-counting. Comprehensive residual mix emission factors are GHG emissions by type Scope 1 Scope 2 (market-based) Scope 2 (location-based) 
currently only available for Europe (European Residual Mixes 2023, Association of Issuing Bodies). Outside of Europe, residual emission 
factors aren’t available from third-party sources to account for voluntary purchases, and this may result in double counting between CH4 5 100 800 
electricity consumers. 

N2O 1 32 100 
Alphabet’s Schedule of GHG Emissions by Region 

For the Year Ended December 31, 2024 
(tCO2e) HFCs 14 13 13 

GHG emissions by region Scope 1 Scope 2 (market-based) Scope 2 (location-based) 

North America 53,600 1,161,200 8,293,200 Scope 3 GHG emissions 

Europe, Middle East, & Africa 8,800 82,700 1,033,800 “Scope 3 GHG emissions” are indirect emissions from other sources in Alphabet’s value chain. Alphabet calculates the reported values 
in the Schedule of Select Environmental Metrics using methodologies from the Scope 3 Technical Guidance for the following categories 
identified as relevant: 

Latin America 1,900 13,900 147,100 ● Category 1: Purchased goods and services 
● Category 2: Capital goods 
● Category 3: Fuel- and energy-related activities (not included in scope 1 or scope 2) 

Asia Pacific 8,800 1,801,300 1,809,100 ● Category 4: Upstream transportation and distribution 
● Category 5: Waste generated in operations 
● Category 6: Business travel 

Global total 73,100 3,059,100 11,283,200 ● Category 7: Employee commuting 
● Category 11: Use of sold products 

Alphabet evaluated the remaining categories using the Scope 3 Standard’s relevance criteria and determined the following categories to 
be either not applicable or not relevant. The emissions associated with categories deemed not relevant are not significant to scope 3 
emissions individually or in the aggregate. 

● Category 8: Upstream leased assets. Not applicable because Alphabet accounts for upstream leased assets within scope 2. 
● Category 9: Downstream transportation and distribution. Not relevant because category 9 emissions are insignificant. 
● Category 10: Processing of sold products. Not applicable because Alphabet does not sell intermediate goods that require further 

processing. 
● Category 12: End-of-life treatment of sold products. Not relevant because category 12 emissions are insignificant. 
● Category 13: Downstream leased assets. Not relevant because category 13 emissions are insignificant. 
● Category 14: Franchises. Not applicable because Alphabet does not have franchises. 
● Category 15: Investments. Not relevant because category 15 emissions are insignificant, based on a screening estimate of 

equity investments in which Alphabet has greater than 5% ownership. 

Alphabet’s reported values in the Schedule of Select Environmental Metrics are presented according to the minimum boundaries listed Alphabet’s goods). Where actual logistics provider emissions data isn’t available, Alphabet calculates WTW emissions using weight and 
by the Scope 3 Standard. For certain categories, Alphabet also includes activities which the Scope 3 Standard deems optional. None of distance data by shipment collected from providers, using emission factors from the 2024 Global Logistics Emissions Council (GLEC) 
the scope 3 categories have associated biogenic carbon dioxide emissions. framework v3.1 or EPA SmartWay carrier performance data. Where logistics provider weight and distance data is not available, emissions 

are estimated based on reported data from other transportation providers and the weight shipped. For warehousing emissions, Alphabet 
Alphabet presents emissions from category 2 (Capital goods) and category 11 (Use of sold products) as an aggregated total for business uses the site-specific method, as defined by the Scope 3 Technical Guidance. To calculate consumer products and data center equipment 
confidentiality purposes. The emissions from category 11 (Use of sold products) are not a material component of total scope 3 emissions. warehousing emissions, Alphabet collects energy data (both) and refrigerant leakage data (data center equipment warehousing only) 

directly from the warehouses and calculates emissions using lifecycle electricity and fuel emission factors from the Sphera Professional 
For each relevant scope 3 category, Alphabet provides the following details, as applicable: the minimum and optional activities included, database 2024. Alphabet’s share of a third party’s warehouse energy and refrigerant leakage activity is determined via physical allocation 
calculation methods, activity data, emission factors, percentage of category emissions from value chain partners, allocations, and any (i.e., based on how much of the total warehouse area is used for Alphabet’s goods). Data obtained from value chain partners is used to 
significant estimations or assumptions. calculate nearly 100% of emissions. 

“Category 1: Purchased goods and services” includes upstream emissions generated from manufacturing consumer devices and “Category 5: Waste generated in operations” includes emissions from solid waste generated at Alphabet’s offices, Google14 owned-
spare parts, the Real Estate & Workplace Services (REWS) food program, and additional goods and services purchased for Alphabet’s and operated data centers, and Google-owned warehouses. The waste is either composted, recycled, landfilled, or incinerated (with or 
operations. Alphabet uses a combination of the average-data method and spend-based method, as defined by the Scope 3 Technical without energy recovery). Alphabet calculates this category’s emissions to also include the optional activity of waste transportation, which 
Guidance. To calculate supply chain emissions generated from manufacturing consumer devices and spare parts, Alphabet performs is embedded in the emission factors used. Alphabet uses a combination of the waste-type-specific method and the average-data method, 
third-party-verified Life Cycle Assessments (LCAs) in accordance with International Organization for Standardization (ISO) 14040 and as defined by the Scope 3 Technical Guidance. The waste generation data comes from a combination of data from invoices and on-site 
ISO 14044. To calculate emissions generated from the REWS food program, Alphabet uses LCA emission factors from WRI’s Cool Food measurements. Where actual waste data isn’t available for a specific facility, Alphabet estimates waste tonnage using waste container 
Pledge Calculator and annual procurement volumes from San Francisco Bay Area offices. For the remaining offices where procurement size and pickup frequency, actual waste data from similar facilities, or historical waste data from the same facility. Alphabet uses waste 
data is unavailable, Alphabet estimates remaining emissions by scaling the San Francisco Bay Area emissions based on global building type- and disposal type-specific emission factors from the 2025 EPA Emission Factors for Greenhouse Gas Inventories for U.S. activity 
admittance data. Where emission factors from WRI aren’t available, Alphabet estimates remaining emissions using spend data and the and the 2024 DEFRA UK Government GHG Conversion Factors for non-U.S. activity. Alphabet excludes from this category the emissions 
EPA’s U.S. Environmentally-Extended Input-Output (“USEEIO”) Supply Chain GHG Emission Factors (2024 v1.3), which are then from wastewater treatment. Although category 5 emissions are insignificant, Alphabet determined that waste generated in operations is 
adjusted for inflation using the U.S. Bureau of Labor Statistics’ Consumer Price Index Inflation Calculator (“USEEIO supply chain emission relevant based on other criteria for relevance such as influence, risk, and stakeholders. 
factors”). To calculate emissions generated from the remaining goods and services purchased for operations, Alphabet estimates supplier 
emissions using spend data and USEEIO supply chain emission factors. Data obtained from value chain partners is used to calculate “Category 6: Business travel” includes emissions from business-related air, rail, bus, personal vehicle (when the employee’s car is used 
approximately 2% of Category 1 emissions. for business purposes), taxi, rideshare, shuttle, and rental car travel, including emissions from relocation travel. Report Values also include 

the optional activity of upstream emissions of business travel. Alphabet uses a combination of the distance-, fuel-, and spend-based 
“Category 2: Capital goods” includes upstream emissions generated from final goods that are used in manufacturing and assembly of calculation methods, as defined by the Scope 3 Technical Guidance. Alphabet collects all travel data through an online booking system 
servers and networking equipment used in technical infrastructure, materials and fuels used in the construction of data centers and or a third-party travel agency. To calculate emissions from the majority of air travel, Alphabet uses the Travel Impact Model, an emissions 
offices, and additional capital goods purchased for Alphabet’s operations. Alphabet uses a combination of the average-data, and spend- estimation model developed by Google that’s built from public and licensable external datasets. Alphabet calculates total plane WTW 
based methods, as defined by the Scope 3 Technical Guidance, as well as LCAs that are in accordance with ISO 14040, ISO 14044, and emissions and allocates an amount to the employee passenger based on the plane’s percentage of occupied seats (i.e., the passenger 
ISO 14067. To calculate emissions generated from manufacturing and assembly of servers and networking equipment used in technical load factor) and the mass of cargo being carried. For all other modes of transport, including rail, taxi, rideshare, non-U.S. personal 
infrastructure, Alphabet primarily uses configurable LCA models (third-party reviewed) for high-impact components (which account for vehicles, non-U.S. shuttle travel, and a minority of air travel, Alphabet uses WTW emissions factors from the 2024 DEFRA UK Government 
the majority of total technical infrastructure hardware emissions). This allows tailored calculations to Alphabet’s specific mix of data center GHG Conversion Factors. Alphabet calculates emissions from car rental, U.S. personal vehicle, and U.S. shuttle travel using well-to-tank 
hardware and incorporation of supplier-specific process-level data. For technical infrastructure components where LCA data is (WTT) emission factors from the 2024 DEFRA UK Government GHG Conversion Factors (WTT) and tank-to-wheel (TTW) emission 
unavailable, Alphabet applies the spend-based method. For these remaining components, Alphabet collects supplier emissions data from factors from the 2025 EPA Emission Factors for Greenhouse Gas Inventories. Data obtained from value chain partners is used to calculate 
contract manufacturers as well as component and fabless suppliers through the CDP Supply Chain Program. Alphabet’s share of these approximately 6% of emissions. 
suppliers’ emissions is determined via economic allocation (i.e., based on revenue and spend). Where available and valid, Alphabet uses 
scope 2 market-based method emissions from these suppliers. Where supplier-specific emissions data is not available through CDP, “Category 7: Employee commuting” includes emissions from the transport of full-time employees between their homes and their 
Alphabet estimates supplier emissions using spend data and either USEEIO supply chain emission factors or proxy supplier economic worksites by passenger car (i.e., carpool, dropoff, taxi, rideshare, or single-occupied vehicle), rail, bus, motorcycle and gas-powered 
allocation. To calculate emissions generated from materials used in data center and office construction, Alphabet uses data on annual scooter. Report Values also include the optional activity of upstream emissions of employee commuting. Alphabet uses the distance-
construction area and lifecycle emission factors derived from LCAs conducted on Alphabet data centers and offices, as well as invoice- based method, as defined by the Scope 3 Technical Guidance. Alphabet surveys its employees to determine typical commuting patterns 
based material information. Alphabet inputs building mass by material data– either collected, or estimated based on actuals where and applies these commuting patterns to its global employee population. Alphabet uses a mode-specific commuting distance obtained 
unknown–into LCA software (Tally, One Click LCA and SimaPro–which reference the emission factor databases from ecoinvent and from the American Public Transportation Association’s 2023 Fact Book and the U.S. Department of Transportation’s 2022 National 
Sphera), and the Embodied Carbon in Construction Calculator (EC3) webtool. For offices, the LCA results undergo third-party review Household Travel Survey. Alphabet calculates employee commuting emissions using mode-specific WTT emission factors from the 2024 
(e.g., by the US Green Building Council for LEED certification). To calculate emissions generated from additional capital goods purchased DEFRA UK Government GHG Conversion Factors and TTW emission factors from the 2025 EPA Emission Factors for Greenhouse Gas 
for operations, Alphabet estimates supplier emissions using spend data and USEEIO supply chain emission factors. Data obtained from Inventories. Alphabet uses passenger distance-based emission factors for shared vehicles (i.e., carpool, taxi, rideshare, rail, bus) in order 
value chain partners is used to calculate approximately 15% of emissions. to allocate the total vehicle emissions to the employee passenger. 

“Category 3: Fuel- and energy-related activities (not included in scope 1 or scope 2)” includes upstream emissions from purchased “Category 11: Use of sold products” includes direct use-phase emissions generated by Google’s consumer devices sold in the 
fuels (e.g., natural gas, diesel, and gasoline) and purchased energy (i.e., electricity, steam, heating, and cooling), as well as emissions reporting period that directly consume electricity during use.15, 16 These emissions also include the optional activity of upstream electricity 
from transmission and distribution losses from purchased energy. Alphabet uses the average-data method, as defined by the Scope 3 emissions of these devices by using LCA emission factors. Alphabet performs LCAs that are in accordance with ISO 14040 and ISO 
Technical Guidance. Alphabet calculates upstream emissions from purchased fuel, steam, heating, and cooling and emissions from 14044 and are third-party reviewed. The LCA results are published on Google’s Sustainability Reports webpage. Alphabet uses laboratory 
transmission and distribution losses from steam, heating, and cooling using 2024 DEFRA UK Government GHG Conversion Factors. power draw measurements, data on use patterns, common industry assumptions on product lifetimes, and LCA electricity emission 
Alphabet calculates emissions from upstream electricity by country using the 2024 IEA Emission Factors. Alphabet calculates emissions factors from the 2024 Sphera LCA for Experts database. 
from electricity transmission and distribution losses using grid loss values and emission factors derived from the 2024 IEA Emission 
Factors and, for the United States, the 2025 EPA eGRID Emission Factors. For upstream electricity, Alphabet calculates emissions using Energy 
scope 2 market-based data (i.e., by using the remaining electricity not addressed by renewable energy). For electricity transmission and 
distribution losses, Alphabet uses the market-based method to account for EACs that Alphabet has purchased to cover a portion of grid Alphabet calculates electricity procured from renewable sources (%) using a custom methodology based on a global approach. Alphabet 
losses. calculates electricity procured from renewable sources (%) on an annual basis by dividing the MWhs of renewable electricity procured 

(i.e., through contractual instruments, on-site renewable electricity generation, and renewable electricity in the electric grids where 
“Category 4: Upstream transportation and distribution” includes emissions generated from transportation and warehousing of facilities are located) by the total MWhs of electricity consumed by Alphabet’s global operations. Contractual instruments may include 
Alphabet’s consumer products and data center equipment. Report Values also include the optional activities of upstream emissions of 
transportation. For transportation emissions, Alphabet uses a combination of the fuel-based and distance-based methods, as defined by 

14
the Scope 3 Technical Guidance. For transportation emissions, Alphabet collects well-to-wheel (WTW) emissions data, calculated based  Alphabet is the parent holding company of Google. 
on fuel use or weight-distance data, and routing associated with a shipment from suppliers. Logistics providers determine Alphabet’s 15 Flagship consumer devices are products that can provide their main functionality without connection to another product. For example, this 
share of a shipment’s transportation emissions via physical allocation (i.e., based on how much of the total shipment’s weight is from generally doesn’t include accessories such as cases. 

16 Network and end-user devices used to access web-based software are not considered to be direct-use phase emissions and are not within the 
reporting boundary for use of sold products. 

113 



PPAs, tax equity investments, PPA-linked Renewable Energy Certificates (RECs) / guarantee of origin (GO) agreements, and utility Alphabet’s Schedule of Electricity Consumpt ion 
renewable energy tariffs, which may result in RECs or GOs. The numerator includes all renewable electricity procured, regardless of the For the Year Ended December 31, 2024 
market in which Alphabet consumed the renewable electricity. To achieve Alphabet’s 100% renewable energy match, Alphabet first (MWh) 
considers both on-site renewable electricity generation and the renewable electricity already in the electric grids where the facilities are 
located (using the residual mix where data is available). Alphabet then procures renewable electricity through contractual instruments. Data centers 30,825,600 
Alphabet has a few facilities located in geographies where it is not currently able to source large volumes of renewable electricity, so 
Alphabet procures surplus renewable electricity in regions where it’s abundant. Refer to  “Achieving Our 100% Renewable Energy Offices and other facilities 1,354,300 
Purchasing Goal and Going Beyond” for additional details on Alphabet’s custom criteria and methodology. 

Total electricity consumption 17 32,179,900 
Alphabet’s Schedule of Electricity and Renewable Electricity by Region 

For the Year Ended December 31, 2024 
(MWh) 

Electricity and renewable electricity allocated by region Total electricity Total renewable electricity 
allocated 

North America 23,233,300 18,747,600 Alphabet ’s Schedule of Electricity Procured from Renewable Sources 
For the Year Ended December 31, 2024 

(MWh) 
Europe, Middle East, & Africa 4,951,900 4,822,000 

Renewable electricity procured (PPAs and other renewable energy agreements) 24,504,500 

Latin America 500,400 411,900 Renewable electricity procured (on-site) 20,500 

Renewable electricity (grid) 7,654,900 
Asia Pacific 3,494,300 14,300 

Total electricity procured from renewable sources 32,179,900 
Global total 32,179,900 23,995,800 

Water 
Relevant operations for water metrics include owned and fully leased data centers and owned and leased offices and other assets. Water 

Alphabet’s Schedul e of Energy Consumption withdrawal data is based on actual metered or invoiced data when it is available. At offices where actual metered or invoiced data is not 
For the Year Ended December 31, 2024 available, water withdrawal is estimated using facility square footage and internally developed water withdrawal intensity factors by office 

(MWh) type based on data from the reporting period. Water discharge is based on actual metered or invoiced data when it’s available. Where 
actual domestic wastewater discharge data isn’t available, Alphabet applies an industry-standard 90% discharge flow factor to a facility’s 

Energy consumption by source type Renewable sources Non-renewable sources Total domestic water withdrawal to estimate domestic water discharge and a 0% discharge flow factor to a facility’s irrigation water withdrawal 
to estimate irrigation water discharge. Alphabet applies this water discharge estimation methodology at all offices and at data centers 
where metered water discharge data isn’t available. At data centers where actual data isn’t available, Alphabet estimates water discharge 

Fuel 63,200 226,500 289,700 using engineering principles. Alphabet calculates “water consumption” by subtracting “water discharge” from “water withdrawal.” 
Purchased electricity 17 23,995,800 8,110,400 32,106,200 

Alphabet’s Schedule of Water Use by Data Centers and Offices 
Purchased heat 0 237,500 237,500 For the Year Ended December 31, 2024 

(mill ion gallons) 
Purchased steam 0 17,100 17,100 Water use by data centers and offices Withdrawal Discharge Consumption 
Purchased cooling 0 56,800 56,800 Data centers 9,866 2,079 7,787 

On-site renewable electricity 20,500 0 20,500 Office and other facilities 1,145 797 348 

Total energy consumption 24,079,500 8,648,300 32,727,800 Total 11,011 2,876 8,135 

17 “Total electricity consumption” includes both purchased and self-generated electricity from renewable and non-renewable sources. Where actual 
natural gas or electricity consumption for facilities isn’t available, Alphabet estimates consumption using building square footage and internally 
developed intensity factors based on data from the reporting period. Total electricity consumption differs slightly from “Purchased electricity,” which is 
electricity sourced from an electrical grid and purchased from a local electric utility company. 

Alphabet’s Schedule of Water Use by Data Center Location 
For the Year Ended December 31, 2024 

(mill ion gallons)18 

Location Withdrawal Discharge Consumption 
Ashburn, VA 59.5 3.5 56.0 
Berkeley County, SC 853.8 77.3 776.5 
Bristow, VA 105.7 21.3 84.4 
Council Bluffs, IA 1,410.3 400.1 1,010.2 
The Dalles, OR 461.1 99.7 361.4 
Douglas County, GA 444.1 77.2 366.9 
Dublin, Ireland 0.9 0.8 0.1 
Eemshaven, Netherlands 416.9 86.9 330.0 
Frankfurt, Germany 2.3 1.8 0.5 
Fredericia, Denmark 48.4 10.6 37.8 
Hamina, Finland 3.0 2.7 0.3 
Hanau, Germany 1.2 0.6 0.6 
Henderson, NV 359.9 152.5 207.4 
Inzai, Japan 26.0 7.8 18.2 
Jackson County, AL 201.6 18.8 182.8 
Lancaster, OH 207.4 106.3 101.1 
Leesburg, VA 246.7 55.1 191.6 
Lenoir, NC 351.7 23.9 327.8 
Lockbourne, OH 177.3 34.0 143.3 
Mayes County, OK 1,108.3 275.1 833.2 
Middenmeer, Netherlands 9.3 2.8 6.5 
Midlothian, TX 221.0 38.7 182.3 
Montgomery County, TN 387.9 66.1 321.8 
Montreal, Canada 0.6 0.5 0.1 
New Albany, OH 405.3 52.6 352.7 
Omaha, NE 44.3 12.2 32.1 
Papillion, NE 532.3 115.4 416.9 
Pflugerville, TX 0.1 0.1 0.01 
Phoenix, AZ 0.2 0.2 0.03 
Quilicura, Chile 219.0 97.2 121.8 
San Bernardo, Chile 0.3 0.3 0.03 
St. Ghislain, Belgium 511.7 118.4 393.3 
Sterling, VA 201.2 43.0 158.2 
Storey County, NV 14.9 13.4 1.5 
Sydney, Australia 1.0 0.9 0.1 
Wilmer, TX 1.9 1.7 0.2 
Other data center locations 828.9 60.0 786.9 
Total 9,866 2,079 7,787 

18 Water use by data center location metrics are rounded to the nearest tenth. If water use by data center location is less than fifty thousand gallons, 
we round to the nearest hundredth. 

114 



Certifications and recognitions 

Certification Details 

In 2024, we maintained our ISO 50001 certification at five of our six 178 Google-owned and -operated data centers in Europe and 
ISO 50001: expanded the scope of the energy management system to our Google-owned and -operated data center in Chile. We were 
Energy management the first major internet company to achieve a multi-site energy management system certification to ISO 50001, which we first 

obtained in 2013. 
ISO 14001: We maintain ISO 14001 certification for our mobile phones, laptop, and tablet consumer hardware in the United States. In 2024, 
Environmental we achieved ISO 14001 certification for our data centers in Dublin, Ireland and Eemshaven, Netherlands, and we’re working on 
management certifications for our remaining Google-owned and -operated data centers in Europe. 

As of 2021, Google is a signatory of the Climate Neutral Data Centre Pact. The Pact sets targets in five areas: energy efficiency, 
Climate Neutral Data 

renewables, water, circular economy, and heat recovery. In 2024, we maintained third-party verification for five of our six 179  
Centre Pact (CNDCP) 

Google-owned and -operated data centers in Europe, meeting the five pact targets in line with the Self-Regulatory Initiative. 
EU Code of Conduct 

In 2024, five of our six 180 Google-owned and -operated data centers in Europe were “Participants” in the EU Code of Conduct on 
on Data Centre Energy 

Data Centre Energy Efficiency. 
Efficiency 

As of the end of 2024, over 300 Google offices and facilities have achieved LEED certification, including 79 with a Platinum 
Leadership in Energy and 

rating and 166 with a Gold rating. In 2024 alone, we achieved LEED certification for 12 Google offices and facilities, including 10 
Environmental Design 

with a Platinum rating and one with a Gold rating. For a list of some of Google’s LEED-certified projects, refer to the U.S. Green 
(LEED) 

Building Council’s project library. 

Below is a selection of sustainability-related recognitions, mainly received in 2024. While most focus on environmental topics exclusively, some also 
recognize additional achievements. 

American Society of Anthem Awards Cannes Lions International Corporate Knights 
Landscape Architects Festival of Creativity 
(ASLA) Anthem Brand of the Year 2025 Carbon Clean200 

Environmental Innovation award 
2024 ASLA Professional Awards Winner Ranked #13 

Bronze award 
Honor Award in General Design 

for “Contrails: Making Flying More 
for “St. John’s Terminal: An Ecology for Sustainable” 
Technology and Innovation” 

CoreNet Global Fast Company Forbes The Repair Association 
2024 Award for Professional Excellence 
and Sustainable Leadership in World Changing Ideas 2024 America’s Best Companies 2025 2024 Right to Repair Advocacy Award 
Corporate Real Estate World-Changing Company of the Year Ranked #2 Repair Advocate of the Year 
Winner 

for Google’s suite of projects that use (Alphabet ranked well in the 
for “Adapting St. John’s Terminal as AI to address climate change sustainability category) 
Google’s Workplace of the Future” 

Royal Academy of S&P Dow Jones Indices,  Sustainability Magazine Sustainability Magazine 
Engineering a division of S&P Global 

Top 10: Sustainable Data Center Top 10: Sustainable Technology 
2024 MacRobert Award Best-in-Class North America Index Providers Companies 

Winner Included (Alphabet) Ranked #1 Ranked #1 

for Google DeepMind’s pioneering 
AI weather forecasting technology, 
GraphCast 

TIME TIME U.S. Environmental U.S. Green Building Council 
Protection Agency 

The Best Inventions of 2024 World’s Best Companies of 2024 California Green Building & 

Winners Ranked #25 (Alphabet) Green Power Partnership National Community Award 
Top 100 Honored 

in AI category for X’s Bellwether (This ranking considers environmental 
(along with others like Google data) Ranked #2 in Health and Wellbeing category for 
DeepMind’s AlphaFold 3 and Google’s Gradient Canopy 
NotebookLM) 

115 



Endnotes 20 “2024: An Active Year of U.S. Billion-Dollar Weather and Climate Disasters,” Climate.gov, 
January 2025.

21 The estimated population covered is based on the forecasted flood risk area, using the 
1 We use the term data center energy emissions to describe scope 1 and 2 (market-based) 

WorldPop Global Project Population dataset.
emissions that result from our Google data center operations.

22 Based on retail packaging (excluding adhesive materials and required plastic stickers) as 
2 The total GW figure represents primarily PPAs, and includes some generation from 

shipped by Google. To meet the request of some retail partners, stickers and/or security 
targeted clean energy investments where we also receive EACs. Actual generation 

tags are applied to some packaging variations and may contain plastic.
may vary from the signed amounts based on changes during construction or project 

23 Refer to endnote 2 above.
terminations.

24 Unique, signed-in Google users that were provided information to make a more 
3 The comparison is based on data from Portugal’s Directorate-General for Energy and 

sustainable choice by at least one sustainable product feature. 
Geology from December 2024: Total renewable energy installed in 2024 was 20,777 MW.

25 Refer to endnote 5 above.
4 Refer to endnote 2 above.

26 Refer to endnote 11 above. 
5 For details about the calculation, refer to the Methodology section in the Appendix.

27 Refer to endnote 8 above.
6 Refer to endnote 5 above.

28 “High-Income Low-Energy Countries Don’t Exist,” Energy for Growth Hub, September 
7 According to Google’s platform-neutral measurement analyzed over a five-year period 

2024.
from 2019–2024.

29 “Energy and AI: World Energy Outlook Special Report,” IEA, April 2025.
8 These calculations are based on internal data, as of March 2025. Google’s TPU power 

30 Refer to endnote 29 above.
efficiency relative to the earliest generation Cloud TPU v2 is measured by peak FP8 flops 

31 “Energy and AI: World Energy Outlook Special Report,” IEA, April 2025. The IEA projects 
delivered per watt of thermal design power per chip package.

that in a “Widespread Adoption Case,” existing AI applications in end-use sectors could 
9 When we use the term “supply chain” or “supply chain emissions,” we're referring to 

lead to 1.4 GT of carbon emissions reductions in 2035. In comparison, emissions from 
the indirect emissions that happen outside of our direct operations. This includes both 

electricity use by data centers are projected to be 300 million tCO2e in the “Base Case” 
upstream and downstream emissions, also referred to as “value chain emissions.”

and up to 500 million tCO2e in the “Lift-Off Case” in 2035. Therefore, the potential 
10 The Google Clean Energy Addendum applies to the electricity consumed by suppliers in 

emissions reductions from AI applications are approximately 3 times (1,400/500 = 2.8) to 
the manufacturing of Google technical infrastructure and consumer hardware products. 

5 times (1,400/300 = 4.7) larger than the projected emissions from data centers.
11 To estimate aggregate enabled emissions reductions, we first estimated annual 

32 Refer to endnote 29 above.
reductions for five products individually (Google Earth Pro, Solar API, Nest thermostats, 

33 To estimate the lifetime emissions reductions enabled in 2024, Google counted the 
fuel-efficient routing, and Green Light) and then combined the totals. For details 

number of buildings that used the Solar API and had a solar permit issued shortly 
about the individual calculation methodologies, refer to endnotes 89, 16, 91, 17, and 86, 

thereafter (based on publicly available permit data). We then used Berkeley Lab’s Tracking 
respectively.

the Sun (open source NREL dataset) to estimate the average installation size per state, 
12 “Greenhouse Gas Equivalencies Calculator,” U.S. Environmental Protection Agency, 

NREL PVWatts to provide insolation data, and the NREL Cambium model to estimate 
November 2024, accessed June 2025.

the amount of emissions reduced by the energy generated due to those panels over a 
13 This figure reflects our "ambition-based" emissions boundary, which represents the 

25-year estimated lifespan. Enabled emissions reductions estimates include inherent 
subset of emissions from our total carbon footprint that are within the boundaries we’ve 

uncertainty due to factors that include the lack of primary data and precise information 
set for our climate ambitions. 

about real-world actions and their effects to date, as well as forward-looking projections. 
14 Estimated energy savings are calculated based on the average percentages for heating 

Google is relying on its own substantiation of the enabled emissions reduction impact, 
and cooling savings found in real-world studies of the Nest Learning Thermostat in the 

in consultation with multiple third-party partners that have reviewed and support 
U.S. and U.K., and generalized for Nest thermostat usage worldwide, assuming user opt-in 

the methodology discussed herein. The data and claims have not been verified by an 
for available energy-saving features. To calculate the total Nest savings, we applied the 

independent third-party. We will continue to work to refine our methodologies and inputs 
savings percentages to the actual heating and cooling hours of all Nest thermostats 

for these estimates.
in use since 2011. As of January 2023, we use an updated energy savings calculation 

34 We estimated location-based, electricity emissions for the Solar API model in 2024 by 
methodology to account for changes in common HVAC sizes and efficiencies, applying 

measuring the energy consumption of training and inference workloads supporting 
the respective energy savings percentages to Nest thermostats in North America and in 

the Solar API model, and applying location-based, hourly grid emissions factors from 
European countries.

ElectricityMaps. We include all relevant compute workloads from January 2024 to 
15 According to the IEA’s Energy Statistics Data Browser, Poland’s total electricity 

December 2024 in this analysis. These findings are a point-in-time measurement of 
consumption was approximately 160 TWh in 2023.

the annual emissions of the Solar API, and may vary as the Solar API model continues 
16 The data used is the same used in the lifetime accounting basis—refer to endnote 33. For 

deployment. This analysis has not been third-party verified or validated.
both annual and lifetime methods, we use a 25-year estimated lifespan. The difference 

35 This estimate is based on our internal analysis comparing the BFLOAT16 / INT8 model step 
is that the estimated annual enabled emissions reduction takes into account solar 

time ratio measured on the MLPerf 3.1 GPT-3 175B model. The results (11,798ms / 8,431ms 
installations enabled by Solar API prior to 2024 (dating back to 2022) to calculate the total 

= 139%) can be interpreted as a 39% speed improvement and, in turn, training efficiency.
impact in 2024 alone. It estimates a single year’s worth of emission reductions each year 

36 “Gemini 1.5: Unlocking Multimodal Understanding Across Millions of Tokens of Context,” 
of a solar panel’s 25-year lifespan. 

Google, 2024.
17 Google uses an AI prediction model to estimate the expected fuel or energy consumption 

37 Refer to endnote 8 above.
for each route option when users request driving directions. We identify the route that 

38 This calculation is based on internal data, as of May 2024.
we predict will consume the least amount of fuel or energy. If this route is not already the 

39 Refer to endnote 8 above.
fastest one and it offers meaningful energy and fuel savings with only a small increase 

40 This calculation is based on internal data, as of April 2025.
in driving time, we recommend it to the user. To calculate enabled emissions reductions, 

41 According to “What NVIDIA’s New Blackwell Chip Says About AI’s Carbon Footprint 
we tally the fuel usage from the chosen fuel-efficient routes and subtract it from the 

Problem,” NVIDIA compared the total power needed to train the latest ultra-large AI 
predicted fuel consumption that would have occurred on the fastest route without 

models using the new Blackwell GPUs (4 megawatts) to the power required with older 
fuel-efficient routing and apply adjustments for factors such as: CO2e factors, fleet mix 

GPUs (15 megawatts) and found the new GPUs use roughly 25% of the power (or 75% 
factors, well-to-wheels factors, and powertrain mismatch factors. This figure covers 

less) of the older ones.
estimated enabled emissions reductions for the calendar year, from January through 

42 “NVIDIA Blackwell Platform Arrives to Power a New Era of Computing,” NVIDIA, March 
December. Enabled emissions reductions estimates include inherent uncertainty due to 

2024.
factors that include the lack of primary data and precise information about real-world 

43 To measure emissions relative to computational performance and enable apples-to-
actions and their effects. These factors contribute to a range of possible outcomes, 

apples comparisons between chips, we developed a new metric—Compute Carbon 
within which we report a central value. The data and claims have not been verified by an 

Intensity (CCI)—that we believe can enable greater transparency and innovation across 
independent third-party.

the industry. CCI quantifies an AI accelerator chip’s carbon emissions per unit of 
18 Refer to endnote 12 above.

computation (measured in grams of CO2e per Exa-FLOP). Lower CCI scores mean lower 
19 Reductions in stops estimates are based on early data points from Google’s analysis of 

emissions from the AI hardware platform for a given AI workload—for example training an 
traffic patterns before and after recommended adjustments to traffic signals that were 

AI model. CCI includes both estimates of lifetime embodied and operational emissions 
implemented during tests conducted in 2024 and 2025. The reduction in stops can vary 

in order to understand the impact of improved chip design on our TPUs. In this study, we 
significantly, in some cases exceeding 30% for a period of time. Emissions reductions 

hold the impact of carbon-free energy on carbon intensity constant across generations, 
estimates are modeled using a Department of Energy emissions model. A single fuel-

by using Google's 2023 average fleetwide carbon intensity. We did this purposefully to 
based vehicle type is used as an approximation for all traffic, adjusted for country-level 

remove the impact of deployment location on the results.
fleet mix from IEA data. These data points are averaged from coordinated intersections, 

44 A February 2025 Google case study quantified the full lifecycle emissions of TPU 
and are subject to variation based on existing scenarios. We expect these estimates to 

hardware as a point-in-time snapshot across Google’s generations of TPUs. To estimate 
evolve over time and look forward to sharing continued results as we perform additional 

operational emissions from electricity consumption of running workloads, we used a 
analysis.

one month sample of observed machine power data from our entire TPU fleet, applying 

116



Google’s 2023 average fleetwide carbon intensity. To estimate embodied emissions from 74 Solder paste is made with multiple materials and contains at least 80% tin. The tin in the 
manufacturing, transportation, and retirement, we performed a life-cycle assessment solder paste is made with 100% recycled content.
of the hardware. Data center construction emissions were estimated based on Google’s 75 Carbon footprint reduction claim based on third-party-verified life cycle assessment. 
disclosed 2023 carbon footprint. These findings do not represent model-level emissions, Recycled aluminum in the enclosures is at least 9% of applicable product based on 
nor are they a complete quantification of Google’s AI emissions. Based on the TPU weight.
location of a specific workload, Compute Carbon Intensity (CCI) results of specific 76 Based on total plastic weight of Google Pixel, Nest, Chromecast, and Fitbit products 
workloads may vary. manufactured in 2024. This does not include plastics in printed circuit boards, labels, 

45 The figure represents the average percentage of Google’s global compute resources that cables, connectors, electronic components and modules, optical components, 
were identified as recoverable and reallocated for more efficient use over this period as a electrostatic discharge (ESD) components, electromagnetic interference (EMI) 
result of using AlphaEvolve. components, films, coatings, and adhesives.

46 We estimated the expected annual generation based on our contracted clean energy, 77 Refer to endnote 22 above.
applying an average capacity factor. Actual generation may vary from the signed amounts 78 Refer to endnote 22 above.
based on changes during construction or project terminations. 79 This includes all final assembly manufacturing sites globally for Google consumer 

47 “Growth in Global Energy Demand Surged in 2024 to Almost Twice Its Recent Average,” hardware products with at least one year of data and which have had up to 4 months to 
IEA, March 2025. obtain the UL 2799 validation.

48 The total MW figure represents primarily PPAs, and includes some generation from 80 “Japan’s Greenhouse Gas Emissions Fall 2.5% in FY22/23 to Record Low,” Reuters, April 
targeted clean energy investments where we also receive EACs. Actual generation 2024.
may vary from the signed amounts based on changes during construction or project 81 Refer to endnote 11 above.
terminations. 82 Refer to endnote 12 above.

49 To calculate avoided emissions from our carbon-free energy purchases, we compare our 83 This figure reflects our “ambition-based” emissions boundary, which represents the 
scope 2 (market-based) emissions to the emissions we would have had if we didn’t use subset of emissions from our total carbon footprint that are within the boundaries we’ve 
any market-based interventions like PPAs or other clean energy agreements and instead set for our climate ambitions. For more details, refer to the Ambition-based carbon 
only used electricity from the local grid (location-based). footprint and Methodology sections.

50 These emissions savings represent the cumulative difference between our scope 2 84 Refer to endnote 17 above.
location-based emissions—which don’t take into account our CFE procurement—and our 85 Refer to endnote 12 above.
scope 2 market-based emissions, from 2012 to 2024. 86 Emissions reductions estimates are modeled using a Department of Energy emissions 

51 We input the estimated avoided emissions into the EPA’s Greenhouse Gas Equivalencies model. A single fuel-based vehicle type is used as an approximation for all traffic, adjusted 
Calculator to calculate the equivalent number of homes’ electricity use for a year, which for country-level fleet mix from IEA data. To estimate fuel savings at an intersection, 
was approximately 9.1 million homes (accessed April 2025). The comparison is based on we first estimate the number of cars passing through an intersection, as well as the 
the data from the U.S. Census: New York State had an estimated 8.7 million housing units behavior: stopping, slowing, turning, etc. Using this in combination with the Department 
as of July 2024. of Energy emissions model, Google can estimate the fuel emitted at each intersection. 

52 Based on a comparison of EPA eGRID Emission Factors that we used for our GHG Google ran a study on a subset of intersections in 2024, estimating emissions before 
inventory for U.S. grid regions where we had operations. and after implementing recommendations on optimal signal timing. Based on this study, 

53 Refer to endnote 7 above. we estimate that the recommendations for optimal signal timing at these intersections 
54 Refer to endnote 2 above. enabled an average of over 10% emissions reductions. We applied this savings factor to 
55 Refer to endnote 2 above. all intervened-upon intersections in 2024 to arrive at the estimated enabled emissions 
56 Refer to endnote 3 above. reduction figure. Enabled emissions reductions estimates include inherent uncertainty 
57 The total GW figure includes generation from targeted clean energy investments. Actual due to factors that include the lack of primary data and precise information about real-

amounts funded and generation developed may vary from the amounts anticipated when world actions and their effects. These factors contribute to a range of possible outcomes, 
the agreements were signed. within which we report a central value. The data and claims have not been verified by an 

58 “Pathways to Commercial Liftoff: Advanced Nuclear,” U.S. Department of Energy, March independent third-party.
2023. 87 Refer to endnote 33 above.

59 Refer to endnote 58 above. 88 Refer to endnote 16 above.
60 Refer to endnote 5 above. 89 To estimate the annual enabled emissions reductions in 2024, Google first interviewed 
61 Refer to endnote 5 above. partners that use Google Earth Pro to understand the significance it played in their 
62 Refer to endnote 5 above. process (from siting to construction) and considered all the solar and onshore wind 
63 Google has purchased “Configuration 3” T-EACs. According to the EnergyTag standard, power plants built by the developers. For solar plants, we estimated the capacity factor 

Configuration 3 “enables Granular Certificate Issuance where the EAC Issuing body does via an EIA published dataset, then estimated the per-hour-of-the-year generation profile 
not oversee the coordination with Granular Certificates for the same production. Instead, via NREL PVWatts. For wind plants, we leveraged Berkeley Lab’s Land-Based Wind Market 
the Granular Certificate Issuer takes such coordination upon itself. This involves canceling Report to estimate a capacity factor and assume that the wind generation profile is 
Granular Certificates upon their Issuance, for the same beneficiary as the beneficiary of steady throughout the year. For both solar and wind, we used the NREL Cambium model 
the associated EACs for the same represented energy.” to estimate the amount of emissions reduced due to the clean energy generated in 

64 This represents Google CFE percentages for grid regions with Google-owned and 2024. The estimated annual emissions reduction takes into account projects enabled by 
-operated data centers in 2024. In previous reports, we included Google CFE percentages Google Earth prior to 2024 (dating back to 2020) to calculate the total impact in 2024 
for all grid regions where we had data center operations, including third-party-operated alone. Enabled emissions reductions estimates include inherent uncertainty due to factors 
facilities. All our data center operations, including third-party-operated facilities, are still that include the lack of primary data and precise information about real-world actions 
included in our global and regional Google CFE metrics. and their effects to date, as well as forward-looking projections. Google is relying on 

65 Refer to endnote 10 above. its own substantiation of the enabled emissions-reduction impact, in consultation with 
66 Based on the average annual irrigation of golf courses in the southwest U.S. of 459 acre-ft multiple third-party partners that have reviewed and support the methodology discussed 

or around 150 million gallons. Source: “How Much Water Does Golf Use and Where Does It herein. The data and claims have not been verified by an independent third-party. We will 
Come From?” U.S. Golf Association, November 2012. continue to work to refine our methodologies and inputs for these estimates.

67 Refer to endnote 5 above. 90 Estimated energy savings are calculated based on the average percentages for heating 
68 Refer to endnote 5 above. and cooling savings found in real-world studies of the Nest Learning Thermostat in the 
69 “California’s Central Valley,” U.S. Geological Survey, accessed March 2025. U.S. and U.K., and generalized for Nest thermostat usage worldwide, assuming user opt-in 
70 For Google-managed server assembly and maintenance, there was a year-on-year for available energy-saving features. To calculate the total Nest savings, we applied the 

increase in the quantity of reused components in 2024 compared to 2023. This savings percentages to the actual heating and cooling hours of all Nest thermostats in 
percentage excludes components used to build servers through original equipment use in 2024.
manufacturers (OEM), which experienced increased deployment in 2024. 91 The enabled emissions reductions are calculated based on these energy savings, applying 

71 Percent reduction in food waste per Googler was calculated as food waste generated in standard emission factors for fossil fuels, and using U.S. EPA AVERT marginal emissions 
kitchens and cafes at Google’s global offices per unique building badge swipes, against a for the 95% of electricity savings that occur in the U.S., with an adjusted value for the 5% 
2019 base year. of electricity savings outside the U.S. The data and claims have not been verified by an 

72 Based on total weight of new Google Pixel and Fitbit products launched and independent third-party.
manufactured in 2024. 92 Refer to endnote 14 above.

73 For Pixel 9 and Pixel 9 Pro phones, the recycled rare earth elements are a minimum of 27% 93 According to the IEA’s Energy Statistics Data Browser, Poland’s total electricity 
of the magnet total weight. Pixel Watch 3 docking, speaker, and haptic magnets contain consumption was approximately 160 TWh in 2023.
100% recycled rare earth elements, but the majority of the magnet weight consists of 94 Refer to endnote 17 above.
other materials. 95 Refer to endnote 12 above.

117



96 Refer to endnote 19 above. both PUE and machine hardware efficiency, we assume additional energy consumption 
97 This is based on estimated daily car rides at the intersections where Green Light has been in the avoided baseline scenario would not have been matched with additional clean 

implemented from 2021 to 2024, multiplied by the average workdays in a month. energy procurement. Refer to endnote 49 for the calculation of avoided emissions from 
98 Refer to endnote 86 above. our carbon-free energy procurement. The data and claims have not been verified by an 
99 The Solar API estimates the rooftop solar potential of buildings around the world using independent third-party.

high-resolution, 3D models of individual roofs from our aerial imagery in Google Maps. 120 Currently, SBTi validates near-term (by 2030) carbon reduction targets and long-term 
We’ve counted the number of individual buildings for which we have data, and which can (by or before 2050) net-zero targets (“SBTi Corporate Net-Zero Standard Version 1.2,” 
be queried via a lat-long in Google Maps Platform. Science Based Targets initiative, March 2024). Our carbon reduction ambition was 

100 Refer to endnote 33 above. validated using the SBTi Corporate Near-Term Criteria Version 5.2 and following the cross-
101 Refer to endnote 16 above. sector absolute reduction method. This approach aligns with a 1.5°C scenario and utilizes 
102 “The Contribution of Global Aviation to Anthropogenic Climate Forcing for 2000 to the standard validation route for target setting. Because our net-zero ambition allows 

2018,” Atmospheric Environment, January 2021. Calculated using Supplementary data to for 50% remaining emissions by our 2030 ambition date, we don’t meet SBTi’s criteria of 
compare the global warming potential (GWP100) of contrails to the total global warming only 10% residuals (for a long-term net-zero target by 2050). For this reason, we’ve only 
potential of the three primary aviation pollutants (CO2, NOx, and contrails). validated our near-term carbon reduction ambition with SBTi to date.

103 Using satellite imagery, large-scale weather data, and flight data, we trained a contrails 121 This covers many of the procured goods and services related to our day-to-day 
prediction model. For this trial, we partnered with American Airlines to integrate contrail operations such as IT, marketing, professional services, legal services, software, real 
likely zone predictions into the tablets that their pilots used in flight so they could make estate management, etc.
real time adjustments in altitude to avoid creating contrails. We evaluated the model’s 122 Alphabet is a collection of businesses—the largest of which is Google. We refer to all non-
performance using satellite imagery, comparing contrail formation (measured in contrail Google businesses collectively as Other Bets. See Alphabet’s 2023 Form 10-K for more 
kilometers) in flights where pilots used predictions to avoid contrails, to contrail formation detail.
in flights where pilots didn’t use contrail predictions. For more details, refer to the Project 123 “SBTi Corporate Near-Term Criteria V5.2,” Science Based Target Initiative, March 2024. 
Contrails website and the Feasibility test of per-flight contrail avoidance in commercial Criteria C5 and C6 outline the requirements for GHG inventory emissions coverage and 
aviation paper. target boundaries.

104 “Aviation Contrail Climate Effects in the North Atlantic from 2016 to 2021,” Atmospheric 124 In 2025, the SBTi validated Alphabet’s near-term science-based emissions reduction 
Chemistry and Physics, vol. 22, iss. 16, August 2022. ambition, aligning our measurements with rigorous standards for emissions reduction. 

105 We estimated a cost efficiency range based on our trial’s results in combination with Our carbon reduction ambition was validated using the SBTi Corporate Near-Term 
published contrail literature. There is inherent uncertainty for this cost range due to Criteria Version 5.2 and following the cross-sector absolute reduction method.
estimations of the impact of contrails to the climate system. For more detail, refer to the 125 Moving forward, we may share updates to this roadmap when there are significant 
Project Contrails website. changes or revisions to our strategy.

106 “CDR.fyi 2024 Year in Review,” CDR.fyi, February 2025. 126 Carbon reduction initiatives refer to all of the specific projects or initiatives that play 
107 “Global Outlook for Air Transport—A World with Lower Oil Prices?,” International Air some role in reducing footprint emissions by 2030. Key reduction areas are groupings of 

Transport Association, December 2024. similar carbon reduction initiatives into higher-level buckets and represent the key areas 
108 “India’s Met Office Warns of Intense Heatwave This Summer,” BBC, March 2025. of focus for our decarbonization plan.
109 Based on an analysis of change in Google Search interest for “hurricanes,” “wildfires,” and 127 Future emissions expectations are illustrative and rely on assumptions about the 

“climate change” topics during extreme weather events between 2022 and 2025. implementation of the key reduction areas outlined in this roadmap. The actual emissions 
110 Based on a comparison of simulation speeds of the NeuralGCM model, the NOAA reductions achieved in the future may differ.

X-SHiELD, and the NCAR CAM6 (AMIP) model, which were run at different resolutions. 128 We’re prioritizing reductions across scopes 2 and 3, which have much larger emissions 
111 Based on a comparison of the computational costs for the SEEDS model and estimated reduction potential. In fact, the vast majority of reductions rely on accelerating the 

computational costs for the U.S. operational forecast system, Global Ensemble Forecast deployment of clean electricity across both our operations and suppliers—which is why 
System (GEFS) version 12. For more details, refer to the Generative emulation of weather a significant portion of our plan focuses specifically on unlocking new clean energy. 
forecast ensembles with diffusion models paper. Reducing scope 1 emissions is important—not only because they’re within our direct 

112 “People in Harm’s Way: Flood Exposure and Poverty in 189 Countries,” World Bank Group, control, but also because they’re part of our broader sustainability efforts. However, they 
October 2020. represent less than 1% of our total 2024 ambition-based carbon footprint.

113 Refer to endnote 21 above. 129 PUE is a standard industry ratio that compares the amount of non-computing overhead 
114 Refer to endnote 5 above. energy (used for things like cooling and power distribution) to the amount of energy used 
115 Based on research from the International Energy Agency (Advancing Decarbonisation to power IT equipment. For example, a PUE of 2.0 means that for every watt of IT power, 

through Clean Electricity Procurement, 2022), Princeton University (The Influence of an additional watt is consumed to cool and distribute power to the IT equipment. A PUE 
Demand-Side Data Granularity on the Efficacy of 24/7 Carbon-Free Electricity closer to 1.0 means nearly all the energy is used for computing. According to the Uptime 
Procurement, 2024), and Technical University of Berlin (System-Level Impacts of 24/7 Institute’s 2024 Global Data Center Survey, the global average PUE of respondents’ data 
Carbon-Free Electricity Procurement in Europe, 2024). centers was 1.56. The overhead energy use comparison was calculated as follows: (1 - 

116 For 2022 and 2023, the Canada & Mexico regional average Google CFE metric includes (Google’s overhead energy use [0.09] divided by the industry average overhead energy 
only Canadian grid regions where we had data center operations. We didn’t have data use [0.56])) x 100 = 84%.
center operations in Mexico prior to 2024. 130 Refer to endnote 2 above.

117 Refer to endnote 5 above. 131 Supplier scope 3 electricity includes hardware supplier electricity (e.g., electricity used 
118 Our carbon reduction ambition was validated using the SBTi Corporate Near-Term Criteria to manufacture semiconductors, servers, Google consumer hardware devices, etc.), 

Version 5.2 and following the cross-sector absolute reduction method. This approach office construction (data center construction supplier electricity is separately covered 
aligns with a 1.5°C scenario and utilizes the standard validation route for target setting. in the scope 3 low-carbon data center construction key reduction area), and food (i.e., 

119 Avoided emissions are emissions that would have otherwise occurred but were avoided electricity used by suppliers of food for Google cafes). Non-supplier scope 3 electricity 
because of actions taken either as part of normal operations or in service of climate includes product use phase electricity (e.g., electricity used to charge Pixel phones), 
ambitions. We calculate avoided emissions by comparing our actual emissions to a and transmission and distribution losses from our scope 2 electricity use. There are also 
scenario where we didn't take action. To calculate avoided emissions from our power scope 3 emissions from the upstream impacts of electricity use: “Category 3: Fuel- and 
usage effectiveness (PUE) improvements, we compare our fleet-wide trailing 12-month energy-related activities (not included in scope 1 or 2).” These are the upstream emissions 
(TTM) PUE in each year from 2019 to 2024 to a baseline from our earliest fleet-wide TTM from purchased electricity consumed by the reporting company: extraction, production, 
PUE (which was 1.21 in 2008). This baseline assumes that our PUE would have remained and transportation of fuels consumed during the generation of electricity, steam, heating, 
the same without our efficiency improvements. We translate this efficiency improvement and cooling. Although these emissions fall under scope 3, our scope 2 clean electricity 
into avoided energy consumption, and then calculate avoided emissions using an annual reduction activities are the drivers of reductions in this scope 3 category because 
emissions rate (emissions/GWh) derived from reported scope 2 electricity data in our any reduction in fossil fuel-based electricity use will translate into a reduction in these 
corporate GHG inventory for the relevant year. To calculate avoided emissions from our upstream electricity emissions.
machine hardware efficiency improvements, we compare the actual emissions from our 132 Refer to endnote 10 above.
servers in 2019 to 2024 and other hardware to a hypothetical scenario where we didn't 133 We calculated the reduction in embodied carbon emissions intensity by comparing 
implement any efficiency measures and continued to deploy older, less efficient hardware Google’s 2019 baseline standard data center design to our revised standardized data 
which could have resulted in increased machines deployed and increased energy center designs which incorporate design updates to server hall hot air containment 
consumption. By comparing the actual energy consumption to this hypothetical baseline, systems, electrical distribution systems, and cooling tower units.
which is defined by the machines deployed in 2019, we estimate the energy savings 134 Based on an internal life cycle assessment of Google’s 2019 standard data center design.
and associated scope 2 emissions avoided through our machine hardware efficiency 135 Refer to endnote 5 above.
initiatives. Similarly, we estimate the scope 3 emissions avoided by comparing actual 136 Refer to endnote 5 above.
hardware manufacturing and logistics emissions to the same hypothetical baseline. For 137 We recalculated data center waste diversion metrics. For additional details, refer to the 

118



Methodology section. 152  “Purchased heat” includes both natural gas in leased facilities and district heat in 
138 Refer to endnote 76 above. applicable facilities.
139 Based on total plastic weight of Google Pixel, Nest, Chromecast, and Fitbit products 153  Refer to endnote 151 above.

manufactured in 2023. This does not include plastics in printed circuit boards, labels, 154  Refer to endnote 152 above.
cables, connectors, electronic components and modules, optical components, 155  “Total electricity consumption” includes both purchased and self-generated electricity.
electrostatic discharge (ESD) components, electromagnetic interference (EMI) 156 Refer to endnote 155 above.
components, films, coatings, and adhesives. 157  “Total renewable electricity allocated” includes renewable electricity generation from 

140 Refer to endnote 76 above. contractual instruments (i.e., EACs), which have been used in the calculation of Scope 2 
141 Refer to endnote 22 above. market-based emissions per the Greenhouse Gas Protocol Scope 2 Quality Criteria.
142 Refer to endnote 22 above. 158 Refer to endnote 116 above.
143 Flagship consumer devices are products that can provide their main functionality without 159 Refer to endnote 64 above.

connection to another product. For example, this generally doesn’t include accessories 160 We report individual campus PUE only for campuses with at least twelve months of data. 
such as cases. All reported PUE values are rounded to the hundredths place.

144 Network and end-user devices used to access web-based software are not considered to 161 In 2023, we adjusted our methodology for calculating waste generated and diversion 
be direct-use phase emissions and are not within the reporting boundary for use of sold for our offices, integrating new data sources for reused furniture and recycled e-waste. 
products. These changes are reflected in our reported office waste data for 2023 and 2024, but not 

145 Excluded scope 3 categories include specific activities within “Category 1: Purchased for prior years.
goods and services” and “Category 2: Capital goods.” 162 We’ve adjusted the terminology used for this metric to clarify that the reported 

146 Refer to endnote 121 above. percentage is applicable to reused inventory for Google-managed server assembly and 
147 Refer to endnote 122 above. maintenance. The scope of the metric remains unchanged.
148 We present all emissions from category 2 (Capital goods) and category 11 (Use of sold 163 We’ve adjusted the terminology used for this metric to clarify that the reported 

products) as an aggregated total for business reasons. percentages are based on sources (which can include watersheds) at risk for both water 
149 While we haven’t excluded any Alphabet scope 1 or scope 2 emissions from our carbon scarcity or depletion. The scope of the metric remains unchanged.

reduction ambition boundary, we’ve excluded specific activities within scope 3 that are 164 Unless otherwise specified, water withdrawals are potable water.
peripheral to our core operations and where our ability to influence emissions reductions 165 Refer to endnote 66 above.
is limited: food program purchases, certain purchased goods and services associated 166 Air-cooled facility.
with Alphabet’s day-to-day operations, and Other Bets capital goods. This boundary is 167 For more details, refer to the Google Data Centers Location website.
in line with SBTi’s guidelines for target validation. For more details, refer to the Ambitions 168 Refer to endnote 166 above.
section. 169 Refer to endnote 164 above.

150 Estimated contracted credits and expected timeframe for delivery may vary based on 170 Refer to endnote 66 above.
changes during the project, supplier circumstances, and contract terminations. This 171 Refer to endnote 166 above.
table reflects the best available information as of April 2025, for agreements signed as 172 Refer to endnote 166 above.
of the end of 2024. At the time of publication, the following information wasn’t available 173 Refer to endnote 166 above.
for all of the projects except for Vaulted Deep and CREW: registry, project identification 174 Refer to endnote 167 above.
number, project name, and protocol used to estimate removal benefits. Removals credits 175 Refer to endnote 166 above.
undergo independent third-party verification prior to registry issuance and delivery 176 Refer to endnote 166 above.
to Google. Details for the Vaulted Deep project include: Registry: Isometric; Project 177 Refer to endnote 166 above.
Identification Number: 01P4; Project Name: Great Plains Organic Waste Sequestration; 178 We’ll also pursue this for our data center in Hanau, Germany, which became operational in 
Protocol: Biomass Geological Storage v1.1 (Isometric). Details for the CREW project 2024.
include: Registry: Isometric; Project Identification Number: X8KC; Project Name: Greater 179 Refer to endnote 178 above.
New Haven Municipal WAE Project; Protocol: Wastewater Alkalinity Enhancement v1.0 180 Refer to endnote 178 above.
(Isometric).

151  “Purchased electricity” is electricity sourced from an electrical grid and purchased from a 
local electric utility company.

Photo details
On the cover/Introduction: Street View image of Redwood State and National Park, used with permission. ©2025 Google
Age of AI: Street View image of the International Space Station, used with permission. ©2025 Google
Energy for our data centers: El Romero solar farm in Chile (80 MW for Google).
Energy for our supply chain: A technician scans hardware components, a critical step for tracking parts through every stage of the production process.
Resource efficiency: Clear waters reflect the beauty of our data center in Eemshaven, Netherlands.
New AI research solutions: The Solar API generates detailed rooftop data based on Google’s extensive geospatial data and computing resources in order to evaluate rooftop solar energy potential.
AI for extreme events and disaster response: A wide river basin during low water levels illustrates the type of flood-prone environment where flood forecasting is critical.
Protecting the planet with our AI products: Street View image of the Great Barrier Reef, used with permission. ©2025 Google
Appendix: Our Bay View campus, as seen from across its stormwater retention pond. (Photo credit: Iwan Baan)

119



Environmental 
Report 
2025 

Want to learn more? 

For interactive ways to explore the report’s data and stories, 
visit our 2025 Environmental Report webpage. For ongoing 
news and progress updates, refer to our Sustainability blog. 

Publication date: June 2025
